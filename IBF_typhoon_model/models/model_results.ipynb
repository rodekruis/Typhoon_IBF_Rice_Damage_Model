{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Loading Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "from imblearn.pipeline import Pipeline\r\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "from xgboost import XGBClassifier\r\n",
    "import os\r\n",
    "from sklearn.feature_selection import RFECV\r\n",
    "import pandas as pd\r\n",
    "from sklearn.model_selection import (\r\n",
    "    GridSearchCV,\r\n",
    "    RandomizedSearchCV,\r\n",
    "    StratifiedKFold,\r\n",
    "    KFold,\r\n",
    ")\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "import numpy as np\r\n",
    "from numpy.lib.function_base import average\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.metrics import (\r\n",
    "    recall_score,\r\n",
    "    f1_score,\r\n",
    "    precision_score,\r\n",
    "    confusion_matrix,\r\n",
    "    make_scorer,\r\n",
    ")\r\n",
    "from sklearn.model_selection import (\r\n",
    "    GridSearchCV,\r\n",
    "    RandomizedSearchCV,\r\n",
    "    StratifiedKFold,\r\n",
    "    KFold,\r\n",
    ")\r\n",
    "from sklearn.feature_selection import SelectKBest, SequentialFeatureSelector\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "from imblearn.pipeline import Pipeline\r\n",
    "import importlib\r\n",
    "import os\r\n",
    "from sklearn.feature_selection import (\r\n",
    "    SelectKBest,\r\n",
    "    RFE,\r\n",
    "    mutual_info_regression,\r\n",
    "    f_regression,\r\n",
    "    mutual_info_classif,\r\n",
    ")\r\n",
    "import eli5\r\n",
    "from eli5.sklearn import PermutationImportance\r\n",
    "from sklearn.inspection import permutation_importance\r\n",
    "import xgboost as xgb\r\n",
    "import random\r\n",
    "import pickle\r\n",
    "import openpyxl\r\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\r\n",
    "from sklearn.feature_selection import RFE\r\n",
    "from sklearn.feature_selection import RFECV\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Setting path to the initial folder\r\n",
    "os.chdir(\"C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\")\r\n",
    "cdir = os.getcwd()\r\n",
    "\r\n",
    "import importlib\r\n",
    "\r\n",
    "from IBF_typhoon_model.models.binary_classification.xgb_binary import xgb_binary_features, xgb_binary_performance\r\n",
    "from IBF_typhoon_model.models.binary_classification.rf_binary import rf_binary_features, rf_binary_performance\r\n",
    "\r\n",
    "from IBF_typhoon_model.models.utility_functions.splitting_train_test import splitting_train_test\r\n",
    "from IBF_typhoon_model.models.utility_functions.determine_class import determine_class"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook to obtain the model performance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Input data\r\n",
    "name = \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\combined_input_data\\\\input_data_01.xlsx\"\r\n",
    "path = os.path.join(cdir, name)\r\n",
    "df = pd.read_excel(path, engine=\"openpyxl\")\r\n",
    "\r\n",
    "# Typhoon overview\r\n",
    "file_name = \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\data_overview.xlsx\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "df_typh_overview = pd.read_excel(path, sheet_name=\"typhoon_overview\", engine=\"openpyxl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Selecting the features to be used\r\n",
    "features = [\r\n",
    "    \"rice_area\",\r\n",
    "    \"mean_slope\",\r\n",
    "    \"mean_elevation_m\",\r\n",
    "    \"ruggedness_stdev\",\r\n",
    "    \"mean_ruggedness\",\r\n",
    "    \"slope_stdev\",\r\n",
    "    \"area_km2\",\r\n",
    "    \"poverty_perc\",\r\n",
    "    \"with_coast\",\r\n",
    "    \"coast_length\",\r\n",
    "    \"perimeter\",\r\n",
    "    \"glat\",\r\n",
    "    \"glon\",\r\n",
    "    \"coast_peri_ratio\",\r\n",
    "    \"rainfall_sum\",\r\n",
    "    \"rainfall_max\",\r\n",
    "    \"dis_track_min\",\r\n",
    "    \"vmax_sust\",\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binary Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Setting the general input variables\r\n",
    "threshold = 0.3\r\n",
    "df[\"class_value_binary\"] = [1 if df[\"perc_loss\"][i] > threshold else 0 for i in range(len(df))]\r\n",
    "\r\n",
    "# Setting for feature selection on full data set\r\n",
    "X = df[features]\r\n",
    "y = df['class_value_binary']\r\n",
    "\r\n",
    "# Setting the train and the test sets for obtaining performance estimate\r\n",
    "df_train_list, df_test_list = splitting_train_test(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the random forest search grid\r\n",
    "rf_search_space_binary = [{\r\n",
    "        \"estimator__n_estimators\": [50, 100, 500],\r\n",
    "        \"estimator__max_depth\": [20, None],\r\n",
    "        \"estimator__min_samples_split\": [2, 8, 10],\r\n",
    "        \"estimator__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }]\r\n",
    "\r\n",
    "# Obtaining the selected features based on the full dataset\r\n",
    "selected_features_rf_binary,  selected_params_rf_binary = rf_binary_features(\r\n",
    "    X=X,\r\n",
    "    y=y,\r\n",
    "    features=features,\r\n",
    "    search_space=rf_search_space_binary,\r\n",
    "    cv_splits=5,\r\n",
    "    class_weight='balanced',\r\n",
    "    min_features_to_select=18,\r\n",
    "    GS_score='f1',\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=3,\r\n",
    ")\r\n",
    "\r\n",
    "print(f\"Number of selected features RF Binary: {len(selected_features_rf_binary)}\")\r\n",
    "print(f\"Selected features RF Binary: {selected_features_rf_binary}\")\r\n",
    "print(f\"Selected Parameters RF Binary {selected_params_rf_binary}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Setting the selected features for RF --> based on outcome in previous cell\r\n",
    "selected_features_rf_binary = [\r\n",
    "    'rice_area', \r\n",
    "    'mean_slope', \r\n",
    "    'mean_elevation_m', \r\n",
    "    'ruggedness_stdev', \r\n",
    "    'mean_ruggedness', \r\n",
    "    'slope_stdev', \r\n",
    "    'area_km2', \r\n",
    "    'poverty_perc', \r\n",
    "    'with_coast', \r\n",
    "    'coast_length', \r\n",
    "    'perimeter', \r\n",
    "    'glat', \r\n",
    "    'glon', \r\n",
    "    'coast_peri_ratio', \r\n",
    "    'rainfall_sum', \r\n",
    "    'rainfall_max', \r\n",
    "    'dis_track_min', \r\n",
    "    'vmax_sust'\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Setting the random forest search grid\r\n",
    "rf_search_space_binary = [{\r\n",
    "        \"estimator__n_estimators\": [50, 100, 500],\r\n",
    "        \"estimator__max_depth\": [20, None],\r\n",
    "        \"estimator__min_samples_split\": [2, 8, 10],\r\n",
    "        \"estimator__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }]\r\n",
    "\r\n",
    "# Obtaining the performance estimate\r\n",
    "df_predicted_rf_binary = rf_binary_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    features=selected_features_rf_binary,\r\n",
    "    search_space=rf_search_space_binary,\r\n",
    "    stratK=True,\r\n",
    "    cv_splits=5,\r\n",
    "    class_weight='balanced',\r\n",
    "    GS_score='f1',\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=10,\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2, 1, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Setting the XGBoost search grid for full dataset\r\n",
    "xgb_search_space_binary = [{\r\n",
    "        \"estimator__learning_rate\": [0.1, 0.5, 1],\r\n",
    "        \"estimator__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"estimator__max_depth\": [6, 8],\r\n",
    "        \"estimator__reg_lambda\": [0.001, 0.01, 0.1, 1],\r\n",
    "        \"estimator__n_estimators\": [100],\r\n",
    "        \"estimator__colsample_bytree\": [0.5, 0.7, 1],\r\n",
    "    }]\r\n",
    "\r\n",
    "# Obtaining the selected features based on the full dataset\r\n",
    "selected_features_xgb_binary, selected_params_xgb_binary = xgb_binary_features(\r\n",
    "    X=X, \r\n",
    "    y=y, \r\n",
    "    features=features, \r\n",
    "    search_space=xgb_search_space_binary, \r\n",
    "    objective=\"binary:hinge\", \r\n",
    "    cv_splits=5, \r\n",
    "    min_features_to_select=10, \r\n",
    "    GS_score='f1', \r\n",
    "    GS_n_iter=1,\r\n",
    "    GS_randomized=True\r\n",
    ")\r\n",
    "\r\n",
    "print(f\"Number of selected features XGBoost Binary {len(selected_features_xgb_binary)}\")\r\n",
    "print(f\"Selected features XGBoost Binary: {selected_features_xgb_binary}\")\r\n",
    "print(f\"Selected parameters XGBoost Binary: {selected_params_xgb_binary}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Number of selected features XGBoost Binary 15\n",
      "Selected features XGBoost Binary: ['rice_area', 'mean_ruggedness', 'slope_stdev', 'area_km2', 'poverty_perc', 'with_coast', 'coast_length', 'perimeter', 'glat', 'glon', 'coast_peri_ratio', 'rainfall_sum', 'rainfall_max', 'dis_track_min', 'vmax_sust']\n",
      "Selected parameters XGBoost Binary: {'estimator__reg_lambda': 0.001, 'estimator__n_estimators': 100, 'estimator__max_depth': 8, 'estimator__learning_rate': 0.1, 'estimator__gamma': 0.1, 'estimator__colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Setting the selected features for XGB --> based on outcome previous cell\r\n",
    "selected_features_xgb = [\r\n",
    "    'rice_area', \r\n",
    "    'mean_slope', \r\n",
    "    'mean_elevation_m', \r\n",
    "    'ruggedness_stdev', \r\n",
    "    'mean_ruggedness', \r\n",
    "    'slope_stdev', \r\n",
    "    'area_km2', \r\n",
    "    'poverty_perc', \r\n",
    "    'with_coast', \r\n",
    "    'coast_length', \r\n",
    "    'perimeter', \r\n",
    "    'glat', \r\n",
    "    'glon', \r\n",
    "    'coast_peri_ratio', \r\n",
    "    'rainfall_sum', \r\n",
    "    'rainfall_max', \r\n",
    "    'dis_track_min', \r\n",
    "    'vmax_sust'\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Setting the XGBoost search grid\r\n",
    "xgb_search_space_binary = [{\r\n",
    "        \"xgb__learning_rate\": [0.1, 0.5, 1],\r\n",
    "        \"xgb__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"xgb__max_depth\": [6, 8],\r\n",
    "        \"xgb__reg_lambda\": [0.001, 0.01, 0.1, 1],\r\n",
    "        \"xgb__n_estimators\": [100],\r\n",
    "        \"xgb__colsample_bytree\": [0.5, 0.7, 1],\r\n",
    "    }]\r\n",
    "\r\n",
    "# Obtaining the performance estimate\r\n",
    "df_predicted_xgb_binary = xgb_binary_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    features=selected_features_xgb,\r\n",
    "    search_space=xgb_search_space_binary,\r\n",
    "    stratK=True,\r\n",
    "    cv_splits=5,\r\n",
    "    objective=\"binary:hinge\",\r\n",
    "    GS_score='f1',\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=10,\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running for 1 out of a total of 5\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Selected Parameters: {'xgb__reg_lambda': 1, 'xgb__n_estimators': 100, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.5, 'xgb__colsample_bytree': 0.5}\n",
      "Train score: 0.8371723590150913\n",
      "Test score: 0.616052060737527\n",
      "Running for 2 out of a total of 5\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Selected Parameters: {'xgb__reg_lambda': 0.001, 'xgb__n_estimators': 100, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.5, 'xgb__colsample_bytree': 1}\n",
      "Train score: 0.8302270416807862\n",
      "Test score: 0.5561497326203209\n",
      "Running for 3 out of a total of 5\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Selected Parameters: {'xgb__reg_lambda': 0.1, 'xgb__n_estimators': 100, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 2, 'xgb__colsample_bytree': 0.5}\n",
      "Train score: 0.8086330935251799\n",
      "Test score: 0.41836734693877553\n",
      "Running for 4 out of a total of 5\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Selected Parameters: {'xgb__reg_lambda': 0.001, 'xgb__n_estimators': 100, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 2, 'xgb__colsample_bytree': 1}\n",
      "Train score: 0.8225078152136158\n",
      "Test score: 0.4727272727272727\n",
      "Running for 5 out of a total of 5\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Selected Parameters: {'xgb__reg_lambda': 1, 'xgb__n_estimators': 100, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.5, 'xgb__colsample_bytree': 1}\n",
      "Train score: 0.8466730954676954\n",
      "Test score: 0.2777777777777778\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multiclass Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "# Setting class value\r\n",
    "classes = {\"0\": [0, 0.3], \"1\": [0.3, 0.8], \"2\": [0.8, 1.1]}\r\n",
    "df['class_value_multi'] = df['perc_loss'].apply(lambda x: determine_class(x, classes=classes))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 132;\n                var nbb_unformatted_code = \"# Setting class value\\r\\nclasses = {\\\"0\\\": [0, 0.3], \\\"1\\\": [0.3, 0.8], \\\"2\\\": [0.8, 1.1]}\\r\\ndf['class_value_mulit'] = df['perc_loss'].apply(lambda x: determine_class(x, classes=classes))\";\n                var nbb_formatted_code = \"# Setting class value\\nclasses = {\\\"0\\\": [0, 0.3], \\\"1\\\": [0.3, 0.8], \\\"2\\\": [0.8, 1.1]}\\ndf[\\\"class_value_mulit\\\"] = df[\\\"perc_loss\\\"].apply(\\n    lambda x: determine_class(x, classes=classes)\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df[features]\r\n",
    "y = df['class_value_multi']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the random forest search grid\r\n",
    "rf_search_space = [{\r\n",
    "        \"estimator__n_estimators\": [50, 100, 500],\r\n",
    "        \"estimator__max_depth\": [20, None],\r\n",
    "        \"estimator__min_samples_split\": [2, 8, 10],\r\n",
    "        \"estimator__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }]\r\n",
    "\r\n",
    "selected_features_rf = rf_multi_features(\r\n",
    "    X=X,\r\n",
    "    y=y,\r\n",
    "    features=features,\r\n",
    "    search_space=rf_search_space,\r\n",
    "    cv_splits=5,\r\n",
    "    class_weight='balanced',\r\n",
    "    min_features_to_select=7,\r\n",
    "    GS_score='f1_macro',\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=10,\r\n",
    ")\r\n",
    "\r\n",
    "print(f\"Selected features RF: {selected_features_rf}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the XGBoost search grid\r\n",
    "xgb_search_space = [{\r\n",
    "        \"estimator__learning_rate\": [0.1, 0.5, 1]\r\n",
    "        \"estimator__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"estimator__max_depth\": [6, 8],\r\n",
    "        \"estimator__reg_lambda\": [0.001, 0.01, 0.1, 1],\r\n",
    "        \"estimator__n_estimators\": [100, 200],\r\n",
    "        \"estimator__colsample_bytree\": [0.5, 0.7, 1],\r\n",
    "    }]\r\n",
    "\r\n",
    "selected_features_xgb = xgb_multi_features(\r\n",
    "    X=X,\r\n",
    "    y=y,\r\n",
    "    features=selected_features_xgb,\r\n",
    "    num_class=len(classes),\r\n",
    "    search_space=xgb_search_space,\r\n",
    "    objective=\"multi:softmax\",\r\n",
    "    cv_splits=5,\r\n",
    "    min_features_to_select=7,\r\n",
    "    GS_score='f1_macro',\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=10,\r\n",
    ")\r\n",
    "\r\n",
    "print(f\"Selected features XGBoost: {selected_features_xgb}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obtain performance estimate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "# Setting the train and the test sets\r\n",
    "df_train_list, df_test_list = splitting_train_test(df)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 135;\n                var nbb_unformatted_code = \"# Setting the train and the test sets\\r\\ndf_train_list, df_test_list = splitting_train_test(df)\";\n                var nbb_formatted_code = \"# Setting the train and the test sets\\ndf_train_list, df_test_list = splitting_train_test(df)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the selected features for RF --> if needed\r\n",
    "selected_features_rf = [\r\n",
    "    'rice_area', \r\n",
    "    'mean_slope', \r\n",
    "    'mean_elevation_m', \r\n",
    "    'ruggedness_stdev', \r\n",
    "    'mean_ruggedness', \r\n",
    "    'slope_stdev', \r\n",
    "    'area_km2', \r\n",
    "    'poverty_perc', \r\n",
    "    'with_coast', \r\n",
    "    'coast_length', \r\n",
    "    'perimeter', \r\n",
    "    'glat', \r\n",
    "    'glon', \r\n",
    "    'coast_peri_ratio', \r\n",
    "    'rainfall_sum', \r\n",
    "    'rainfall_max', \r\n",
    "    'dis_track_min', \r\n",
    "    'vmax_sust'\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the random forest search grid\r\n",
    "rf_search_space = [{\r\n",
    "        \"rf__n_estimators\": [50, 100, 500],\r\n",
    "        \"rf__max_depth\": [20, None],\r\n",
    "        \"rf__min_samples_split\": [2, 8, 10],\r\n",
    "        \"rf__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }]\r\n",
    "\r\n",
    "df_predicted_rf = rf_multi_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    features=selected_features_rf,\r\n",
    "    search_space=rf_search_space,\r\n",
    "    stratK=True,\r\n",
    "    cv_splits=5,\r\n",
    "    class_weight='balanced',\r\n",
    "    GS_score='f1_macro',\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=10,\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the selected features for XGB\r\n",
    "selected_features_xgb = [\r\n",
    "    'rice_area', \r\n",
    "    'mean_slope', \r\n",
    "    'mean_elevation_m', \r\n",
    "    'ruggedness_stdev', \r\n",
    "    'mean_ruggedness', \r\n",
    "    'slope_stdev', \r\n",
    "    'area_km2', \r\n",
    "    'poverty_perc', \r\n",
    "    'with_coast', \r\n",
    "    'coast_length', \r\n",
    "    'perimeter', \r\n",
    "    'glat', \r\n",
    "    'glon', \r\n",
    "    'coast_peri_ratio', \r\n",
    "    'rainfall_sum', \r\n",
    "    'rainfall_max', \r\n",
    "    'dis_track_min', \r\n",
    "    'vmax_sust'\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the XGBoost search grid\r\n",
    "xgb_search_space = [{\r\n",
    "        \"xgb__learning_rate\": [0.1, 0.5, 1],\r\n",
    "        \"xgb__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"xgb__max_depth\": [6, 8],\r\n",
    "        \"xgb__reg_lambda\": [0.001, 0.01, 0.1, 1],\r\n",
    "        \"xgb__n_estimators\": [100, 200],\r\n",
    "        \"xgb__colsample_bytree\": [0.5, 0.7, 1],\r\n",
    "    }]\r\n",
    "\r\n",
    "df_predicted_xgb = xgb_multi_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    num_class=len(classes),\r\n",
    "    features=selected_features_xgb,\r\n",
    "    search_space=xgb_search_space,\r\n",
    "    stratK=True,\r\n",
    "    cv_splits=5,\r\n",
    "    objective=\"multi:softmax\",\r\n",
    "    GS_score='f1_macro',\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=10,\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature selections"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df[features]\r\n",
    "y = df['perc_loss']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#%% Setting input varialbes\r\n",
    "rf_search_space = [{\r\n",
    "        \"estimator__n_estimators\": [50, 100, 500],\r\n",
    "        \"estimator__max_depth\": [20, None],\r\n",
    "        \"estimator__min_samples_split\": [2, 8, 10],\r\n",
    "        \"estimator__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }]\r\n",
    "\r\n",
    "selected_features_rf = rf_regression_features(\r\n",
    "    X=X,\r\n",
    "    y=y,\r\n",
    "    features=features,\r\n",
    "    search_space=rf_search_space,\r\n",
    "    min_features_to_select=7,\r\n",
    "    cv_splits=5,\r\n",
    "    GS_score=\"neg_root_mean_squared_error\",\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=10,\r\n",
    ")\r\n",
    "\r\n",
    "print(f\"Selected features RF: {selected_features_rf}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "xgb_search_space = [{\r\n",
    "        \"estimator__learning_rate\": [0.1, 0.5, 1],\r\n",
    "        \"estimator__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"estimator__max_depth\": [6, 8],\r\n",
    "        \"estimator__reg_lambda\": [0.001, 0.01, 0.1, 1],\r\n",
    "        \"estimator__n_estimators\": [100, 200],\r\n",
    "        \"estimator__colsample_bytree\": [0.5, 0.7, 1],\r\n",
    "    }]\r\n",
    "\r\n",
    "selected_features_xgb = xgb_regression_features(\r\n",
    "    X=X,\r\n",
    "    y=y,\r\n",
    "    features=features,\r\n",
    "    search_space=xgb_search_space,\r\n",
    "    min_features_to_select=7,\r\n",
    "    cv_splits=5,\r\n",
    "    GS_score=\"neg_root_mean_squared_error\",\r\n",
    "    objective='\"reg:squarederror\"',\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=10,\r\n",
    ")\r\n",
    "\r\n",
    "print(f\"Selected features RF: {selected_features_xgb}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obtaining performance Estimate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the train and the test sets\r\n",
    "df_train_list, df_test_list = splitting_train_test(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the selected features for rf\r\n",
    "selected_features_rf = [\r\n",
    "    'rice_area', \r\n",
    "    'mean_slope', \r\n",
    "    'mean_elevation_m', \r\n",
    "    'ruggedness_stdev', \r\n",
    "    'mean_ruggedness', \r\n",
    "    'slope_stdev', \r\n",
    "    'area_km2', \r\n",
    "    'poverty_perc', \r\n",
    "    'with_coast', \r\n",
    "    'coast_length', \r\n",
    "    'perimeter', \r\n",
    "    'glat', \r\n",
    "    'glon', \r\n",
    "    'coast_peri_ratio', \r\n",
    "    'rainfall_sum', \r\n",
    "    'rainfall_max', \r\n",
    "    'dis_track_min', \r\n",
    "    'vmax_sust'\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#%% Setting input varialbes\r\n",
    "rf_search_space = [{\r\n",
    "        \"rf__n_estimators\": [50, 100, 500],\r\n",
    "        \"rf__max_depth\": [20, None],\r\n",
    "        \"rf__min_samples_split\": [2, 8, 10],\r\n",
    "        \"rf__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }]\r\n",
    "\r\n",
    "df_predicted_rf = rf_regression_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    features=selected_features_rf,\r\n",
    "    search_space=rf_search_space,\r\n",
    "    cv_splits=5,\r\n",
    "    GS_score=\"neg_root_mean_squared_error\",\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=10,\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the selected features for XGB\r\n",
    "selected_features_xgb = [\r\n",
    "    'rice_area', \r\n",
    "    'mean_slope', \r\n",
    "    'mean_elevation_m', \r\n",
    "    'ruggedness_stdev', \r\n",
    "    'mean_ruggedness', \r\n",
    "    'slope_stdev', \r\n",
    "    'area_km2', \r\n",
    "    'poverty_perc', \r\n",
    "    'with_coast', \r\n",
    "    'coast_length', \r\n",
    "    'perimeter', \r\n",
    "    'glat', \r\n",
    "    'glon', \r\n",
    "    'coast_peri_ratio', \r\n",
    "    'rainfall_sum', \r\n",
    "    'rainfall_max', \r\n",
    "    'dis_track_min', \r\n",
    "    'vmax_sust'\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "xgb_search_space = [{\r\n",
    "        \"xgb__learning_rate\": [0.1, 0.5, 1],\r\n",
    "        \"xgb__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"xgb__max_depth\": [6, 8],\r\n",
    "        \"xgb__reg_lambda\": [0.001, 0.01, 0.1, 1],\r\n",
    "        \"xgb__n_estimators\": [100, 200],\r\n",
    "        \"xgb__colsample_bytree\": [0.5, 0.7, 1],\r\n",
    "    }]\r\n",
    "\r\n",
    "df_predicted_xgb = xgb_regression_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    features=features,\r\n",
    "    search_space=xgb_search_space,\r\n",
    "    cv_splits=5,\r\n",
    "    objective=\"reg:squarederror\",\r\n",
    "    GS_score=\"neg_root_mean_squared_error\",\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=10\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('Rice_Field_Damage_Philippines': conda)"
  },
  "interpreter": {
   "hash": "b367308e6f055391f859b515bbb645f6640c7b29224a7a1d3f6b55de7d9ef17f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}