{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook to obtain model performance\r\n",
    "\r\n",
    "In this notebook, all the different models are trained and tested to obtain optimal selected features, hyperparameters and performance scores. The models to obtain the selected features and performance estimate are called from separate scripts. For all models, Recursive Feature Elimination with Cross Validation (to find the optimal number of features) is applied on the full dataset. With the selected features, the performance is estimated (using Nested CV). In addition to comparing the performance scores of the models trained, the scores are also compared to a benchmark model.\r\n",
    "\r\n",
    "This notebook consists of three main sections:\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "Binary Classification <br>\r\n",
    "The models to perform a binary classification with threshold of 30% damage are trained and tested. \r\n",
    "\r\n",
    "Multiclass Classification <br>\r\n",
    "The models to perform multiclass classification with three classes are trained and tests.\r\n",
    "- 0 - 30%\r\n",
    "- 30% - 80%\r\n",
    "- 80% - 100%\r\n",
    "\r\n",
    "Regression <br>\r\n",
    "The models to obtain a continous prediction are trained and tested."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "from imblearn.pipeline import Pipeline\r\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\r\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\r\n",
    "from xgboost import XGBClassifier\r\n",
    "import os\r\n",
    "from sklearn.feature_selection import RFECV\r\n",
    "import pandas as pd\r\n",
    "from sklearn.model_selection import (\r\n",
    "    GridSearchCV,\r\n",
    "    RandomizedSearchCV,\r\n",
    "    StratifiedKFold,\r\n",
    "    KFold,\r\n",
    ")\r\n",
    "from sklearn.metrics import f1_score, mean_squared_error, mean_absolute_error\r\n",
    "import numpy as np\r\n",
    "from numpy.lib.function_base import average\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.metrics import (\r\n",
    "    recall_score,\r\n",
    "    f1_score,\r\n",
    "    precision_score,\r\n",
    "    confusion_matrix,\r\n",
    "    make_scorer,\r\n",
    ")\r\n",
    "from sklearn.model_selection import (\r\n",
    "    GridSearchCV,\r\n",
    "    RandomizedSearchCV,\r\n",
    "    StratifiedKFold,\r\n",
    "    KFold,\r\n",
    ")\r\n",
    "from sklearn.feature_selection import SelectKBest, SequentialFeatureSelector\r\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "from imblearn.pipeline import Pipeline\r\n",
    "import importlib\r\n",
    "import os\r\n",
    "from sklearn.feature_selection import (\r\n",
    "    SelectKBest,\r\n",
    "    RFE,\r\n",
    "    mutual_info_regression,\r\n",
    "    f_regression,\r\n",
    "    mutual_info_classif,\r\n",
    ")\r\n",
    "import eli5\r\n",
    "from eli5.sklearn import PermutationImportance\r\n",
    "from sklearn.inspection import permutation_importance\r\n",
    "import xgboost as xgb\r\n",
    "import random\r\n",
    "import pickle\r\n",
    "import openpyxl\r\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\r\n",
    "from sklearn.feature_selection import RFE\r\n",
    "from sklearn.feature_selection import RFECV\r\n",
    "import pickle\r\n",
    "from sklearn.linear_model import LinearRegression\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Local libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "# Setting path to the initial folder\r\n",
    "os.chdir(\"C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\")\r\n",
    "cdir = os.getcwd()\r\n",
    "import importlib\r\n",
    "\r\n",
    "# Binary classification functions\r\n",
    "from IBF_typhoon_model.models.binary_classification.xgb_binary import (\r\n",
    "    xgb_binary_features,\r\n",
    "    xgb_binary_performance,\r\n",
    ")\r\n",
    "from IBF_typhoon_model.models.binary_classification.rf_binary import (\r\n",
    "    rf_binary_features,\r\n",
    "    rf_binary_performance,\r\n",
    ")\r\n",
    "\r\n",
    "# Multiclass classification functions\r\n",
    "from IBF_typhoon_model.models.multiclass_classification.rf_multi import (\r\n",
    "    rf_multi_features,\r\n",
    "    rf_multi_performance,\r\n",
    ")\r\n",
    "from IBF_typhoon_model.models.multiclass_classification.xgb_multi import (\r\n",
    "    xgb_multi_features,\r\n",
    "    xgb_multi_performance,\r\n",
    ")\r\n",
    "\r\n",
    "# Regression functions\r\n",
    "from IBF_typhoon_model.models.regression.rf_regression import (\r\n",
    "    rf_regression_features,\r\n",
    "    rf_regression_performance,\r\n",
    ")\r\n",
    "from IBF_typhoon_model.models.regression.xgb_regression import (\r\n",
    "    xgb_regression_features,\r\n",
    "    xgb_regression_performance,\r\n",
    ")\r\n",
    "\r\n",
    "# Utility functions\r\n",
    "from IBF_typhoon_model.models.utility_functions.splitting_train_test import (\r\n",
    "    splitting_train_test,\r\n",
    ")\r\n",
    "from IBF_typhoon_model.models.utility_functions.determine_class import determine_class\r\n",
    "from IBF_typhoon_model.models.utility_functions.unweighted_random import (\r\n",
    "    unweighted_random,\r\n",
    ")\r\n",
    "from IBF_typhoon_model.models.utility_functions.weighted_random import weighted_random\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "# Input data: the sheet that contains all the processed input data\r\n",
    "name = \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\combined_input_data\\\\input_data_05.xlsx\"\r\n",
    "path = os.path.join(cdir, name)\r\n",
    "df = pd.read_excel(path, engine=\"openpyxl\")\r\n",
    "display(df.head(5))\r\n",
    "\r\n",
    "# Typhoon overview\r\n",
    "file_name = \"IBF_typhoon_model\\\\data\\\\data_overview.xlsx\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "df_typh_overview = pd.read_excel(path, sheet_name=\"typhoon_overview\", engine=\"openpyxl\")\r\n",
    "display(df_typh_overview.head(5))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mun_code</th>\n",
       "      <th>typhoon</th>\n",
       "      <th>area_affected</th>\n",
       "      <th>storm_id</th>\n",
       "      <th>year</th>\n",
       "      <th>reg_code</th>\n",
       "      <th>prov_code</th>\n",
       "      <th>rice_area</th>\n",
       "      <th>perc_loss</th>\n",
       "      <th>mean_slope</th>\n",
       "      <th>...</th>\n",
       "      <th>glat</th>\n",
       "      <th>glon</th>\n",
       "      <th>coast_peri_ratio</th>\n",
       "      <th>rainfall_max_6h</th>\n",
       "      <th>rainfall_max_24h</th>\n",
       "      <th>vmax</th>\n",
       "      <th>dis_track_min</th>\n",
       "      <th>perc_loss_new</th>\n",
       "      <th>damage_above_30</th>\n",
       "      <th>class_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PH142708000</td>\n",
       "      <td>goni2015</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015226N12151</td>\n",
       "      <td>2015</td>\n",
       "      <td>PH140000000</td>\n",
       "      <td>PH142700000</td>\n",
       "      <td>124.72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.35</td>\n",
       "      <td>...</td>\n",
       "      <td>7.475</td>\n",
       "      <td>124.58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.863333</td>\n",
       "      <td>2.347917</td>\n",
       "      <td>11.295801</td>\n",
       "      <td>271.221492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PH142708000</td>\n",
       "      <td>mangkhut2018</td>\n",
       "      <td>104.31</td>\n",
       "      <td>2018250N12170</td>\n",
       "      <td>2018</td>\n",
       "      <td>PH140000000</td>\n",
       "      <td>PH142700000</td>\n",
       "      <td>236.24</td>\n",
       "      <td>0.441542</td>\n",
       "      <td>6.89</td>\n",
       "      <td>...</td>\n",
       "      <td>7.483</td>\n",
       "      <td>124.71</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.861667</td>\n",
       "      <td>2.931250</td>\n",
       "      <td>22.718248</td>\n",
       "      <td>111.246866</td>\n",
       "      <td>0.441542</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PH142708000</td>\n",
       "      <td>molave2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020298N13131</td>\n",
       "      <td>2020</td>\n",
       "      <td>PH140000000</td>\n",
       "      <td>PH142700000</td>\n",
       "      <td>143.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>7.313</td>\n",
       "      <td>124.76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.805833</td>\n",
       "      <td>2.076875</td>\n",
       "      <td>3.590794</td>\n",
       "      <td>400.835034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PH142708000</td>\n",
       "      <td>usagi2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013259N17132</td>\n",
       "      <td>2013</td>\n",
       "      <td>PH140000000</td>\n",
       "      <td>PH142700000</td>\n",
       "      <td>126.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.21</td>\n",
       "      <td>...</td>\n",
       "      <td>6.710</td>\n",
       "      <td>124.46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.519167</td>\n",
       "      <td>1.859583</td>\n",
       "      <td>4.850429</td>\n",
       "      <td>389.636727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PH142708000</td>\n",
       "      <td>vamco2020</td>\n",
       "      <td>89.73</td>\n",
       "      <td>2020314N12131</td>\n",
       "      <td>2020</td>\n",
       "      <td>PH140000000</td>\n",
       "      <td>PH142700000</td>\n",
       "      <td>135.40</td>\n",
       "      <td>0.662703</td>\n",
       "      <td>13.79</td>\n",
       "      <td>...</td>\n",
       "      <td>5.785</td>\n",
       "      <td>125.34</td>\n",
       "      <td>0.458986</td>\n",
       "      <td>4.867500</td>\n",
       "      <td>2.057500</td>\n",
       "      <td>10.782503</td>\n",
       "      <td>199.648355</td>\n",
       "      <td>0.662703</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mun_code       typhoon  area_affected       storm_id  year     reg_code  \\\n",
       "0  PH142708000      goni2015           0.00  2015226N12151  2015  PH140000000   \n",
       "1  PH142708000  mangkhut2018         104.31  2018250N12170  2018  PH140000000   \n",
       "2  PH142708000    molave2020            NaN  2020298N13131  2020  PH140000000   \n",
       "3  PH142708000     usagi2013            NaN  2013259N17132  2013  PH140000000   \n",
       "4  PH142708000     vamco2020          89.73  2020314N12131  2020  PH140000000   \n",
       "\n",
       "     prov_code  rice_area  perc_loss  mean_slope  ...   glat    glon  \\\n",
       "0  PH142700000     124.72   0.000000       10.35  ...  7.475  124.58   \n",
       "1  PH142700000     236.24   0.441542        6.89  ...  7.483  124.71   \n",
       "2  PH142700000     143.32        NaN        5.48  ...  7.313  124.76   \n",
       "3  PH142700000     126.36        NaN        7.21  ...  6.710  124.46   \n",
       "4  PH142700000     135.40   0.662703       13.79  ...  5.785  125.34   \n",
       "\n",
       "   coast_peri_ratio  rainfall_max_6h  rainfall_max_24h       vmax  \\\n",
       "0          0.000000         2.863333          2.347917  11.295801   \n",
       "1          0.000000         5.861667          2.931250  22.718248   \n",
       "2          0.000000         6.805833          2.076875   3.590794   \n",
       "3          0.000000         3.519167          1.859583   4.850429   \n",
       "4          0.458986         4.867500          2.057500  10.782503   \n",
       "\n",
       "   dis_track_min  perc_loss_new  damage_above_30  class_old  \n",
       "0     271.221492       0.000000            False        0.0  \n",
       "1     111.246866       0.441542             True        1.0  \n",
       "2     400.835034            NaN            False        NaN  \n",
       "3     389.636727            NaN            False        NaN  \n",
       "4     199.648355       0.662703             True        1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagasa_name</th>\n",
       "      <th>unofficial_name</th>\n",
       "      <th>year</th>\n",
       "      <th>unofficial_name_year</th>\n",
       "      <th>name_year</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>landfall_date</th>\n",
       "      <th>landfall_time</th>\n",
       "      <th>storm_id</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aere</td>\n",
       "      <td>Bebeng</td>\n",
       "      <td>2011</td>\n",
       "      <td>Bebeng2011</td>\n",
       "      <td>aere2011</td>\n",
       "      <td>2011-05-05</td>\n",
       "      <td>2011-05-15</td>\n",
       "      <td>2011-05-07</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2011126N11129</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atsani</td>\n",
       "      <td>siony</td>\n",
       "      <td>2020</td>\n",
       "      <td>siony2020</td>\n",
       "      <td>atsani2020</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>2020304N08148</td>\n",
       "      <td>no landfall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bopha</td>\n",
       "      <td>pablo</td>\n",
       "      <td>2012</td>\n",
       "      <td>pablo2012</td>\n",
       "      <td>bopha2012</td>\n",
       "      <td>2012-11-25</td>\n",
       "      <td>2012-12-09</td>\n",
       "      <td>2012-12-03</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2012331N03157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>danas</td>\n",
       "      <td>falcon</td>\n",
       "      <td>2019</td>\n",
       "      <td>falcon2019</td>\n",
       "      <td>danas2019</td>\n",
       "      <td>2019-07-14</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>2019195N13136</td>\n",
       "      <td>no landfall in PH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>durian</td>\n",
       "      <td>reming</td>\n",
       "      <td>2006</td>\n",
       "      <td>reming2006</td>\n",
       "      <td>durian2006</td>\n",
       "      <td>2006-11-24</td>\n",
       "      <td>2006-12-09</td>\n",
       "      <td>2006-11-30</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2006329N06150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pagasa_name unofficial_name  year unofficial_name_year   name_year  \\\n",
       "0        aere          Bebeng  2011           Bebeng2011    aere2011   \n",
       "1      atsani           siony  2020            siony2020  atsani2020   \n",
       "2       bopha           pablo  2012            pablo2012   bopha2012   \n",
       "3       danas          falcon  2019           falcon2019   danas2019   \n",
       "4      durian          reming  2006           reming2006  durian2006   \n",
       "\n",
       "  start_date   end_date landfall_date landfall_time       storm_id  \\\n",
       "0 2011-05-05 2011-05-15    2011-05-07      21:00:00  2011126N11129   \n",
       "1 2020-10-29 2020-11-07    2020-11-06      00:00:00  2020304N08148   \n",
       "2 2012-11-25 2012-12-09    2012-12-03      21:00:00  2012331N03157   \n",
       "3 2019-07-14 2019-07-23    2019-07-17      00:00:00  2019195N13136   \n",
       "4 2006-11-24 2006-12-09    2006-11-30      06:00:00  2006329N06150   \n",
       "\n",
       "         Unnamed: 10  \n",
       "0                NaN  \n",
       "1        no landfall  \n",
       "2                NaN  \n",
       "3  no landfall in PH  \n",
       "4                NaN  "
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "# Selecting the features to be used: should be available for historical and future typhoons\r\n",
    "features = [\r\n",
    "    \"mean_slope\",\r\n",
    "    \"mean_elevation_m\",\r\n",
    "    \"ruggedness_stdev\",\r\n",
    "    \"mean_ruggedness\",\r\n",
    "    \"slope_stdev\",\r\n",
    "    \"area_km2\",\r\n",
    "    \"poverty_perc\",\r\n",
    "    \"with_coast\",\r\n",
    "    \"coast_length\",\r\n",
    "    \"perimeter\",\r\n",
    "    \"glat\",\r\n",
    "    \"glon\",\r\n",
    "    \"coast_peri_ratio\",\r\n",
    "    \"rainfall_max_6h\",\r\n",
    "    \"rainfall_max_24h\",\r\n",
    "    \"dis_track_min\",\r\n",
    "    \"vmax\",\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binary Classification\r\n",
    "\r\n",
    "This section obtain the optimal Binary Classification models and the performance estimates, for a 30% threshold. Two models are implemented: Random Forest Classifier, XGBoost Classifier. First, the model is trained on the full dataset to obtain the optimal features followed by a model that obtains the performance estimate using Nested Cross Validation. \r\n",
    "\r\n",
    "- Performance Metric\r\n",
    "- Nested Cross Validation\r\n",
    "- Benchmark Models\r\n",
    "- Main findings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# Setting the general input variables: for the dataframe with threshold 30\r\n",
    "# Contorplot threshold was used to create damage_above_30 variable\r\n",
    "df_binary = df[df['damage_above_30'].notnull()]\r\n",
    "df_binary[\"class_value_binary\"] = [\r\n",
    "    1 if df_binary[\"damage_above_30\"][i] == True else 0 for i in range(len(df_binary))\r\n",
    "]\r\n",
    "\r\n",
    "# Setting for feature selection on full data set\r\n",
    "X = df_binary[features]\r\n",
    "y = df_binary[\"class_value_binary\"]\r\n",
    "y = y.astype(int)\r\n",
    "\r\n",
    "# Setting the train and the test sets for obtaining performance estimate\r\n",
    "df_train_list, df_test_list = splitting_train_test(df_binary)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtain features and optimal hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of selected features RF Binary: 3\r\n",
    "\r\n",
    "Selected features RF Binary:\r\n",
    "- rainfall_max_6h\r\n",
    "- dis_track_min\r\n",
    "- vmax\r\n",
    "\r\n",
    "\r\n",
    "Selected parameters RF Binary:\r\n",
    "- max_depth = 20\r\n",
    "- min_samples_leaf = 5\r\n",
    "- min_samples_split = 15\r\n",
    "- n_estimators = 250\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Setting the random forest search grid\r\n",
    "rf_search_space = [\r\n",
    "    {\r\n",
    "        \"estimator__n_estimators\": [100, 250],\r\n",
    "        \"estimator__max_depth\": [20, None],\r\n",
    "        \"estimator__min_samples_split\": [2, 8, 10, 15],\r\n",
    "        \"estimator__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "# Obtaining the selected features based on the full dataset\r\n",
    "selected_features_rf_binary, selected_params_rf_binary_full = rf_binary_features(\r\n",
    "    X=X,\r\n",
    "    y=y,\r\n",
    "    features=features,\r\n",
    "    search_space=rf_search_space,\r\n",
    "    cv_splits=5,\r\n",
    "    class_weight=\"balanced\",\r\n",
    "    min_features_to_select=1,\r\n",
    "    GS_score=\"f1\",\r\n",
    "    GS_randomized=False,\r\n",
    "    GS_n_iter=10,\r\n",
    "    verbose=10,\r\n",
    ")\r\n",
    "\r\n",
    "print(f\"Number of selected features RF Binary: {len(selected_features_rf_binary)}\")\r\n",
    "print(f\"Selected features RF Binary: {selected_features_rf_binary}\")\r\n",
    "print(f\"Selected Parameters RF Binary {selected_params_rf_binary_full}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5; 1/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 1/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.597) total time=  56.3s\n",
      "[CV 2/5; 1/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 1/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.588) total time=  56.0s\n",
      "[CV 3/5; 1/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 1/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.998, test=0.588) total time=  56.4s\n",
      "[CV 4/5; 1/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 1/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.546) total time=  52.2s\n",
      "[CV 5/5; 1/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 1/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.534) total time=  54.5s\n",
      "[CV 1/5; 2/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 2/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=1.000, test=0.583) total time= 2.3min\n",
      "[CV 2/5; 2/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 2/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=1.000, test=0.595) total time= 2.3min\n",
      "[CV 3/5; 2/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 2/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.999, test=0.586) total time= 2.6min\n",
      "[CV 4/5; 2/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 2/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=1.000, test=0.515) total time= 2.7min\n",
      "[CV 5/5; 2/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 2/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=1.000, test=0.586) total time= 2.5min\n",
      "[CV 1/5; 3/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 3/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.934, test=0.604) total time=  52.1s\n",
      "[CV 2/5; 3/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 3/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.940, test=0.622) total time=  58.1s\n",
      "[CV 3/5; 3/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 3/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.928, test=0.604) total time= 1.1min\n",
      "[CV 4/5; 3/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 3/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.969, test=0.592) total time=  54.7s\n",
      "[CV 5/5; 3/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 3/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.935, test=0.609) total time=  57.5s\n",
      "[CV 1/5; 4/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 4/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.936, test=0.616) total time= 2.4min\n",
      "[CV 2/5; 4/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 4/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.945, test=0.631) total time= 2.2min\n",
      "[CV 3/5; 4/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 4/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.934, test=0.605) total time= 2.3min\n",
      "[CV 4/5; 4/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 4/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.981, test=0.574) total time= 2.1min\n",
      "[CV 5/5; 4/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 4/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.932, test=0.616) total time= 2.4min\n",
      "[CV 1/5; 5/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 5/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.905, test=0.610) total time=  57.9s\n",
      "[CV 2/5; 5/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 5/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.918, test=0.634) total time=  53.2s\n",
      "[CV 3/5; 5/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 5/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.903, test=0.603) total time=  48.3s\n",
      "[CV 4/5; 5/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 5/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.911, test=0.629) total time=  47.8s\n",
      "[CV 5/5; 5/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 5/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.906, test=0.621) total time=  48.3s\n",
      "[CV 1/5; 6/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 6/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.913, test=0.624) total time= 2.2min\n",
      "[CV 2/5; 6/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 6/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.919, test=0.636) total time= 2.6min\n",
      "[CV 3/5; 6/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 6/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.904, test=0.588) total time= 2.6min\n",
      "[CV 4/5; 6/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 6/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.915, test=0.630) total time= 2.6min\n",
      "[CV 5/5; 6/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 6/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.907, test=0.610) total time= 2.6min\n",
      "[CV 1/5; 7/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 7/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.854, test=0.624) total time= 1.0min\n",
      "[CV 2/5; 7/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 7/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.864, test=0.657) total time= 1.0min\n",
      "[CV 3/5; 7/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 7/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.849, test=0.609) total time= 1.0min\n",
      "[CV 4/5; 7/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 7/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.863, test=0.625) total time= 1.0min\n",
      "[CV 5/5; 7/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 7/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.855, test=0.638) total time= 1.0min\n",
      "[CV 1/5; 8/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 1/5; 8/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.864, test=0.629) total time= 2.5min\n",
      "[CV 2/5; 8/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 2/5; 8/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.870, test=0.653) total time= 2.6min\n",
      "[CV 3/5; 8/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 3/5; 8/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.851, test=0.602) total time= 2.6min\n",
      "[CV 4/5; 8/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 4/5; 8/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.860, test=0.633) total time= 2.6min\n",
      "[CV 5/5; 8/48] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 5/5; 8/48] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.855, test=0.642) total time= 2.6min\n",
      "[CV 1/5; 9/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 9/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.907, test=0.631) total time=  51.9s\n",
      "[CV 2/5; 9/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 9/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.905, test=0.628) total time=  52.9s\n",
      "[CV 3/5; 9/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 9/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.896, test=0.589) total time= 1.1min\n",
      "[CV 4/5; 9/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 9/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.955, test=0.565) total time=  58.1s\n",
      "[CV 5/5; 9/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 9/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.899, test=0.634) total time=  56.6s\n",
      "[CV 1/5; 10/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 10/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.907, test=0.612) total time= 2.6min\n",
      "[CV 2/5; 10/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 10/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.910, test=0.626) total time= 2.2min\n",
      "[CV 3/5; 10/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 10/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.898, test=0.593) total time= 2.9min\n",
      "[CV 4/5; 10/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 10/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.907, test=0.622) total time= 3.5min\n",
      "[CV 5/5; 10/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 10/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.904, test=0.625) total time= 2.8min\n",
      "[CV 1/5; 11/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 11/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.883, test=0.623) total time=  49.2s\n",
      "[CV 2/5; 11/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 11/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.891, test=0.633) total time=  57.0s\n",
      "[CV 3/5; 11/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 11/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.882, test=0.593) total time= 1.2min\n",
      "[CV 4/5; 11/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 11/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.944, test=0.592) total time= 1.2min\n",
      "[CV 5/5; 11/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 11/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.880, test=0.631) total time= 1.2min\n",
      "[CV 1/5; 12/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 12/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.893, test=0.630) total time= 3.9min\n",
      "[CV 2/5; 12/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 12/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.903, test=0.640) total time= 2.7min\n",
      "[CV 3/5; 12/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 12/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.883, test=0.602) total time= 2.2min\n",
      "[CV 4/5; 12/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 12/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.894, test=0.628) total time= 2.9min\n",
      "[CV 5/5; 12/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 12/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.884, test=0.641) total time= 3.2min\n",
      "[CV 1/5; 13/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 13/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.867, test=0.625) total time= 1.3min\n",
      "[CV 2/5; 13/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 13/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.881, test=0.634) total time=  59.4s\n",
      "[CV 3/5; 13/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 13/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.866, test=0.594) total time=  57.3s\n",
      "[CV 4/5; 13/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 13/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.928, test=0.587) total time=  49.3s\n",
      "[CV 5/5; 13/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 13/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.868, test=0.646) total time=  54.1s\n",
      "[CV 1/5; 14/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 14/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.870, test=0.630) total time= 2.3min\n",
      "[CV 2/5; 14/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 14/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.882, test=0.648) total time= 2.3min\n",
      "[CV 3/5; 14/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 14/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.864, test=0.607) total time= 2.8min\n",
      "[CV 4/5; 14/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 14/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.925, test=0.577) total time= 3.4min\n",
      "[CV 5/5; 14/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 14/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.872, test=0.632) total time= 3.1min\n",
      "[CV 1/5; 15/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 15/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.830, test=0.625) total time=  52.8s\n",
      "[CV 2/5; 15/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 15/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.842, test=0.647) total time=  47.3s\n",
      "[CV 3/5; 15/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 15/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.824, test=0.613) total time=  48.3s\n",
      "[CV 4/5; 15/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 15/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.830, test=0.633) total time=  48.1s\n",
      "[CV 5/5; 15/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 15/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.835, test=0.653) total time= 1.0min\n",
      "[CV 1/5; 16/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 1/5; 16/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.833, test=0.629) total time= 2.8min\n",
      "[CV 2/5; 16/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 2/5; 16/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.835, test=0.649) total time= 4.2min\n",
      "[CV 3/5; 16/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 3/5; 16/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.830, test=0.601) total time= 3.4min\n",
      "[CV 4/5; 16/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 4/5; 16/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.835, test=0.646) total time= 2.4min\n",
      "[CV 5/5; 16/48] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 5/5; 16/48] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.835, test=0.631) total time= 2.6min\n",
      "[CV 1/5; 17/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 17/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.830, test=0.638) total time= 1.1min\n",
      "[CV 2/5; 17/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 17/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.838, test=0.656) total time= 1.3min\n",
      "[CV 3/5; 17/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 17/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.825, test=0.614) total time= 1.5min\n",
      "[CV 4/5; 17/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 17/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.894, test=0.602) total time= 1.3min\n",
      "[CV 5/5; 17/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 17/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.823, test=0.636) total time= 1.3min\n",
      "[CV 1/5; 18/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 18/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.833, test=0.634) total time= 3.3min\n",
      "[CV 2/5; 18/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 18/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.843, test=0.647) total time= 3.7min\n",
      "[CV 3/5; 18/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 18/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.826, test=0.607) total time= 4.3min\n",
      "[CV 4/5; 18/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 18/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.832, test=0.639) total time= 2.7min\n",
      "[CV 5/5; 18/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 18/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.830, test=0.652) total time= 3.1min\n",
      "[CV 1/5; 19/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 19/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.833, test=0.638) total time= 1.9min\n",
      "[CV 2/5; 19/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 19/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.839, test=0.650) total time= 1.9min\n",
      "[CV 3/5; 19/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 19/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.825, test=0.607) total time= 1.9min\n",
      "[CV 4/5; 19/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 19/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.898, test=0.612) total time= 1.8min\n",
      "[CV 5/5; 19/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 19/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.830, test=0.637) total time= 2.0min\n",
      "[CV 1/5; 20/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 20/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.834, test=0.630) total time= 4.5min\n",
      "[CV 2/5; 20/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 20/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.842, test=0.646) total time= 3.7min\n",
      "[CV 3/5; 20/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 20/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.824, test=0.601) total time= 5.0min\n",
      "[CV 4/5; 20/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 20/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.887, test=0.598) total time= 3.4min\n",
      "[CV 5/5; 20/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 20/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.831, test=0.636) total time= 3.0min\n",
      "[CV 1/5; 21/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 21/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.825, test=0.634) total time= 2.0min\n",
      "[CV 2/5; 21/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 21/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.835, test=0.660) total time= 1.7min\n",
      "[CV 3/5; 21/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 21/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.823, test=0.596) total time= 1.6min\n",
      "[CV 4/5; 21/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 21/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.831, test=0.648) total time= 1.3min\n",
      "[CV 5/5; 21/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 21/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.832, test=0.643) total time= 1.0min\n",
      "[CV 1/5; 22/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 22/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.832, test=0.638) total time= 2.2min\n",
      "[CV 2/5; 22/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 22/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.842, test=0.649) total time= 2.3min\n",
      "[CV 3/5; 22/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 22/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.830, test=0.607) total time= 2.4min\n",
      "[CV 4/5; 22/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 22/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.885, test=0.586) total time= 2.2min\n",
      "[CV 5/5; 22/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 22/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.832, test=0.650) total time= 1.9min\n",
      "[CV 1/5; 23/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 23/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.810, test=0.643) total time=  45.5s\n",
      "[CV 2/5; 23/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 23/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.815, test=0.650) total time=  51.2s\n",
      "[CV 3/5; 23/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 23/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.801, test=0.609) total time= 1.0min\n",
      "[CV 4/5; 23/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 23/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.810, test=0.643) total time=  55.4s\n",
      "[CV 5/5; 23/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 23/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.807, test=0.631) total time= 1.1min\n",
      "[CV 1/5; 24/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 1/5; 24/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.814, test=0.627) total time= 2.5min\n",
      "[CV 2/5; 24/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 2/5; 24/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.817, test=0.649) total time= 2.5min\n",
      "[CV 3/5; 24/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 3/5; 24/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.809, test=0.610) total time= 2.4min\n",
      "[CV 4/5; 24/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 4/5; 24/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.806, test=0.654) total time= 2.2min\n",
      "[CV 5/5; 24/48] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 5/5; 24/48] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.810, test=0.654) total time= 1.9min\n",
      "[CV 1/5; 25/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 25/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.585) total time= 1.0min\n",
      "[CV 2/5; 25/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 25/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.567) total time= 1.0min\n",
      "[CV 3/5; 25/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 25/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.578) total time=  58.7s\n",
      "[CV 4/5; 25/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 25/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.524) total time=  58.6s\n",
      "[CV 5/5; 25/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 25/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.588) total time= 1.1min\n",
      "[CV 1/5; 26/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 26/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=1.000, test=0.591) total time= 2.8min\n",
      "[CV 2/5; 26/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 26/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=1.000, test=0.591) total time= 2.8min\n",
      "[CV 3/5; 26/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 26/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=1.000, test=0.583) total time= 2.9min\n",
      "[CV 4/5; 26/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 26/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=1.000, test=0.513) total time= 2.1min\n",
      "[CV 5/5; 26/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 26/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=1.000, test=0.592) total time= 2.4min\n",
      "[CV 1/5; 27/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 27/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.944, test=0.596) total time=  53.8s\n",
      "[CV 2/5; 27/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 27/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.948, test=0.630) total time=  59.5s\n",
      "[CV 3/5; 27/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 27/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.938, test=0.611) total time=  56.7s\n",
      "[CV 4/5; 27/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 27/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.947, test=0.616) total time=  57.6s\n",
      "[CV 5/5; 27/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 27/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.979, test=0.575) total time=  55.6s\n",
      "[CV 1/5; 28/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 28/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.946, test=0.604) total time= 2.6min\n",
      "[CV 2/5; 28/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 28/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.948, test=0.636) total time= 2.7min\n",
      "[CV 3/5; 28/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 28/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.944, test=0.603) total time= 2.8min\n",
      "[CV 4/5; 28/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 28/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.981, test=0.562) total time= 2.6min\n",
      "[CV 5/5; 28/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 28/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.944, test=0.613) total time= 2.4min\n",
      "[CV 1/5; 29/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 29/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.908, test=0.611) total time=  54.3s\n",
      "[CV 2/5; 29/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 29/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.921, test=0.627) total time=  58.3s\n",
      "[CV 3/5; 29/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 29/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.908, test=0.604) total time= 1.1min\n",
      "[CV 4/5; 29/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 29/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.964, test=0.578) total time=  55.4s\n",
      "[CV 5/5; 29/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 29/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.914, test=0.617) total time= 1.0min\n",
      "[CV 1/5; 30/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 30/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.918, test=0.618) total time= 2.5min\n",
      "[CV 2/5; 30/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 30/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.923, test=0.639) total time= 2.6min\n",
      "[CV 3/5; 30/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 30/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.912, test=0.601) total time= 2.4min\n",
      "[CV 4/5; 30/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 30/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.917, test=0.611) total time= 2.2min\n",
      "[CV 5/5; 30/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 30/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.918, test=0.631) total time= 2.4min\n",
      "[CV 1/5; 31/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 31/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.860, test=0.625) total time=  50.4s\n",
      "[CV 2/5; 31/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 31/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.871, test=0.648) total time=  52.1s\n",
      "[CV 3/5; 31/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 31/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.865, test=0.588) total time=  54.2s\n",
      "[CV 4/5; 31/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 31/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.924, test=0.560) total time=  47.9s\n",
      "[CV 5/5; 31/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 31/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.866, test=0.626) total time=  48.1s\n",
      "[CV 1/5; 32/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 1/5; 32/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.865, test=0.631) total time= 2.2min\n",
      "[CV 2/5; 32/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 2/5; 32/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.874, test=0.655) total time= 2.3min\n",
      "[CV 3/5; 32/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 3/5; 32/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.857, test=0.595) total time= 2.2min\n",
      "[CV 4/5; 32/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 4/5; 32/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.864, test=0.635) total time= 2.4min\n",
      "[CV 5/5; 32/48] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 5/5; 32/48] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.864, test=0.634) total time= 2.6min\n",
      "[CV 1/5; 33/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 33/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.909, test=0.621) total time=  55.6s\n",
      "[CV 2/5; 33/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 33/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.914, test=0.633) total time= 1.0min\n",
      "[CV 3/5; 33/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 33/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.901, test=0.593) total time= 1.1min\n",
      "[CV 4/5; 33/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 33/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.959, test=0.594) total time= 1.0min\n",
      "[CV 5/5; 33/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 33/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.904, test=0.633) total time= 1.0min\n",
      "[CV 1/5; 34/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 34/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.910, test=0.618) total time= 2.5min\n",
      "[CV 2/5; 34/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 34/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.910, test=0.639) total time= 2.4min\n",
      "[CV 3/5; 34/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 34/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.908, test=0.603) total time= 2.7min\n",
      "[CV 4/5; 34/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 34/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.907, test=0.624) total time= 2.4min\n",
      "[CV 5/5; 34/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 34/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.905, test=0.622) total time= 2.7min\n",
      "[CV 1/5; 35/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 35/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.889, test=0.621) total time=  49.7s\n",
      "[CV 2/5; 35/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 35/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.896, test=0.645) total time=  49.0s\n",
      "[CV 3/5; 35/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 35/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.884, test=0.594) total time=  49.9s\n",
      "[CV 4/5; 35/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 35/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.891, test=0.628) total time=  51.5s\n",
      "[CV 5/5; 35/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 35/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.886, test=0.634) total time=  53.0s\n",
      "[CV 1/5; 36/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 36/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.891, test=0.620) total time= 2.2min\n",
      "[CV 2/5; 36/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 36/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.905, test=0.637) total time= 2.4min\n",
      "[CV 3/5; 36/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 36/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.892, test=0.601) total time= 2.3min\n",
      "[CV 4/5; 36/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 36/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.894, test=0.617) total time= 2.3min\n",
      "[CV 5/5; 36/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 36/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.885, test=0.632) total time= 2.2min\n",
      "[CV 1/5; 37/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 37/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.870, test=0.624) total time=  50.8s\n",
      "[CV 2/5; 37/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 37/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.886, test=0.641) total time=  50.7s\n",
      "[CV 3/5; 37/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 37/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.866, test=0.593) total time=  51.5s\n",
      "[CV 4/5; 37/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 37/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.870, test=0.629) total time=  50.4s\n",
      "[CV 5/5; 37/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 37/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.870, test=0.637) total time= 1.1min\n",
      "[CV 1/5; 38/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 38/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.875, test=0.620) total time= 2.3min\n",
      "[CV 2/5; 38/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 38/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.887, test=0.640) total time= 2.2min\n",
      "[CV 3/5; 38/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 38/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.871, test=0.596) total time= 2.0min\n",
      "[CV 4/5; 38/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 38/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.874, test=0.633) total time= 2.0min\n",
      "[CV 5/5; 38/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 38/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.868, test=0.636) total time= 2.2min\n",
      "[CV 1/5; 39/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 39/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.840, test=0.629) total time=  49.5s\n",
      "[CV 2/5; 39/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 39/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.845, test=0.642) total time=  51.8s\n",
      "[CV 3/5; 39/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 39/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.835, test=0.601) total time=  55.8s\n",
      "[CV 4/5; 39/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 39/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.842, test=0.637) total time=  54.2s\n",
      "[CV 5/5; 39/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 39/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.834, test=0.645) total time=  56.4s\n",
      "[CV 1/5; 40/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 1/5; 40/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.839, test=0.629) total time= 2.0min\n",
      "[CV 2/5; 40/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 2/5; 40/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.849, test=0.660) total time= 2.1min\n",
      "[CV 3/5; 40/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 3/5; 40/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.835, test=0.601) total time= 2.0min\n",
      "[CV 4/5; 40/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 4/5; 40/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.840, test=0.645) total time= 2.1min\n",
      "[CV 5/5; 40/48] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 5/5; 40/48] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.837, test=0.648) total time= 2.3min\n",
      "[CV 1/5; 41/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 41/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.832, test=0.634) total time=  49.3s\n",
      "[CV 2/5; 41/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 41/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.842, test=0.647) total time=  52.5s\n",
      "[CV 3/5; 41/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 41/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.830, test=0.613) total time=  50.8s\n",
      "[CV 4/5; 41/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 41/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.892, test=0.598) total time=  44.4s\n",
      "[CV 5/5; 41/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 41/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.827, test=0.635) total time=  54.8s\n",
      "[CV 1/5; 42/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 42/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.838, test=0.631) total time= 1.9min\n",
      "[CV 2/5; 42/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 42/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.843, test=0.645) total time= 2.0min\n",
      "[CV 3/5; 42/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 42/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.831, test=0.606) total time= 2.0min\n",
      "[CV 4/5; 42/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 42/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.840, test=0.642) total time= 1.9min\n",
      "[CV 5/5; 42/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 42/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=0.833, test=0.650) total time= 2.0min\n",
      "[CV 1/5; 43/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 43/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.828, test=0.633) total time=  46.6s\n",
      "[CV 2/5; 43/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 43/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.839, test=0.644) total time=  46.9s\n",
      "[CV 3/5; 43/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 43/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.827, test=0.603) total time=  46.8s\n",
      "[CV 4/5; 43/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 43/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.837, test=0.640) total time=  53.3s\n",
      "[CV 5/5; 43/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 43/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=0.833, test=0.649) total time=  46.6s\n",
      "[CV 1/5; 44/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 44/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.833, test=0.632) total time= 1.9min\n",
      "[CV 2/5; 44/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 44/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.843, test=0.654) total time= 2.5min\n",
      "[CV 3/5; 44/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 44/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.826, test=0.604) total time= 3.7min\n",
      "[CV 4/5; 44/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 44/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.899, test=0.594) total time= 4.7min\n",
      "[CV 5/5; 44/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 44/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=0.832, test=0.634) total time= 5.1min\n",
      "[CV 1/5; 45/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 45/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.837, test=0.636) total time= 2.1min\n",
      "[CV 2/5; 45/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 45/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.838, test=0.648) total time=  50.2s\n",
      "[CV 3/5; 45/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 45/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.825, test=0.614) total time=  46.9s\n",
      "[CV 4/5; 45/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 45/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.882, test=0.615) total time= 1.5min\n",
      "[CV 5/5; 45/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 45/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.831, test=0.640) total time= 1.1min\n",
      "[CV 1/5; 46/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 46/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.835, test=0.627) total time= 2.4min\n",
      "[CV 2/5; 46/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 46/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.841, test=0.648) total time= 1.9min\n",
      "[CV 3/5; 46/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 46/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.828, test=0.610) total time= 1.9min\n",
      "[CV 4/5; 46/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 46/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.834, test=0.636) total time= 1.9min\n",
      "[CV 5/5; 46/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 46/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=0.832, test=0.632) total time= 1.9min\n",
      "[CV 1/5; 47/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 47/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.811, test=0.630) total time=  45.5s\n",
      "[CV 2/5; 47/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 47/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.815, test=0.653) total time=  45.4s\n",
      "[CV 3/5; 47/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 47/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.804, test=0.612) total time=  45.4s\n",
      "[CV 4/5; 47/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 47/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.858, test=0.614) total time=  48.1s\n",
      "[CV 5/5; 47/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 47/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.811, test=0.629) total time=  51.5s\n",
      "[CV 1/5; 48/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 1/5; 48/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.813, test=0.637) total time= 2.1min\n",
      "[CV 2/5; 48/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 2/5; 48/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.819, test=0.658) total time= 2.1min\n",
      "[CV 3/5; 48/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 3/5; 48/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.806, test=0.615) total time= 2.1min\n",
      "[CV 4/5; 48/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 4/5; 48/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.809, test=0.636) total time= 2.2min\n",
      "[CV 5/5; 48/48] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250\n",
      "[CV 5/5; 48/48] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=250;, score=(train=0.810, test=0.646) total time= 2.1min\n",
      "Number of selected features RF Binary: 3\n",
      "Selected features RF Binary: ['rainfall_max_6h', 'dis_track_min', 'vmax']\n",
      "Selected Parameters RF Binary {'estimator__max_depth': 20, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 15, 'estimator__n_estimators': 250}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtaining performance estimate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Setting the selected features for RF --> based on outcome in previous cell\r\n",
    "selected_features_rf_binary = [\r\n",
    "    \"rice_area\",\r\n",
    "    \"mean_slope\",\r\n",
    "    \"mean_elevation_m\",\r\n",
    "    \"ruggedness_stdev\",\r\n",
    "    \"mean_ruggedness\",\r\n",
    "    \"slope_stdev\",\r\n",
    "    \"area_km2\",\r\n",
    "    \"poverty_perc\",\r\n",
    "    \"with_coast\",\r\n",
    "    \"coast_length\",\r\n",
    "    \"perimeter\",\r\n",
    "    \"glat\",\r\n",
    "    \"glon\",\r\n",
    "    \"coast_peri_ratio\",\r\n",
    "    \"rainfall_sum\",\r\n",
    "    \"rainfall_max\",\r\n",
    "    \"dis_track_min\",\r\n",
    "    \"vmax_sust\",\r\n",
    "]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Setting the random forest search grid\r\n",
    "rf_search_space = [\r\n",
    "    {\r\n",
    "        \"rf__n_estimators\": [100, 250],\r\n",
    "        \"rf__max_depth\": [20, None],\r\n",
    "        \"rf__min_samples_split\": [2, 8, 15],\r\n",
    "        \"rf__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "# Obtaining the performance estimate\r\n",
    "df_predicted_rf_binary, selected_params_rf_binary = rf_binary_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    features=selected_features_rf_binary,\r\n",
    "    search_space=rf_search_space,\r\n",
    "    stratK=True,\r\n",
    "    cv_splits=5,\r\n",
    "    class_weight=\"balanced\",\r\n",
    "    GS_score=\"f1\",\r\n",
    "    GS_randomized=False,\r\n",
    "    GS_n_iter=10,\r\n",
    "    verbose=10,\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running for 1 out of a total of 5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.598) total time=   0.2s\n",
      "[CV 2/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.599) total time=   0.2s\n",
      "[CV 3/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.638) total time=   0.2s\n",
      "[CV 4/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.620) total time=   0.2s\n",
      "[CV 5/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.632) total time=   0.2s\n",
      "[CV 1/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.593) total time=   0.7s\n",
      "[CV 2/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.592) total time=   0.7s\n",
      "[CV 3/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.628) total time=   0.7s\n",
      "[CV 4/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.624) total time=   0.7s\n",
      "[CV 5/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.614) total time=   0.7s\n",
      "[CV 1/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.937, test=0.632) total time=   0.2s\n",
      "[CV 2/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.945, test=0.622) total time=   0.2s\n",
      "[CV 3/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.945, test=0.633) total time=   0.2s\n",
      "[CV 4/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.941, test=0.614) total time=   0.2s\n",
      "[CV 5/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.948, test=0.617) total time=   0.2s\n",
      "[CV 1/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.944, test=0.624) total time=   0.7s\n",
      "[CV 2/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.945, test=0.608) total time=   0.6s\n",
      "[CV 3/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.944, test=0.635) total time=   0.6s\n",
      "[CV 4/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.944, test=0.630) total time=   0.6s\n",
      "[CV 5/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.953, test=0.647) total time=   0.7s\n",
      "[CV 1/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.864, test=0.636) total time=   0.2s\n",
      "[CV 2/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.884, test=0.626) total time=   0.2s\n",
      "[CV 3/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.871, test=0.630) total time=   0.2s\n",
      "[CV 4/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.870, test=0.623) total time=   0.2s\n",
      "[CV 5/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.874, test=0.656) total time=   0.2s\n",
      "[CV 1/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.867, test=0.647) total time=   0.6s\n",
      "[CV 2/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.883, test=0.634) total time=   0.6s\n",
      "[CV 3/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.882, test=0.639) total time=   0.6s\n",
      "[CV 4/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.875, test=0.641) total time=   0.6s\n",
      "[CV 5/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.882, test=0.663) total time=   0.6s\n",
      "[CV 1/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.918, test=0.633) total time=   0.2s\n",
      "[CV 2/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.914, test=0.639) total time=   0.2s\n",
      "[CV 3/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.911, test=0.639) total time=   0.2s\n",
      "[CV 4/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.911, test=0.636) total time=   0.2s\n",
      "[CV 5/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.920, test=0.630) total time=   0.2s\n",
      "[CV 1/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.917, test=0.625) total time=   0.6s\n",
      "[CV 2/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.916, test=0.634) total time=   0.7s\n",
      "[CV 3/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.913, test=0.626) total time=   0.6s\n",
      "[CV 4/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.910, test=0.639) total time=   0.6s\n",
      "[CV 5/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.920, test=0.665) total time=   0.6s\n",
      "[CV 1/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.895, test=0.623) total time=   0.2s\n",
      "[CV 2/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.908, test=0.610) total time=   0.2s\n",
      "[CV 3/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.903, test=0.634) total time=   0.2s\n",
      "[CV 4/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.890, test=0.638) total time=   0.2s\n",
      "[CV 5/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.902, test=0.636) total time=   0.2s\n",
      "[CV 1/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.895, test=0.628) total time=   0.6s\n",
      "[CV 2/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.907, test=0.640) total time=   0.6s\n",
      "[CV 3/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.903, test=0.647) total time=   0.6s\n",
      "[CV 4/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.896, test=0.647) total time=   0.7s\n",
      "[CV 5/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.904, test=0.645) total time=   0.6s\n",
      "[CV 1/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.851, test=0.645) total time=   0.2s\n",
      "[CV 2/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.855, test=0.642) total time=   0.2s\n",
      "[CV 3/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.855, test=0.629) total time=   0.2s\n",
      "[CV 4/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.852, test=0.663) total time=   0.2s\n",
      "[CV 5/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.857, test=0.647) total time=   0.2s\n",
      "[CV 1/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.853, test=0.643) total time=   0.6s\n",
      "[CV 2/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.857, test=0.644) total time=   0.6s\n",
      "[CV 3/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.853, test=0.636) total time=   0.6s\n",
      "[CV 4/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.851, test=0.647) total time=   0.6s\n",
      "[CV 5/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.860, test=0.665) total time=   0.6s\n",
      "[CV 1/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.843, test=0.643) total time=   0.2s\n",
      "[CV 2/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.849, test=0.632) total time=   0.2s\n",
      "[CV 3/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.851, test=0.620) total time=   0.2s\n",
      "[CV 4/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.843, test=0.654) total time=   0.2s\n",
      "[CV 5/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.854, test=0.659) total time=   0.2s\n",
      "[CV 1/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.844, test=0.649) total time=   0.6s\n",
      "[CV 2/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.854, test=0.665) total time=   0.6s\n",
      "[CV 3/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.857, test=0.645) total time=   0.6s\n",
      "[CV 4/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.852, test=0.649) total time=   0.6s\n",
      "[CV 5/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.860, test=0.652) total time=   0.6s\n",
      "[CV 1/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.836, test=0.633) total time=   0.2s\n",
      "[CV 2/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.852, test=0.638) total time=   0.2s\n",
      "[CV 3/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.847, test=0.650) total time=   0.2s\n",
      "[CV 4/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.839, test=0.642) total time=   0.2s\n",
      "[CV 5/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.845, test=0.654) total time=   0.2s\n",
      "[CV 1/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.840, test=0.656) total time=   0.6s\n",
      "[CV 2/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.849, test=0.636) total time=   0.6s\n",
      "[CV 3/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.852, test=0.627) total time=   0.6s\n",
      "[CV 4/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.845, test=0.646) total time=   0.6s\n",
      "[CV 5/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.854, test=0.652) total time=   0.6s\n",
      "[CV 1/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.825, test=0.660) total time=   0.2s\n",
      "[CV 2/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.830, test=0.636) total time=   0.2s\n",
      "[CV 3/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.828, test=0.636) total time=   0.2s\n",
      "[CV 4/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.831, test=0.647) total time=   0.2s\n",
      "[CV 5/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.833, test=0.632) total time=   0.2s\n",
      "[CV 1/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.827, test=0.642) total time=   0.6s\n",
      "[CV 2/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.830, test=0.661) total time=   0.6s\n",
      "[CV 3/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.833, test=0.636) total time=   0.6s\n",
      "[CV 4/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.823, test=0.639) total time=   0.6s\n",
      "[CV 5/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.831, test=0.644) total time=   0.6s\n",
      "[CV 1/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.584) total time=   0.2s\n",
      "[CV 2/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.584) total time=   0.2s\n",
      "[CV 3/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.625) total time=   0.2s\n",
      "[CV 4/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.605) total time=   0.2s\n",
      "[CV 5/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.606) total time=   0.2s\n",
      "[CV 1/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.583) total time=   0.7s\n",
      "[CV 2/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.602) total time=   0.7s\n",
      "[CV 3/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.624) total time=   0.7s\n",
      "[CV 4/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.612) total time=   0.7s\n",
      "[CV 5/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.623) total time=   0.7s\n",
      "[CV 1/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.945, test=0.623) total time=   0.2s\n",
      "[CV 2/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.947, test=0.617) total time=   0.2s\n",
      "[CV 3/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.946, test=0.631) total time=   0.2s\n",
      "[CV 4/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.944, test=0.635) total time=   0.2s\n",
      "[CV 5/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.951, test=0.643) total time=   0.2s\n",
      "[CV 1/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.948, test=0.615) total time=   0.6s\n",
      "[CV 2/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.951, test=0.608) total time=   0.6s\n",
      "[CV 3/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.947, test=0.641) total time=   0.7s\n",
      "[CV 4/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.945, test=0.635) total time=   0.6s\n",
      "[CV 5/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.952, test=0.628) total time=   0.7s\n",
      "[CV 1/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.872, test=0.641) total time=   0.2s\n",
      "[CV 2/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.884, test=0.628) total time=   0.2s\n",
      "[CV 3/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.882, test=0.643) total time=   0.2s\n",
      "[CV 4/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.862, test=0.629) total time=   0.2s\n",
      "[CV 5/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.888, test=0.625) total time=   0.2s\n",
      "[CV 1/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.876, test=0.643) total time=   0.6s\n",
      "[CV 2/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.876, test=0.640) total time=   0.6s\n",
      "[CV 3/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.881, test=0.648) total time=   0.6s\n",
      "[CV 4/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.870, test=0.643) total time=   0.6s\n",
      "[CV 5/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.884, test=0.652) total time=   0.6s\n",
      "[CV 1/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.914, test=0.626) total time=   0.2s\n",
      "[CV 2/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.920, test=0.635) total time=   0.2s\n",
      "[CV 3/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.916, test=0.638) total time=   0.2s\n",
      "[CV 4/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.905, test=0.635) total time=   0.2s\n",
      "[CV 5/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.920, test=0.668) total time=   0.2s\n",
      "[CV 1/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.914, test=0.636) total time=   0.6s\n",
      "[CV 2/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.920, test=0.640) total time=   0.6s\n",
      "[CV 3/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.920, test=0.624) total time=   0.6s\n",
      "[CV 4/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.913, test=0.634) total time=   0.6s\n",
      "[CV 5/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.919, test=0.667) total time=   0.6s\n",
      "[CV 1/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.890, test=0.626) total time=   0.2s\n",
      "[CV 2/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.906, test=0.625) total time=   0.2s\n",
      "[CV 3/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.902, test=0.636) total time=   0.2s\n",
      "[CV 4/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.889, test=0.634) total time=   0.2s\n",
      "[CV 5/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.903, test=0.660) total time=   0.2s\n",
      "[CV 1/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.895, test=0.630) total time=   0.7s\n",
      "[CV 2/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.908, test=0.638) total time=   0.6s\n",
      "[CV 3/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.904, test=0.626) total time=   0.6s\n",
      "[CV 4/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.889, test=0.640) total time=   0.6s\n",
      "[CV 5/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.907, test=0.652) total time=   0.7s\n",
      "[CV 1/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.840, test=0.651) total time=   0.2s\n",
      "[CV 2/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.854, test=0.657) total time=   0.2s\n",
      "[CV 3/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.847, test=0.630) total time=   0.2s\n",
      "[CV 4/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.851, test=0.638) total time=   0.2s\n",
      "[CV 5/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.856, test=0.661) total time=   0.2s\n",
      "[CV 1/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.846, test=0.643) total time=   0.6s\n",
      "[CV 2/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.854, test=0.644) total time=   0.6s\n",
      "[CV 3/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.860, test=0.643) total time=   0.6s\n",
      "[CV 4/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.850, test=0.645) total time=   0.6s\n",
      "[CV 5/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.857, test=0.652) total time=   0.6s\n",
      "[CV 1/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.841, test=0.645) total time=   0.2s\n",
      "[CV 2/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.851, test=0.634) total time=   0.2s\n",
      "[CV 3/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.844, test=0.638) total time=   0.2s\n",
      "[CV 4/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.846, test=0.638) total time=   0.2s\n",
      "[CV 5/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.848, test=0.663) total time=   0.2s\n",
      "[CV 1/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.842, test=0.638) total time=   0.6s\n",
      "[CV 2/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.846, test=0.642) total time=   0.6s\n",
      "[CV 3/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.852, test=0.632) total time=   0.6s\n",
      "[CV 4/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.841, test=0.653) total time=   0.6s\n",
      "[CV 5/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.857, test=0.651) total time=   0.8s\n",
      "[CV 1/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.840, test=0.642) total time=   0.2s\n",
      "[CV 2/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.849, test=0.646) total time=   0.2s\n",
      "[CV 3/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.852, test=0.649) total time=   0.2s\n",
      "[CV 4/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.844, test=0.626) total time=   0.2s\n",
      "[CV 5/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.850, test=0.660) total time=   0.2s\n",
      "[CV 1/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.840, test=0.643) total time=   0.6s\n",
      "[CV 2/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.847, test=0.644) total time=   0.6s\n",
      "[CV 3/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.855, test=0.623) total time=   0.6s\n",
      "[CV 4/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.844, test=0.640) total time=   0.6s\n",
      "[CV 5/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.853, test=0.656) total time=   0.6s\n",
      "[CV 1/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.826, test=0.656) total time=   0.2s\n",
      "[CV 2/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.824, test=0.650) total time=   0.2s\n",
      "[CV 3/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.825, test=0.643) total time=   0.2s\n",
      "[CV 4/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.822, test=0.640) total time=   0.2s\n",
      "[CV 5/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.831, test=0.665) total time=   0.2s\n",
      "[CV 1/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.830, test=0.653) total time=   0.6s\n",
      "[CV 2/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.834, test=0.661) total time=   0.6s\n",
      "[CV 3/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.833, test=0.631) total time=   0.6s\n",
      "[CV 4/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.827, test=0.642) total time=   0.6s\n",
      "[CV 5/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.834, test=0.647) total time=   0.6s\n",
      "Selected Parameters: {'rf__max_depth': 20, 'rf__min_samples_leaf': 5, 'rf__min_samples_split': 2, 'rf__n_estimators': 250}\n",
      "Train score: 0.8507867607162235\n",
      "Test score: 0.6939571150097466\n",
      "Running for 2 out of a total of 5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.649) total time=   0.3s\n",
      "[CV 2/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.678) total time=   0.3s\n",
      "[CV 3/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.616) total time=   0.3s\n",
      "[CV 4/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.647) total time=   0.3s\n",
      "[CV 5/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.626) total time=   0.3s\n",
      "[CV 1/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.651) total time=   0.8s\n",
      "[CV 2/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.670) total time=   0.9s\n",
      "[CV 3/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.618) total time=   0.9s\n",
      "[CV 4/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.665) total time=   0.8s\n",
      "[CV 5/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.632) total time=   0.9s\n",
      "[CV 1/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.943, test=0.661) total time=   0.3s\n",
      "[CV 2/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.946, test=0.686) total time=   0.3s\n",
      "[CV 3/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.944, test=0.605) total time=   0.2s\n",
      "[CV 4/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.940, test=0.668) total time=   0.3s\n",
      "[CV 5/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.947, test=0.633) total time=   0.2s\n",
      "[CV 1/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.951, test=0.667) total time=   0.8s\n",
      "[CV 2/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.942, test=0.672) total time=   0.8s\n",
      "[CV 3/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.947, test=0.617) total time=   0.7s\n",
      "[CV 4/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.941, test=0.654) total time=   0.8s\n",
      "[CV 5/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.946, test=0.650) total time=   0.8s\n",
      "[CV 1/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.882, test=0.690) total time=   0.2s\n",
      "[CV 2/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.888, test=0.695) total time=   0.2s\n",
      "[CV 3/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.881, test=0.619) total time=   0.2s\n",
      "[CV 4/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.877, test=0.662) total time=   0.2s\n",
      "[CV 5/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.886, test=0.636) total time=   0.2s\n",
      "[CV 1/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.887, test=0.683) total time=   0.8s\n",
      "[CV 2/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.886, test=0.679) total time=   0.8s\n",
      "[CV 3/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.879, test=0.606) total time=   0.7s\n",
      "[CV 4/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.875, test=0.675) total time=   0.7s\n",
      "[CV 5/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.876, test=0.650) total time=   0.8s\n",
      "[CV 1/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.921, test=0.668) total time=   0.3s\n",
      "[CV 2/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.911, test=0.686) total time=   0.3s\n",
      "[CV 3/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.913, test=0.614) total time=   0.3s\n",
      "[CV 4/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.914, test=0.654) total time=   0.2s\n",
      "[CV 5/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.916, test=0.639) total time=   0.2s\n",
      "[CV 1/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.920, test=0.681) total time=   0.7s\n",
      "[CV 2/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.916, test=0.682) total time=   0.7s\n",
      "[CV 3/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.914, test=0.605) total time=   0.7s\n",
      "[CV 4/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.909, test=0.661) total time=   0.8s\n",
      "[CV 5/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.917, test=0.640) total time=   0.7s\n",
      "[CV 1/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.904, test=0.672) total time=   0.2s\n",
      "[CV 2/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.903, test=0.698) total time=   0.3s\n",
      "[CV 3/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.903, test=0.613) total time=   0.2s\n",
      "[CV 4/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.899, test=0.657) total time=   0.2s\n",
      "[CV 5/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.902, test=0.631) total time=   0.2s\n",
      "[CV 1/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.904, test=0.681) total time=   0.7s\n",
      "[CV 2/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.901, test=0.672) total time=   0.7s\n",
      "[CV 3/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.896, test=0.619) total time=   0.7s\n",
      "[CV 4/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.896, test=0.655) total time=   0.7s\n",
      "[CV 5/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.903, test=0.642) total time=   0.8s\n",
      "[CV 1/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.861, test=0.685) total time=   0.2s\n",
      "[CV 2/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.855, test=0.688) total time=   0.2s\n",
      "[CV 3/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.849, test=0.621) total time=   0.2s\n",
      "[CV 4/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.854, test=0.671) total time=   0.2s\n",
      "[CV 5/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.859, test=0.648) total time=   0.2s\n",
      "[CV 1/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.860, test=0.689) total time=   0.7s\n",
      "[CV 2/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.859, test=0.679) total time=   0.7s\n",
      "[CV 3/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.857, test=0.603) total time=   0.7s\n",
      "[CV 4/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.852, test=0.672) total time=   0.7s\n",
      "[CV 5/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.863, test=0.651) total time=   0.7s\n",
      "[CV 1/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.862, test=0.693) total time=   0.2s\n",
      "[CV 2/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.855, test=0.691) total time=   0.2s\n",
      "[CV 3/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.848, test=0.634) total time=   0.2s\n",
      "[CV 4/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.847, test=0.668) total time=   0.2s\n",
      "[CV 5/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.864, test=0.651) total time=   0.2s\n",
      "[CV 1/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.864, test=0.686) total time=   0.7s\n",
      "[CV 2/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.848, test=0.690) total time=   0.7s\n",
      "[CV 3/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.851, test=0.617) total time=   0.7s\n",
      "[CV 4/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.849, test=0.662) total time=   0.7s\n",
      "[CV 5/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.855, test=0.652) total time=   0.7s\n",
      "[CV 1/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.863, test=0.687) total time=   0.2s\n",
      "[CV 2/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.852, test=0.692) total time=   0.2s\n",
      "[CV 3/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.849, test=0.604) total time=   0.2s\n",
      "[CV 4/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.844, test=0.667) total time=   0.2s\n",
      "[CV 5/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.854, test=0.650) total time=   0.2s\n",
      "[CV 1/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.860, test=0.690) total time=   0.7s\n",
      "[CV 2/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.855, test=0.688) total time=   0.7s\n",
      "[CV 3/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.852, test=0.624) total time=   0.7s\n",
      "[CV 4/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.848, test=0.664) total time=   0.7s\n",
      "[CV 5/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.857, test=0.658) total time=   0.7s\n",
      "[CV 1/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.846, test=0.694) total time=   0.2s\n",
      "[CV 2/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.832, test=0.696) total time=   0.2s\n",
      "[CV 3/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.827, test=0.615) total time=   0.2s\n",
      "[CV 4/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.834, test=0.672) total time=   0.2s\n",
      "[CV 5/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.838, test=0.657) total time=   0.2s\n",
      "[CV 1/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.841, test=0.684) total time=   0.7s\n",
      "[CV 2/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.837, test=0.700) total time=   0.7s\n",
      "[CV 3/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.831, test=0.614) total time=   0.7s\n",
      "[CV 4/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.831, test=0.668) total time=   0.7s\n",
      "[CV 5/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.841, test=0.652) total time=   0.7s\n",
      "[CV 1/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.627) total time=   0.3s\n",
      "[CV 2/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.651) total time=   0.3s\n",
      "[CV 3/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.619) total time=   0.3s\n",
      "[CV 4/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.641) total time=   0.3s\n",
      "[CV 5/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.629) total time=   0.3s\n",
      "[CV 1/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.645) total time=   0.8s\n",
      "[CV 2/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.661) total time=   0.9s\n",
      "[CV 3/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.617) total time=   0.9s\n",
      "[CV 4/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.649) total time=   0.9s\n",
      "[CV 5/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.626) total time=   0.9s\n",
      "[CV 1/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.948, test=0.672) total time=   0.4s\n",
      "[CV 2/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.947, test=0.675) total time=   0.3s\n",
      "[CV 3/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.942, test=0.600) total time=   0.2s\n",
      "[CV 4/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.939, test=0.673) total time=   0.3s\n",
      "[CV 5/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.951, test=0.644) total time=   0.2s\n",
      "[CV 1/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.949, test=0.667) total time=   0.8s\n",
      "[CV 2/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.949, test=0.669) total time=   0.8s\n",
      "[CV 3/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.943, test=0.605) total time=   0.8s\n",
      "[CV 4/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.939, test=0.665) total time=   0.8s\n",
      "[CV 5/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.950, test=0.647) total time=   0.9s\n",
      "[CV 1/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.886, test=0.681) total time=   0.3s\n",
      "[CV 2/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.880, test=0.703) total time=   0.3s\n",
      "[CV 3/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.880, test=0.609) total time=   0.2s\n",
      "[CV 4/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.881, test=0.661) total time=   0.3s\n",
      "[CV 5/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.887, test=0.643) total time=   0.3s\n",
      "[CV 1/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.889, test=0.690) total time=   0.7s\n",
      "[CV 2/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.889, test=0.690) total time=   0.7s\n",
      "[CV 3/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.879, test=0.621) total time=   0.7s\n",
      "[CV 4/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.880, test=0.664) total time=   0.7s\n",
      "[CV 5/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.884, test=0.643) total time=   0.7s\n",
      "[CV 1/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.912, test=0.665) total time=   0.2s\n",
      "[CV 2/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.915, test=0.679) total time=   0.2s\n",
      "[CV 3/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.910, test=0.604) total time=   0.2s\n",
      "[CV 4/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.908, test=0.648) total time=   0.2s\n",
      "[CV 5/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.917, test=0.646) total time=   0.2s\n",
      "[CV 1/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.920, test=0.667) total time=   0.7s\n",
      "[CV 2/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.915, test=0.690) total time=   0.8s\n",
      "[CV 3/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.921, test=0.608) total time=   0.8s\n",
      "[CV 4/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.911, test=0.661) total time=   0.8s\n",
      "[CV 5/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.919, test=0.640) total time=   0.9s\n",
      "[CV 1/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.902, test=0.668) total time=   0.3s\n",
      "[CV 2/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.900, test=0.680) total time=   0.3s\n",
      "[CV 3/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.903, test=0.617) total time=   0.3s\n",
      "[CV 4/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.901, test=0.658) total time=   0.2s\n",
      "[CV 5/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.907, test=0.658) total time=   0.2s\n",
      "[CV 1/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.908, test=0.662) total time=   0.8s\n",
      "[CV 2/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.901, test=0.690) total time=   0.7s\n",
      "[CV 3/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.901, test=0.615) total time=   0.7s\n",
      "[CV 4/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.898, test=0.671) total time=   0.7s\n",
      "[CV 5/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.903, test=0.642) total time=   0.8s\n",
      "[CV 1/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.858, test=0.674) total time=   0.2s\n",
      "[CV 2/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.856, test=0.698) total time=   0.2s\n",
      "[CV 3/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.851, test=0.608) total time=   0.2s\n",
      "[CV 4/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.858, test=0.675) total time=   0.3s\n",
      "[CV 5/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.862, test=0.639) total time=   0.2s\n",
      "[CV 1/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.864, test=0.690) total time=   0.7s\n",
      "[CV 2/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.862, test=0.696) total time=   0.7s\n",
      "[CV 3/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.855, test=0.618) total time=   0.7s\n",
      "[CV 4/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.852, test=0.670) total time=   0.7s\n",
      "[CV 5/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.862, test=0.650) total time=   0.7s\n",
      "[CV 1/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.863, test=0.692) total time=   0.3s\n",
      "[CV 2/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.852, test=0.691) total time=   0.2s\n",
      "[CV 3/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.852, test=0.617) total time=   0.2s\n",
      "[CV 4/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.855, test=0.671) total time=   0.2s\n",
      "[CV 5/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.855, test=0.656) total time=   0.2s\n",
      "[CV 1/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.860, test=0.686) total time=   0.7s\n",
      "[CV 2/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.854, test=0.695) total time=   0.7s\n",
      "[CV 3/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.852, test=0.601) total time=   0.7s\n",
      "[CV 4/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.847, test=0.681) total time=   0.7s\n",
      "[CV 5/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.860, test=0.649) total time=   0.7s\n",
      "[CV 1/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.861, test=0.672) total time=   0.2s\n",
      "[CV 2/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.853, test=0.686) total time=   0.2s\n",
      "[CV 3/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.846, test=0.609) total time=   0.2s\n",
      "[CV 4/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.852, test=0.665) total time=   0.2s\n",
      "[CV 5/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.855, test=0.648) total time=   0.2s\n",
      "[CV 1/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.864, test=0.680) total time=   0.7s\n",
      "[CV 2/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.855, test=0.688) total time=   0.7s\n",
      "[CV 3/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.851, test=0.621) total time=   0.7s\n",
      "[CV 4/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.851, test=0.668) total time=   0.7s\n",
      "[CV 5/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.856, test=0.653) total time=   0.7s\n",
      "[CV 1/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.839, test=0.696) total time=   0.2s\n",
      "[CV 2/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.832, test=0.675) total time=   0.2s\n",
      "[CV 3/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.827, test=0.617) total time=   0.2s\n",
      "[CV 4/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.830, test=0.681) total time=   0.2s\n",
      "[CV 5/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.839, test=0.659) total time=   0.2s\n",
      "[CV 1/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.850, test=0.686) total time=   0.7s\n",
      "[CV 2/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.840, test=0.692) total time=   0.7s\n",
      "[CV 3/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.830, test=0.620) total time=   0.7s\n",
      "[CV 4/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.831, test=0.658) total time=   0.7s\n",
      "[CV 5/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.841, test=0.657) total time=   0.7s\n",
      "Selected Parameters: {'rf__max_depth': 20, 'rf__min_samples_leaf': 5, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n",
      "Train score: 0.8513513513513513\n",
      "Test score: 0.5925925925925927\n",
      "Running for 3 out of a total of 5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.608) total time=   0.3s\n",
      "[CV 2/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.614) total time=   0.3s\n",
      "[CV 3/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.612) total time=   0.3s\n",
      "[CV 4/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.667) total time=   0.3s\n",
      "[CV 5/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.641) total time=   0.3s\n",
      "[CV 1/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.615) total time=   0.9s\n",
      "[CV 2/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.604) total time=   1.0s\n",
      "[CV 3/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.612) total time=   1.0s\n",
      "[CV 4/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.665) total time=   1.0s\n",
      "[CV 5/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.638) total time=   1.0s\n",
      "[CV 1/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.939, test=0.626) total time=   0.4s\n",
      "[CV 2/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.951, test=0.618) total time=   0.3s\n",
      "[CV 3/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.941, test=0.628) total time=   0.3s\n",
      "[CV 4/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.939, test=0.673) total time=   0.3s\n",
      "[CV 5/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.942, test=0.667) total time=   0.3s\n",
      "[CV 1/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.948, test=0.616) total time=   0.8s\n",
      "[CV 2/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.946, test=0.630) total time=   0.8s\n",
      "[CV 3/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.947, test=0.618) total time=   0.9s\n",
      "[CV 4/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.950, test=0.687) total time=   0.9s\n",
      "[CV 5/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.950, test=0.656) total time=   1.0s\n",
      "[CV 1/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.888, test=0.624) total time=   0.3s\n",
      "[CV 2/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.881, test=0.652) total time=   0.3s\n",
      "[CV 3/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.875, test=0.644) total time=   0.2s\n",
      "[CV 4/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.882, test=0.689) total time=   0.3s\n",
      "[CV 5/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.886, test=0.658) total time=   0.3s\n",
      "[CV 1/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.885, test=0.629) total time=   0.8s\n",
      "[CV 2/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.892, test=0.637) total time=   0.8s\n",
      "[CV 3/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.879, test=0.639) total time=   0.8s\n",
      "[CV 4/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.884, test=0.679) total time=   0.8s\n",
      "[CV 5/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.886, test=0.665) total time=   0.8s\n",
      "[CV 1/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.917, test=0.615) total time=   0.3s\n",
      "[CV 2/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.920, test=0.620) total time=   0.3s\n",
      "[CV 3/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.909, test=0.625) total time=   0.3s\n",
      "[CV 4/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.913, test=0.668) total time=   0.3s\n",
      "[CV 5/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.921, test=0.643) total time=   0.3s\n",
      "[CV 1/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.919, test=0.621) total time=   0.8s\n",
      "[CV 2/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.924, test=0.639) total time=   0.8s\n",
      "[CV 3/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.904, test=0.628) total time=   1.0s\n",
      "[CV 4/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.917, test=0.671) total time=   0.8s\n",
      "[CV 5/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.918, test=0.659) total time=   1.0s\n",
      "[CV 1/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.902, test=0.619) total time=   0.4s\n",
      "[CV 2/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.912, test=0.630) total time=   0.3s\n",
      "[CV 3/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.898, test=0.651) total time=   0.3s\n",
      "[CV 4/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.906, test=0.663) total time=   0.3s\n",
      "[CV 5/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.905, test=0.647) total time=   0.3s\n",
      "[CV 1/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.908, test=0.634) total time=   0.8s\n",
      "[CV 2/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.907, test=0.635) total time=   0.9s\n",
      "[CV 3/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.896, test=0.636) total time=   0.9s\n",
      "[CV 4/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.904, test=0.680) total time=   0.9s\n",
      "[CV 5/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.910, test=0.652) total time=   0.9s\n",
      "[CV 1/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.863, test=0.625) total time=   0.2s\n",
      "[CV 2/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.862, test=0.629) total time=   0.2s\n",
      "[CV 3/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.859, test=0.641) total time=   0.2s\n",
      "[CV 4/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.855, test=0.669) total time=   0.2s\n",
      "[CV 5/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.856, test=0.656) total time=   0.3s\n",
      "[CV 1/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.861, test=0.632) total time=   0.7s\n",
      "[CV 2/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.867, test=0.655) total time=   0.7s\n",
      "[CV 3/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.859, test=0.646) total time=   0.7s\n",
      "[CV 4/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.862, test=0.668) total time=   0.7s\n",
      "[CV 5/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.864, test=0.649) total time=   0.8s\n",
      "[CV 1/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.854, test=0.628) total time=   0.3s\n",
      "[CV 2/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.859, test=0.645) total time=   0.2s\n",
      "[CV 3/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.849, test=0.638) total time=   0.2s\n",
      "[CV 4/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.854, test=0.677) total time=   0.2s\n",
      "[CV 5/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.860, test=0.660) total time=   0.2s\n",
      "[CV 1/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.861, test=0.636) total time=   0.7s\n",
      "[CV 2/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.863, test=0.647) total time=   0.7s\n",
      "[CV 3/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.851, test=0.643) total time=   0.7s\n",
      "[CV 4/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.857, test=0.680) total time=   0.8s\n",
      "[CV 5/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.859, test=0.651) total time=   0.7s\n",
      "[CV 1/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.862, test=0.639) total time=   0.3s\n",
      "[CV 2/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.862, test=0.634) total time=   0.2s\n",
      "[CV 3/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.848, test=0.658) total time=   0.2s\n",
      "[CV 4/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.858, test=0.669) total time=   0.2s\n",
      "[CV 5/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.857, test=0.649) total time=   0.2s\n",
      "[CV 1/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.855, test=0.641) total time=   0.8s\n",
      "[CV 2/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.863, test=0.659) total time=   0.7s\n",
      "[CV 3/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.849, test=0.658) total time=   0.7s\n",
      "[CV 4/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.855, test=0.678) total time=   0.7s\n",
      "[CV 5/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.858, test=0.653) total time=   0.8s\n",
      "[CV 1/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.839, test=0.634) total time=   0.2s\n",
      "[CV 2/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.842, test=0.638) total time=   0.3s\n",
      "[CV 3/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.830, test=0.650) total time=   0.2s\n",
      "[CV 4/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.831, test=0.677) total time=   0.2s\n",
      "[CV 5/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.841, test=0.669) total time=   0.2s\n",
      "[CV 1/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.844, test=0.629) total time=   0.7s\n",
      "[CV 2/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.843, test=0.652) total time=   0.7s\n",
      "[CV 3/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.837, test=0.658) total time=   0.7s\n",
      "[CV 4/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.832, test=0.663) total time=   0.7s\n",
      "[CV 5/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.842, test=0.663) total time=   0.7s\n",
      "[CV 1/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.615) total time=   0.3s\n",
      "[CV 2/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.610) total time=   0.3s\n",
      "[CV 3/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.609) total time=   0.3s\n",
      "[CV 4/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.667) total time=   0.3s\n",
      "[CV 5/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.638) total time=   0.3s\n",
      "[CV 1/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.595) total time=   0.9s\n",
      "[CV 2/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.606) total time=   1.0s\n",
      "[CV 3/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.999, test=0.613) total time=   1.0s\n",
      "[CV 4/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.665) total time=   1.0s\n",
      "[CV 5/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.639) total time=   1.0s\n",
      "[CV 1/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.945, test=0.619) total time=   0.4s\n",
      "[CV 2/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.951, test=0.624) total time=   0.3s\n",
      "[CV 3/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.946, test=0.635) total time=   0.3s\n",
      "[CV 4/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.949, test=0.656) total time=   0.3s\n",
      "[CV 5/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.951, test=0.647) total time=   0.3s\n",
      "[CV 1/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.950, test=0.606) total time=   0.8s\n",
      "[CV 2/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.951, test=0.624) total time=   0.9s\n",
      "[CV 3/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.945, test=0.627) total time=   1.0s\n",
      "[CV 4/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.955, test=0.678) total time=   1.0s\n",
      "[CV 5/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.951, test=0.657) total time=   1.0s\n",
      "[CV 1/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.884, test=0.631) total time=   0.4s\n",
      "[CV 2/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.884, test=0.627) total time=   0.3s\n",
      "[CV 3/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.876, test=0.640) total time=   0.3s\n",
      "[CV 4/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.881, test=0.643) total time=   0.3s\n",
      "[CV 5/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.891, test=0.647) total time=   0.3s\n",
      "[CV 1/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.885, test=0.628) total time=   0.8s\n",
      "[CV 2/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.891, test=0.642) total time=   0.8s\n",
      "[CV 3/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.878, test=0.643) total time=   0.8s\n",
      "[CV 4/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.885, test=0.683) total time=   0.8s\n",
      "[CV 5/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.891, test=0.660) total time=   1.0s\n",
      "[CV 1/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.914, test=0.624) total time=   0.3s\n",
      "[CV 2/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.928, test=0.645) total time=   0.3s\n",
      "[CV 3/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.908, test=0.628) total time=   0.3s\n",
      "[CV 4/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.923, test=0.673) total time=   0.3s\n",
      "[CV 5/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.914, test=0.652) total time=   0.3s\n",
      "[CV 1/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.922, test=0.614) total time=   0.8s\n",
      "[CV 2/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.923, test=0.643) total time=   0.8s\n",
      "[CV 3/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.914, test=0.636) total time=   0.9s\n",
      "[CV 4/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.921, test=0.661) total time=   0.9s\n",
      "[CV 5/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.924, test=0.652) total time=   1.0s\n",
      "[CV 1/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.908, test=0.620) total time=   0.4s\n",
      "[CV 2/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.913, test=0.625) total time=   0.3s\n",
      "[CV 3/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.899, test=0.635) total time=   0.3s\n",
      "[CV 4/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.899, test=0.671) total time=   0.2s\n",
      "[CV 5/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.906, test=0.658) total time=   0.3s\n",
      "[CV 1/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.905, test=0.626) total time=   0.8s\n",
      "[CV 2/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.912, test=0.644) total time=   0.8s\n",
      "[CV 3/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.902, test=0.643) total time=   0.9s\n",
      "[CV 4/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.907, test=0.677) total time=   0.9s\n",
      "[CV 5/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.905, test=0.647) total time=   0.8s\n",
      "[CV 1/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.865, test=0.621) total time=   0.2s\n",
      "[CV 2/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.866, test=0.641) total time=   0.2s\n",
      "[CV 3/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.856, test=0.635) total time=   0.3s\n",
      "[CV 4/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.863, test=0.664) total time=   0.3s\n",
      "[CV 5/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.857, test=0.660) total time=   0.2s\n",
      "[CV 1/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.863, test=0.631) total time=   0.8s\n",
      "[CV 2/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.869, test=0.635) total time=   0.8s\n",
      "[CV 3/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.854, test=0.643) total time=   0.8s\n",
      "[CV 4/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.860, test=0.673) total time=   0.8s\n",
      "[CV 5/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.868, test=0.668) total time=   0.9s\n",
      "[CV 1/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.858, test=0.618) total time=   0.4s\n",
      "[CV 2/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.859, test=0.654) total time=   0.3s\n",
      "[CV 3/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.847, test=0.630) total time=   0.3s\n",
      "[CV 4/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.864, test=0.661) total time=   0.2s\n",
      "[CV 5/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.856, test=0.656) total time=   0.2s\n",
      "[CV 1/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.860, test=0.628) total time=   0.7s\n",
      "[CV 2/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.860, test=0.647) total time=   0.7s\n",
      "[CV 3/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.851, test=0.648) total time=   0.8s\n",
      "[CV 4/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.857, test=0.669) total time=   0.7s\n",
      "[CV 5/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.862, test=0.669) total time=   0.8s\n",
      "[CV 1/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.859, test=0.630) total time=   0.2s\n",
      "[CV 2/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.855, test=0.645) total time=   0.2s\n",
      "[CV 3/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.853, test=0.646) total time=   0.2s\n",
      "[CV 4/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.852, test=0.677) total time=   0.3s\n",
      "[CV 5/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.855, test=0.656) total time=   0.2s\n",
      "[CV 1/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.859, test=0.631) total time=   0.7s\n",
      "[CV 2/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.861, test=0.654) total time=   0.8s\n",
      "[CV 3/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.852, test=0.650) total time=   0.7s\n",
      "[CV 4/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.855, test=0.669) total time=   0.8s\n",
      "[CV 5/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.861, test=0.663) total time=   0.7s\n",
      "[CV 1/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.836, test=0.638) total time=   0.3s\n",
      "[CV 2/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.838, test=0.646) total time=   0.2s\n",
      "[CV 3/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.825, test=0.650) total time=   0.3s\n",
      "[CV 4/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.833, test=0.689) total time=   0.3s\n",
      "[CV 5/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.843, test=0.663) total time=   0.3s\n",
      "[CV 1/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.844, test=0.633) total time=   0.8s\n",
      "[CV 2/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.841, test=0.655) total time=   0.7s\n",
      "[CV 3/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.834, test=0.658) total time=   0.7s\n",
      "[CV 4/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.837, test=0.675) total time=   0.7s\n",
      "[CV 5/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.848, test=0.662) total time=   0.8s\n",
      "Selected Parameters: {'rf__max_depth': 20, 'rf__min_samples_leaf': 5, 'rf__min_samples_split': 8, 'rf__n_estimators': 250}\n",
      "Train score: 0.8560311284046692\n",
      "Test score: 0.42056074766355145\n",
      "Running for 4 out of a total of 5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.647) total time=   0.4s\n",
      "[CV 2/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.601) total time=   0.3s\n",
      "[CV 3/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.639) total time=   0.3s\n",
      "[CV 4/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.631) total time=   0.3s\n",
      "[CV 5/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.626) total time=   0.3s\n",
      "[CV 1/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.645) total time=   0.9s\n",
      "[CV 2/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.615) total time=   1.1s\n",
      "[CV 3/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.639) total time=   1.2s\n",
      "[CV 4/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.639) total time=   1.1s\n",
      "[CV 5/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.640) total time=   1.0s\n",
      "[CV 1/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.940, test=0.654) total time=   0.4s\n",
      "[CV 2/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.937, test=0.629) total time=   0.3s\n",
      "[CV 3/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.944, test=0.647) total time=   0.3s\n",
      "[CV 4/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.944, test=0.638) total time=   0.3s\n",
      "[CV 5/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.947, test=0.630) total time=   0.3s\n",
      "[CV 1/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.945, test=0.650) total time=   0.9s\n",
      "[CV 2/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.945, test=0.642) total time=   1.0s\n",
      "[CV 3/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.946, test=0.656) total time=   1.1s\n",
      "[CV 4/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.949, test=0.644) total time=   1.1s\n",
      "[CV 5/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.942, test=0.641) total time=   1.0s\n",
      "[CV 1/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.877, test=0.654) total time=   0.4s\n",
      "[CV 2/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.884, test=0.636) total time=   0.3s\n",
      "[CV 3/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.879, test=0.656) total time=   0.3s\n",
      "[CV 4/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.883, test=0.650) total time=   0.3s\n",
      "[CV 5/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.883, test=0.635) total time=   0.3s\n",
      "[CV 1/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.875, test=0.652) total time=   0.9s\n",
      "[CV 2/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.885, test=0.629) total time=   1.0s\n",
      "[CV 3/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.884, test=0.673) total time=   1.0s\n",
      "[CV 4/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.883, test=0.636) total time=   1.0s\n",
      "[CV 5/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.882, test=0.645) total time=   1.0s\n",
      "[CV 1/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.919, test=0.653) total time=   0.4s\n",
      "[CV 2/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.916, test=0.636) total time=   0.3s\n",
      "[CV 3/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.912, test=0.657) total time=   0.3s\n",
      "[CV 4/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.920, test=0.634) total time=   0.3s\n",
      "[CV 5/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.915, test=0.651) total time=   0.3s\n",
      "[CV 1/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.914, test=0.651) total time=   0.9s\n",
      "[CV 2/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.921, test=0.626) total time=   1.0s\n",
      "[CV 3/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.919, test=0.674) total time=   1.0s\n",
      "[CV 4/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.921, test=0.638) total time=   1.0s\n",
      "[CV 5/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.918, test=0.647) total time=   1.0s\n",
      "[CV 1/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.896, test=0.637) total time=   0.4s\n",
      "[CV 2/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.905, test=0.629) total time=   0.3s\n",
      "[CV 3/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.902, test=0.647) total time=   0.3s\n",
      "[CV 4/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.904, test=0.642) total time=   0.3s\n",
      "[CV 5/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.906, test=0.646) total time=   0.3s\n",
      "[CV 1/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.902, test=0.648) total time=   0.8s\n",
      "[CV 2/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.905, test=0.636) total time=   1.0s\n",
      "[CV 3/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.906, test=0.658) total time=   0.9s\n",
      "[CV 4/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.910, test=0.639) total time=   1.0s\n",
      "[CV 5/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.904, test=0.651) total time=   1.0s\n",
      "[CV 1/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.860, test=0.651) total time=   0.4s\n",
      "[CV 2/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.860, test=0.649) total time=   0.3s\n",
      "[CV 3/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.856, test=0.683) total time=   0.3s\n",
      "[CV 4/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.861, test=0.647) total time=   0.3s\n",
      "[CV 5/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.851, test=0.648) total time=   0.3s\n",
      "[CV 1/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.856, test=0.662) total time=   0.8s\n",
      "[CV 2/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.864, test=0.629) total time=   1.0s\n",
      "[CV 3/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.862, test=0.663) total time=   1.0s\n",
      "[CV 4/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.868, test=0.644) total time=   0.9s\n",
      "[CV 5/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.853, test=0.649) total time=   0.9s\n",
      "[CV 1/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.854, test=0.649) total time=   0.4s\n",
      "[CV 2/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.853, test=0.624) total time=   0.3s\n",
      "[CV 3/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.856, test=0.672) total time=   0.3s\n",
      "[CV 4/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.865, test=0.651) total time=   0.3s\n",
      "[CV 5/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.846, test=0.640) total time=   0.3s\n",
      "[CV 1/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.857, test=0.657) total time=   0.8s\n",
      "[CV 2/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.860, test=0.625) total time=   0.9s\n",
      "[CV 3/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.849, test=0.666) total time=   0.9s\n",
      "[CV 4/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.857, test=0.635) total time=   0.8s\n",
      "[CV 5/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.850, test=0.643) total time=   1.0s\n",
      "[CV 1/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.849, test=0.647) total time=   0.4s\n",
      "[CV 2/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.860, test=0.639) total time=   0.3s\n",
      "[CV 3/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.853, test=0.665) total time=   0.3s\n",
      "[CV 4/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.863, test=0.629) total time=   0.3s\n",
      "[CV 5/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.845, test=0.648) total time=   0.3s\n",
      "[CV 1/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.850, test=0.657) total time=   0.8s\n",
      "[CV 2/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.860, test=0.638) total time=   1.0s\n",
      "[CV 3/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.857, test=0.667) total time=   1.0s\n",
      "[CV 4/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.861, test=0.640) total time=   0.9s\n",
      "[CV 5/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.852, test=0.652) total time=   1.0s\n",
      "[CV 1/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.832, test=0.671) total time=   0.4s\n",
      "[CV 2/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.834, test=0.636) total time=   0.3s\n",
      "[CV 3/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.832, test=0.661) total time=   0.3s\n",
      "[CV 4/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.830, test=0.642) total time=   0.3s\n",
      "[CV 5/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.829, test=0.634) total time=   0.3s\n",
      "[CV 1/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.835, test=0.663) total time=   0.8s\n",
      "[CV 2/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.837, test=0.633) total time=   0.9s\n",
      "[CV 3/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.837, test=0.664) total time=   1.0s\n",
      "[CV 4/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.834, test=0.645) total time=   0.9s\n",
      "[CV 5/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.829, test=0.656) total time=   0.9s\n",
      "[CV 1/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.640) total time=   0.4s\n",
      "[CV 2/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.603) total time=   0.3s\n",
      "[CV 3/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.632) total time=   0.3s\n",
      "[CV 4/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.635) total time=   0.3s\n",
      "[CV 5/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.641) total time=   0.4s\n",
      "[CV 1/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.647) total time=   1.0s\n",
      "[CV 2/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.600) total time=   1.2s\n",
      "[CV 3/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.643) total time=   1.1s\n",
      "[CV 4/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.631) total time=   1.1s\n",
      "[CV 5/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.627) total time=   1.1s\n",
      "[CV 1/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.949, test=0.648) total time=   0.4s\n",
      "[CV 2/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.945, test=0.629) total time=   0.3s\n",
      "[CV 3/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.947, test=0.648) total time=   0.3s\n",
      "[CV 4/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.951, test=0.644) total time=   0.3s\n",
      "[CV 5/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.948, test=0.639) total time=   0.3s\n",
      "[CV 1/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.950, test=0.650) total time=   0.9s\n",
      "[CV 2/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.944, test=0.620) total time=   1.1s\n",
      "[CV 3/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.956, test=0.668) total time=   1.0s\n",
      "[CV 4/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.952, test=0.641) total time=   1.0s\n",
      "[CV 5/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.954, test=0.644) total time=   1.1s\n",
      "[CV 1/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.880, test=0.649) total time=   0.4s\n",
      "[CV 2/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.888, test=0.619) total time=   0.3s\n",
      "[CV 3/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.885, test=0.676) total time=   0.3s\n",
      "[CV 4/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.884, test=0.646) total time=   0.3s\n",
      "[CV 5/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.879, test=0.633) total time=   0.3s\n",
      "[CV 1/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.886, test=0.649) total time=   0.9s\n",
      "[CV 2/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.884, test=0.631) total time=   1.0s\n",
      "[CV 3/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.889, test=0.668) total time=   1.0s\n",
      "[CV 4/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.888, test=0.632) total time=   1.0s\n",
      "[CV 5/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.886, test=0.650) total time=   1.0s\n",
      "[CV 1/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.912, test=0.651) total time=   0.4s\n",
      "[CV 2/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.916, test=0.635) total time=   0.3s\n",
      "[CV 3/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.915, test=0.651) total time=   0.3s\n",
      "[CV 4/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.916, test=0.649) total time=   0.3s\n",
      "[CV 5/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.916, test=0.643) total time=   0.3s\n",
      "[CV 1/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.919, test=0.653) total time=   0.9s\n",
      "[CV 2/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.919, test=0.645) total time=   1.1s\n",
      "[CV 3/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.917, test=0.651) total time=   1.0s\n",
      "[CV 4/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.922, test=0.635) total time=   1.0s\n",
      "[CV 5/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.922, test=0.633) total time=   1.1s\n",
      "[CV 1/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.899, test=0.638) total time=   0.4s\n",
      "[CV 2/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.910, test=0.629) total time=   0.3s\n",
      "[CV 3/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.902, test=0.649) total time=   0.3s\n",
      "[CV 4/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.903, test=0.629) total time=   0.3s\n",
      "[CV 5/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.907, test=0.640) total time=   0.3s\n",
      "[CV 1/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.906, test=0.644) total time=   0.9s\n",
      "[CV 2/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.911, test=0.621) total time=   1.0s\n",
      "[CV 3/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.908, test=0.661) total time=   1.0s\n",
      "[CV 4/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.911, test=0.647) total time=   1.0s\n",
      "[CV 5/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.908, test=0.653) total time=   1.0s\n",
      "[CV 1/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.862, test=0.649) total time=   0.3s\n",
      "[CV 2/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.861, test=0.629) total time=   0.3s\n",
      "[CV 3/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.862, test=0.662) total time=   0.3s\n",
      "[CV 4/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.860, test=0.626) total time=   0.3s\n",
      "[CV 5/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.857, test=0.629) total time=   0.3s\n",
      "[CV 1/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.867, test=0.643) total time=   0.9s\n",
      "[CV 2/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.865, test=0.631) total time=   1.0s\n",
      "[CV 3/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.860, test=0.675) total time=   1.0s\n",
      "[CV 4/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.862, test=0.652) total time=   1.0s\n",
      "[CV 5/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.853, test=0.644) total time=   0.9s\n",
      "[CV 1/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.855, test=0.649) total time=   0.3s\n",
      "[CV 2/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.855, test=0.648) total time=   0.3s\n",
      "[CV 3/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.857, test=0.667) total time=   0.3s\n",
      "[CV 4/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.863, test=0.643) total time=   0.3s\n",
      "[CV 5/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.851, test=0.665) total time=   0.3s\n",
      "[CV 1/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.854, test=0.656) total time=   0.8s\n",
      "[CV 2/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.858, test=0.633) total time=   1.0s\n",
      "[CV 3/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.856, test=0.662) total time=   0.9s\n",
      "[CV 4/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.862, test=0.640) total time=   0.9s\n",
      "[CV 5/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.855, test=0.647) total time=   1.0s\n",
      "[CV 1/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.847, test=0.653) total time=   0.4s\n",
      "[CV 2/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.859, test=0.627) total time=   0.3s\n",
      "[CV 3/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.859, test=0.653) total time=   0.3s\n",
      "[CV 4/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.860, test=0.648) total time=   0.3s\n",
      "[CV 5/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.850, test=0.663) total time=   0.3s\n",
      "[CV 1/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.854, test=0.655) total time=   0.8s\n",
      "[CV 2/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.861, test=0.635) total time=   0.9s\n",
      "[CV 3/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.854, test=0.671) total time=   1.0s\n",
      "[CV 4/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.853, test=0.646) total time=   1.0s\n",
      "[CV 5/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.850, test=0.654) total time=   1.0s\n",
      "[CV 1/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.830, test=0.654) total time=   0.4s\n",
      "[CV 2/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.837, test=0.644) total time=   0.3s\n",
      "[CV 3/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.837, test=0.652) total time=   0.3s\n",
      "[CV 4/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.839, test=0.648) total time=   0.3s\n",
      "[CV 5/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.827, test=0.639) total time=   0.3s\n",
      "[CV 1/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.833, test=0.653) total time=   0.8s\n",
      "[CV 2/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.838, test=0.633) total time=   0.9s\n",
      "[CV 3/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.847, test=0.666) total time=   0.9s\n",
      "[CV 4/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.836, test=0.634) total time=   0.9s\n",
      "[CV 5/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.830, test=0.653) total time=   0.8s\n",
      "Selected Parameters: {'rf__max_depth': 20, 'rf__min_samples_leaf': 3, 'rf__min_samples_split': 15, 'rf__n_estimators': 100}\n",
      "Train score: 0.8575438596491228\n",
      "Test score: 0.5062240663900415\n",
      "Running for 5 out of a total of 5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.632) total time=   0.4s\n",
      "[CV 2/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.667) total time=   0.4s\n",
      "[CV 3/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.592) total time=   0.3s\n",
      "[CV 4/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.638) total time=   0.3s\n",
      "[CV 5/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.593) total time=   0.4s\n",
      "[CV 1/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.622) total time=   1.0s\n",
      "[CV 2/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.674) total time=   1.2s\n",
      "[CV 3/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.599) total time=   1.1s\n",
      "[CV 4/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.641) total time=   1.1s\n",
      "[CV 5/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.619) total time=   1.1s\n",
      "[CV 1/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.938, test=0.640) total time=   0.4s\n",
      "[CV 2/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.937, test=0.677) total time=   0.3s\n",
      "[CV 3/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.940, test=0.622) total time=   0.4s\n",
      "[CV 4/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.938, test=0.657) total time=   0.3s\n",
      "[CV 5/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.935, test=0.624) total time=   0.3s\n",
      "[CV 1/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.945, test=0.639) total time=   0.9s\n",
      "[CV 2/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.948, test=0.679) total time=   1.1s\n",
      "[CV 3/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.941, test=0.629) total time=   1.1s\n",
      "[CV 4/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.945, test=0.653) total time=   1.1s\n",
      "[CV 5/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.938, test=0.640) total time=   1.0s\n",
      "[CV 1/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.870, test=0.648) total time=   0.4s\n",
      "[CV 2/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.878, test=0.698) total time=   0.3s\n",
      "[CV 3/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.876, test=0.631) total time=   0.3s\n",
      "[CV 4/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.871, test=0.672) total time=   0.3s\n",
      "[CV 5/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.871, test=0.637) total time=   0.3s\n",
      "[CV 1/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.879, test=0.632) total time=   0.9s\n",
      "[CV 2/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.880, test=0.690) total time=   1.1s\n",
      "[CV 3/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.881, test=0.640) total time=   1.0s\n",
      "[CV 4/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.872, test=0.658) total time=   1.0s\n",
      "[CV 5/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.865, test=0.642) total time=   1.1s\n",
      "[CV 1/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.915, test=0.613) total time=   0.4s\n",
      "[CV 2/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.919, test=0.677) total time=   0.3s\n",
      "[CV 3/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.914, test=0.622) total time=   0.3s\n",
      "[CV 4/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.909, test=0.649) total time=   0.3s\n",
      "[CV 5/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.907, test=0.639) total time=   0.3s\n",
      "[CV 1/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.916, test=0.643) total time=   0.9s\n",
      "[CV 2/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.916, test=0.694) total time=   1.1s\n",
      "[CV 3/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.919, test=0.631) total time=   1.1s\n",
      "[CV 4/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.911, test=0.643) total time=   1.1s\n",
      "[CV 5/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.910, test=0.635) total time=   1.1s\n",
      "[CV 1/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.900, test=0.641) total time=   0.4s\n",
      "[CV 2/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.899, test=0.679) total time=   0.3s\n",
      "[CV 3/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.898, test=0.624) total time=   0.3s\n",
      "[CV 4/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.896, test=0.657) total time=   0.3s\n",
      "[CV 5/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.887, test=0.629) total time=   0.3s\n",
      "[CV 1/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.906, test=0.645) total time=   0.9s\n",
      "[CV 2/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.904, test=0.697) total time=   1.1s\n",
      "[CV 3/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.905, test=0.625) total time=   1.1s\n",
      "[CV 4/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.895, test=0.651) total time=   1.1s\n",
      "[CV 5/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.892, test=0.632) total time=   1.0s\n",
      "[CV 1/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.846, test=0.648) total time=   0.4s\n",
      "[CV 2/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.850, test=0.675) total time=   0.3s\n",
      "[CV 3/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.856, test=0.628) total time=   0.3s\n",
      "[CV 4/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.847, test=0.669) total time=   0.3s\n",
      "[CV 5/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.848, test=0.645) total time=   0.3s\n",
      "[CV 1/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.853, test=0.640) total time=   0.9s\n",
      "[CV 2/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.853, test=0.698) total time=   1.0s\n",
      "[CV 3/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.857, test=0.637) total time=   1.0s\n",
      "[CV 4/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.851, test=0.656) total time=   1.0s\n",
      "[CV 5/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.850, test=0.639) total time=   1.0s\n",
      "[CV 1/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.844, test=0.644) total time=   0.4s\n",
      "[CV 2/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.845, test=0.689) total time=   0.3s\n",
      "[CV 3/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.849, test=0.645) total time=   0.3s\n",
      "[CV 4/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.841, test=0.668) total time=   0.3s\n",
      "[CV 5/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.843, test=0.640) total time=   0.3s\n",
      "[CV 1/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.848, test=0.634) total time=   0.9s\n",
      "[CV 2/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.852, test=0.690) total time=   1.0s\n",
      "[CV 3/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.853, test=0.634) total time=   1.0s\n",
      "[CV 4/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.849, test=0.665) total time=   1.0s\n",
      "[CV 5/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.848, test=0.641) total time=   1.0s\n",
      "[CV 1/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.846, test=0.647) total time=   0.4s\n",
      "[CV 2/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.848, test=0.679) total time=   0.3s\n",
      "[CV 3/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.850, test=0.632) total time=   0.3s\n",
      "[CV 4/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.846, test=0.663) total time=   0.3s\n",
      "[CV 5/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.842, test=0.639) total time=   0.3s\n",
      "[CV 1/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.846, test=0.644) total time=   0.9s\n",
      "[CV 2/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.856, test=0.678) total time=   1.1s\n",
      "[CV 3/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.852, test=0.641) total time=   1.0s\n",
      "[CV 4/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.845, test=0.658) total time=   1.0s\n",
      "[CV 5/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.847, test=0.635) total time=   1.0s\n",
      "[CV 1/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.832, test=0.654) total time=   0.4s\n",
      "[CV 2/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.822, test=0.690) total time=   0.3s\n",
      "[CV 3/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.833, test=0.638) total time=   0.3s\n",
      "[CV 4/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.830, test=0.657) total time=   0.3s\n",
      "[CV 5/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.830, test=0.637) total time=   0.3s\n",
      "[CV 1/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.831, test=0.646) total time=   0.9s\n",
      "[CV 2/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.827, test=0.682) total time=   1.0s\n",
      "[CV 3/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.835, test=0.640) total time=   1.0s\n",
      "[CV 4/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.824, test=0.668) total time=   1.0s\n",
      "[CV 5/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.831, test=0.640) total time=   1.0s\n",
      "[CV 1/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.619) total time=   0.5s\n",
      "[CV 2/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.663) total time=   0.4s\n",
      "[CV 3/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.609) total time=   0.4s\n",
      "[CV 4/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.999, test=0.623) total time=   0.4s\n",
      "[CV 5/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.603) total time=   0.4s\n",
      "[CV 1/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.631) total time=   1.1s\n",
      "[CV 2/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.678) total time=   1.2s\n",
      "[CV 3/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.604) total time=   1.2s\n",
      "[CV 4/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.642) total time=   1.1s\n",
      "[CV 5/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=1.000, test=0.608) total time=   1.1s\n",
      "[CV 1/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.947, test=0.631) total time=   0.4s\n",
      "[CV 2/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.954, test=0.682) total time=   0.3s\n",
      "[CV 3/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.945, test=0.614) total time=   0.3s\n",
      "[CV 4/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.949, test=0.656) total time=   0.3s\n",
      "[CV 5/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.945, test=0.635) total time=   0.3s\n",
      "[CV 1/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.954, test=0.642) total time=   1.0s\n",
      "[CV 2/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.958, test=0.679) total time=   1.3s\n",
      "[CV 3/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.946, test=0.626) total time=   1.4s\n",
      "[CV 4/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.951, test=0.644) total time=   1.3s\n",
      "[CV 5/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.948, test=0.625) total time=   1.1s\n",
      "[CV 1/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.881, test=0.642) total time=   0.4s\n",
      "[CV 2/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.879, test=0.679) total time=   0.4s\n",
      "[CV 3/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.874, test=0.611) total time=   0.3s\n",
      "[CV 4/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.875, test=0.647) total time=   0.4s\n",
      "[CV 5/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.875, test=0.636) total time=   0.3s\n",
      "[CV 1/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.880, test=0.642) total time=   0.9s\n",
      "[CV 2/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.888, test=0.689) total time=   1.0s\n",
      "[CV 3/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.878, test=0.633) total time=   1.1s\n",
      "[CV 4/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.881, test=0.655) total time=   1.0s\n",
      "[CV 5/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.874, test=0.634) total time=   1.1s\n",
      "[CV 1/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.920, test=0.637) total time=   0.5s\n",
      "[CV 2/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.916, test=0.675) total time=   0.3s\n",
      "[CV 3/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.923, test=0.616) total time=   0.3s\n",
      "[CV 4/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.911, test=0.662) total time=   0.3s\n",
      "[CV 5/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.904, test=0.619) total time=   0.3s\n",
      "[CV 1/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.920, test=0.637) total time=   0.9s\n",
      "[CV 2/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.923, test=0.685) total time=   1.1s\n",
      "[CV 3/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.924, test=0.621) total time=   1.1s\n",
      "[CV 4/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.918, test=0.657) total time=   1.1s\n",
      "[CV 5/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.916, test=0.625) total time=   1.1s\n",
      "[CV 1/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.908, test=0.639) total time=   0.5s\n",
      "[CV 2/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.905, test=0.679) total time=   0.4s\n",
      "[CV 3/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.902, test=0.626) total time=   0.3s\n",
      "[CV 4/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.897, test=0.647) total time=   0.3s\n",
      "[CV 5/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.893, test=0.630) total time=   0.3s\n",
      "[CV 1/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.907, test=0.634) total time=   0.9s\n",
      "[CV 2/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.910, test=0.683) total time=   1.0s\n",
      "[CV 3/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.910, test=0.640) total time=   1.1s\n",
      "[CV 4/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.905, test=0.657) total time=   1.1s\n",
      "[CV 5/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.900, test=0.631) total time=   1.0s\n",
      "[CV 1/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.857, test=0.646) total time=   0.4s\n",
      "[CV 2/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.861, test=0.683) total time=   0.3s\n",
      "[CV 3/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.860, test=0.633) total time=   0.3s\n",
      "[CV 4/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.852, test=0.676) total time=   0.3s\n",
      "[CV 5/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.842, test=0.637) total time=   0.3s\n",
      "[CV 1/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.858, test=0.637) total time=   0.9s\n",
      "[CV 2/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.859, test=0.688) total time=   1.1s\n",
      "[CV 3/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.856, test=0.634) total time=   1.0s\n",
      "[CV 4/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.853, test=0.660) total time=   1.1s\n",
      "[CV 5/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.855, test=0.639) total time=   1.0s\n",
      "[CV 1/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.850, test=0.635) total time=   0.4s\n",
      "[CV 2/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.852, test=0.680) total time=   0.3s\n",
      "[CV 3/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.851, test=0.642) total time=   0.3s\n",
      "[CV 4/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.848, test=0.651) total time=   0.3s\n",
      "[CV 5/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.846, test=0.630) total time=   0.3s\n",
      "[CV 1/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.850, test=0.634) total time=   0.9s\n",
      "[CV 2/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.853, test=0.682) total time=   1.0s\n",
      "[CV 3/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.848, test=0.641) total time=   1.0s\n",
      "[CV 4/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.847, test=0.654) total time=   1.0s\n",
      "[CV 5/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=0.850, test=0.633) total time=   1.0s\n",
      "[CV 1/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.850, test=0.651) total time=   0.4s\n",
      "[CV 2/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.849, test=0.683) total time=   0.4s\n",
      "[CV 3/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.845, test=0.634) total time=   0.3s\n",
      "[CV 4/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.849, test=0.654) total time=   0.3s\n",
      "[CV 5/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=0.845, test=0.640) total time=   0.3s\n",
      "[CV 1/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.852, test=0.643) total time=   0.9s\n",
      "[CV 2/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.853, test=0.706) total time=   1.0s\n",
      "[CV 3/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.849, test=0.638) total time=   1.0s\n",
      "[CV 4/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.848, test=0.649) total time=   1.0s\n",
      "[CV 5/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=0.850, test=0.633) total time=   1.0s\n",
      "[CV 1/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.828, test=0.632) total time=   0.4s\n",
      "[CV 2/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.828, test=0.690) total time=   0.3s\n",
      "[CV 3/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.832, test=0.637) total time=   0.3s\n",
      "[CV 4/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.829, test=0.652) total time=   0.3s\n",
      "[CV 5/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.830, test=0.643) total time=   0.3s\n",
      "[CV 1/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 1/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.828, test=0.644) total time=   0.9s\n",
      "[CV 2/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 2/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.832, test=0.694) total time=   1.0s\n",
      "[CV 3/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 3/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.828, test=0.638) total time=   1.0s\n",
      "[CV 4/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 4/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.829, test=0.661) total time=   1.0s\n",
      "[CV 5/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250\n",
      "[CV 5/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=250;, score=(train=0.833, test=0.628) total time=   1.0s\n",
      "Selected Parameters: {'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 15, 'rf__n_estimators': 100}\n",
      "Train score: 0.8692556634304207\n",
      "Test score: 0.26765799256505574\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_binary.p\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "pickle.dump(selected_params_rf_binary, open(path, \"wb\"))\r\n",
    "\r\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_rf_binary.csv\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "df_predicted_rf_binary.to_csv(path, index=False)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:3: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_binary.p'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtaining optimal features and hyperparamters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of selected features XGGBoost Binary: \r\n",
    "\r\n",
    "Selected features XGBoost Binary:\r\n",
    "\r\n",
    "\r\n",
    "Selected parameters XGBoost Binary:\r\n",
    "\r\n",
    "- Rainfall in the pipeline only looks at predictions of rainfall prior to making landfall —> rain mostly follows the typhoon\r\n",
    "- Distance and Wind data are collected only for municipalities that are close to the track\r\n",
    "    - this is too limiting for rice damage predictions as historical data shows damage can also occur further away from the track. Rainfall is a very important variable here\r\n",
    "- In wind script: find bug & correct for municipalities that are consistently missing\r\n",
    "- There is a filter on windspeed intensity and distance in the Climada package, but in the windfield grid excel sheet that is generated, there are also values outside of the threshold\r\n",
    "    - how is this possible —> general follow-up on the Climada package\r\n",
    "- Rice area is currently not included in the model (same holds for the growing stage)\r\n",
    "    - This is expected to improve model performs, but can only be included if the data is also available for new typhoons\r\n",
    "    - Discuss the type of data that is available and how this can be obtained with PRiSM\r\n",
    "    - If near-real-time rice area estimates are available: the rice area and growing stage can be included"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Setting the XGBoost search grid for full dataset\r\n",
    "xgb_search_space = [\r\n",
    "    {\r\n",
    "        \"estimator__learning_rate\": [0.1, 0.5, 1],\r\n",
    "        \"estimator__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"estimator__max_depth\": [6, 8],\r\n",
    "        \"estimator__reg_lambda\": [0.001, 0.1, 1],\r\n",
    "        \"estimator__n_estimators\": [100, 200],\r\n",
    "        \"estimator__colsample_bytree\": [0.5, 0.7],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "# Obtaining the selected features based on the full dataset\r\n",
    "selected_features_xgb_binary, selected_params_xgb_binary_full = xgb_binary_features(\r\n",
    "    X=X,\r\n",
    "    y=y,\r\n",
    "    features=features,\r\n",
    "    search_space=xgb_search_space,\r\n",
    "    objective=\"binary:hinge\",\r\n",
    "    cv_splits=5,\r\n",
    "    min_features_to_select=1,\r\n",
    "    GS_score=\"f1\",\r\n",
    "    GS_n_iter=50,\r\n",
    "    GS_randomized=True,\r\n",
    "    verbose=10,\r\n",
    ")\r\n",
    "\r\n",
    "print(f\"Number of selected features XGBoost Binary {len(selected_features_xgb_binary)}\")\r\n",
    "print(f\"Selected features XGBoost Binary: {selected_features_xgb_binary}\")\r\n",
    "print(f\"Selected parameters XGBoost Binary: {selected_params_xgb_binary_full}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5; 1/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 1/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.471) total time= 1.3min\n",
      "[CV 2/5; 1/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 1/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.511) total time= 1.2min\n",
      "[CV 3/5; 1/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 1/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.988, test=0.547) total time= 1.4min\n",
      "[CV 4/5; 1/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 1/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.489) total time= 1.4min\n",
      "[CV 5/5; 1/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 1/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.509) total time= 1.3min\n",
      "[CV 1/5; 2/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 2/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.829, test=0.526) total time=  38.3s\n",
      "[CV 2/5; 2/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 2/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.825, test=0.545) total time=  38.3s\n",
      "[CV 3/5; 2/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 2/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.827, test=0.517) total time=  38.2s\n",
      "[CV 4/5; 2/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 2/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.736, test=0.398) total time=  42.3s\n",
      "[CV 5/5; 2/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 2/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.770, test=0.561) total time=  42.1s\n",
      "[CV 1/5; 3/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 3/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.883, test=0.519) total time= 1.7min\n",
      "[CV 2/5; 3/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 3/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.964, test=0.580) total time= 1.6min\n",
      "[CV 3/5; 3/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 3/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.881, test=0.522) total time= 1.7min\n",
      "[CV 4/5; 3/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 3/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.877, test=0.604) total time= 1.6min\n",
      "[CV 5/5; 3/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 3/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.910, test=0.577) total time= 1.6min\n",
      "[CV 1/5; 4/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 1/5; 4/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.996, test=0.497) total time=  56.7s\n",
      "[CV 2/5; 4/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 2/5; 4/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.996, test=0.518) total time=  48.5s\n",
      "[CV 3/5; 4/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 3/5; 4/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.946, test=0.467) total time= 1.1min\n",
      "[CV 4/5; 4/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 4/5; 4/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.993, test=0.515) total time=  50.7s\n",
      "[CV 5/5; 4/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 5/5; 4/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.996, test=0.524) total time=  41.6s\n",
      "[CV 1/5; 5/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 5/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.996, test=0.484) total time= 1.5min\n",
      "[CV 2/5; 5/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 5/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.999, test=0.524) total time= 1.4min\n",
      "[CV 3/5; 5/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 5/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.998, test=0.470) total time= 1.5min\n",
      "[CV 4/5; 5/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 5/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=1.000, test=0.545) total time= 1.3min\n",
      "[CV 5/5; 5/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 5/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=1.000, test=0.515) total time= 1.3min\n",
      "[CV 1/5; 6/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 1/5; 6/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.798, test=0.550) total time= 1.3min\n",
      "[CV 2/5; 6/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 2/5; 6/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.834, test=0.569) total time= 1.3min\n",
      "[CV 3/5; 6/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 3/5; 6/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.713, test=0.441) total time= 1.4min\n",
      "[CV 4/5; 6/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 4/5; 6/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.837, test=0.581) total time= 1.2min\n",
      "[CV 5/5; 6/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 5/5; 6/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.870, test=0.571) total time= 1.3min\n",
      "[CV 1/5; 7/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 7/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.998, test=0.506) total time= 1.3min\n",
      "[CV 2/5; 7/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 7/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.998, test=0.488) total time= 1.5min\n",
      "[CV 3/5; 7/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 7/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.538) total time= 1.5min\n",
      "[CV 4/5; 7/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 7/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.522) total time= 1.3min\n",
      "[CV 5/5; 7/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 7/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.997, test=0.522) total time= 1.4min\n",
      "[CV 1/5; 8/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 8/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.858, test=0.543) total time= 1.0min\n",
      "[CV 2/5; 8/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 8/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.873, test=0.602) total time= 1.0min\n",
      "[CV 3/5; 8/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 8/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.886, test=0.547) total time=  58.5s\n",
      "[CV 4/5; 8/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 8/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.863, test=0.617) total time=  57.0s\n",
      "[CV 5/5; 8/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 8/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.880, test=0.600) total time=  55.4s\n",
      "[CV 1/5; 9/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 9/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.754, test=0.541) total time=  42.5s\n",
      "[CV 2/5; 9/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 9/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.782, test=0.627) total time=  42.0s\n",
      "[CV 3/5; 9/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 9/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.665, test=0.456) total time=  42.2s\n",
      "[CV 4/5; 9/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 9/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.761, test=0.609) total time=  41.9s\n",
      "[CV 5/5; 9/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 9/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.776, test=0.603) total time=  44.9s\n",
      "[CV 1/5; 10/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 10/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.999, test=0.497) total time= 1.1min\n",
      "[CV 2/5; 10/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 10/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.535) total time= 1.3min\n",
      "[CV 3/5; 10/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 10/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.999, test=0.546) total time= 1.3min\n",
      "[CV 4/5; 10/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 10/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.528) total time= 1.1min\n",
      "[CV 5/5; 10/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 10/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.999, test=0.513) total time= 1.4min\n",
      "[CV 1/5; 11/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 1/5; 11/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.999, test=0.504) total time=  45.5s\n",
      "[CV 2/5; 11/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 2/5; 11/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.920, test=0.549) total time=  50.0s\n",
      "[CV 3/5; 11/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 3/5; 11/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.969, test=0.529) total time=  50.7s\n",
      "[CV 4/5; 11/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 4/5; 11/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=1.000, test=0.485) total time=  44.6s\n",
      "[CV 5/5; 11/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 5/5; 11/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.997, test=0.514) total time=  49.6s\n",
      "[CV 1/5; 12/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 12/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.981, test=0.514) total time= 1.1min\n",
      "[CV 2/5; 12/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 12/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.985, test=0.539) total time= 1.2min\n",
      "[CV 3/5; 12/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 12/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.902, test=0.462) total time= 1.1min\n",
      "[CV 4/5; 12/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 12/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.983, test=0.529) total time= 1.1min\n",
      "[CV 5/5; 12/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 12/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.997, test=0.541) total time=  58.7s\n",
      "[CV 1/5; 13/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 13/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.903, test=0.529) total time= 1.7min\n",
      "[CV 2/5; 13/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 13/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.931, test=0.538) total time= 1.6min\n",
      "[CV 3/5; 13/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 13/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.919, test=0.550) total time= 1.6min\n",
      "[CV 4/5; 13/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 13/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.945, test=0.545) total time= 1.5min\n",
      "[CV 5/5; 13/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 13/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.906, test=0.590) total time= 1.6min\n",
      "[CV 1/5; 14/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 1/5; 14/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.998, test=0.498) total time= 1.1min\n",
      "[CV 2/5; 14/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 2/5; 14/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.999, test=0.549) total time= 1.0min\n",
      "[CV 3/5; 14/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 3/5; 14/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.997, test=0.469) total time= 1.3min\n",
      "[CV 4/5; 14/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 4/5; 14/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.997, test=0.535) total time= 1.2min\n",
      "[CV 5/5; 14/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 5/5; 14/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.508) total time= 1.2min\n",
      "[CV 1/5; 15/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 1/5; 15/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.777, test=0.541) total time= 1.4min\n",
      "[CV 2/5; 15/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 2/5; 15/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.807, test=0.617) total time= 1.3min\n",
      "[CV 3/5; 15/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 3/5; 15/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.671, test=0.476) total time= 1.4min\n",
      "[CV 4/5; 15/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 4/5; 15/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.802, test=0.599) total time= 1.3min\n",
      "[CV 5/5; 15/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 5/5; 15/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.641, test=0.566) total time= 1.4min\n",
      "[CV 1/5; 16/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 1/5; 16/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.999, test=0.438) total time=  46.6s\n",
      "[CV 2/5; 16/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 2/5; 16/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.999, test=0.551) total time=  52.3s\n",
      "[CV 3/5; 16/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 3/5; 16/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=1.000, test=0.511) total time=  49.4s\n",
      "[CV 4/5; 16/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 4/5; 16/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.997, test=0.541) total time=  49.9s\n",
      "[CV 5/5; 16/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 5/5; 16/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.995, test=0.520) total time=  48.6s\n",
      "[CV 1/5; 17/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 17/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.528) total time= 1.3min\n",
      "[CV 2/5; 17/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 17/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.942, test=0.500) total time= 1.4min\n",
      "[CV 3/5; 17/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 17/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.540) total time= 1.4min\n",
      "[CV 4/5; 17/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 17/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.513) total time= 1.4min\n",
      "[CV 5/5; 17/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 17/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.976, test=0.537) total time= 1.4min\n",
      "[CV 1/5; 18/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 18/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.838, test=0.556) total time=  58.5s\n",
      "[CV 2/5; 18/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 18/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.864, test=0.601) total time= 1.0min\n",
      "[CV 3/5; 18/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 18/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.860, test=0.564) total time= 1.1min\n",
      "[CV 4/5; 18/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 18/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.861, test=0.601) total time= 1.2min\n",
      "[CV 5/5; 18/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 18/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.884, test=0.586) total time=  57.2s\n",
      "[CV 1/5; 19/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 19/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.804, test=0.542) total time= 1.1min\n",
      "[CV 2/5; 19/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 19/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.651, test=0.482) total time= 1.2min\n",
      "[CV 3/5; 19/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 19/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.639, test=0.466) total time= 1.2min\n",
      "[CV 4/5; 19/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 19/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.825, test=0.588) total time= 1.2min\n",
      "[CV 5/5; 19/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 19/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.655, test=0.578) total time= 1.2min\n",
      "[CV 1/5; 20/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 1/5; 20/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.998, test=0.538) total time=  50.3s\n",
      "[CV 2/5; 20/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 2/5; 20/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.999, test=0.485) total time=  46.4s\n",
      "[CV 3/5; 20/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 3/5; 20/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.992, test=0.507) total time=  52.4s\n",
      "[CV 4/5; 20/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 4/5; 20/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.998, test=0.516) total time=  53.4s\n",
      "[CV 5/5; 20/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 5/5; 20/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.998, test=0.518) total time=  51.8s\n",
      "[CV 1/5; 21/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 1/5; 21/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.747, test=0.557) total time=  43.8s\n",
      "[CV 2/5; 21/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 2/5; 21/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.783, test=0.613) total time=  45.2s\n",
      "[CV 3/5; 21/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 3/5; 21/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.666, test=0.453) total time=  49.3s\n",
      "[CV 4/5; 21/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 4/5; 21/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.782, test=0.606) total time=  45.4s\n",
      "[CV 5/5; 21/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 5/5; 21/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.759, test=0.601) total time=  47.5s\n",
      "[CV 1/5; 22/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 1/5; 22/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.493) total time= 1.4min\n",
      "[CV 2/5; 22/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 2/5; 22/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.513) total time= 1.5min\n",
      "[CV 3/5; 22/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 3/5; 22/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.535) total time= 1.4min\n",
      "[CV 4/5; 22/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 4/5; 22/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.560) total time= 1.4min\n",
      "[CV 5/5; 22/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 5/5; 22/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.975, test=0.514) total time= 1.5min\n",
      "[CV 1/5; 23/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 1/5; 23/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.898, test=0.538) total time= 1.2min\n",
      "[CV 2/5; 23/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 2/5; 23/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.881, test=0.543) total time= 1.2min\n",
      "[CV 3/5; 23/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 3/5; 23/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.921, test=0.555) total time= 1.2min\n",
      "[CV 4/5; 23/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 4/5; 23/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.974, test=0.523) total time= 1.1min\n",
      "[CV 5/5; 23/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 5/5; 23/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.836, test=0.554) total time= 1.2min\n",
      "[CV 1/5; 24/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 24/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.996, test=0.530) total time= 1.1min\n",
      "[CV 2/5; 24/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 24/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.997, test=0.505) total time=  59.2s\n",
      "[CV 3/5; 24/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 24/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.891, test=0.465) total time= 1.2min\n",
      "[CV 4/5; 24/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 24/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.995, test=0.487) total time= 1.2min\n",
      "[CV 5/5; 24/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 24/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.964, test=0.549) total time= 1.3min\n",
      "[CV 1/5; 25/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 25/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.835, test=0.567) total time=  40.3s\n",
      "[CV 2/5; 25/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 25/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.830, test=0.566) total time=  42.6s\n",
      "[CV 3/5; 25/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 25/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.749, test=0.491) total time=  36.8s\n",
      "[CV 4/5; 25/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 25/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.730, test=0.543) total time=  35.6s\n",
      "[CV 5/5; 25/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 25/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.747, test=0.557) total time=  36.7s\n",
      "[CV 1/5; 26/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 26/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.796, test=0.545) total time= 1.1min\n",
      "[CV 2/5; 26/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 26/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.658, test=0.507) total time= 1.1min\n",
      "[CV 3/5; 26/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 26/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.661, test=0.467) total time= 1.1min\n",
      "[CV 4/5; 26/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 26/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.831, test=0.600) total time= 1.0min\n",
      "[CV 5/5; 26/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 26/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.640, test=0.565) total time= 1.1min\n",
      "[CV 1/5; 27/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 27/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.890, test=0.551) total time= 1.1min\n",
      "[CV 2/5; 27/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 27/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.958, test=0.545) total time= 1.0min\n",
      "[CV 3/5; 27/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 27/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.818, test=0.476) total time= 1.1min\n",
      "[CV 4/5; 27/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 27/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.874, test=0.561) total time= 1.1min\n",
      "[CV 5/5; 27/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 27/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.837, test=0.543) total time= 1.1min\n",
      "[CV 1/5; 28/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 28/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.893, test=0.514) total time=  34.9s\n",
      "[CV 2/5; 28/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 28/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.910, test=0.539) total time=  34.7s\n",
      "[CV 3/5; 28/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 28/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.806, test=0.477) total time=  35.9s\n",
      "[CV 4/5; 28/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 28/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.876, test=0.583) total time=  34.7s\n",
      "[CV 5/5; 28/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 28/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.920, test=0.562) total time=  37.6s\n",
      "[CV 1/5; 29/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 29/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.993, test=0.525) total time= 1.1min\n",
      "[CV 2/5; 29/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 29/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.933, test=0.544) total time= 1.2min\n",
      "[CV 3/5; 29/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 29/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.874, test=0.509) total time= 1.2min\n",
      "[CV 4/5; 29/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 29/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.996, test=0.541) total time=  57.6s\n",
      "[CV 5/5; 29/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 29/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.913, test=0.542) total time= 1.2min\n",
      "[CV 1/5; 30/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 30/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.891, test=0.526) total time= 1.1min\n",
      "[CV 2/5; 30/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 30/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.863, test=0.536) total time= 1.1min\n",
      "[CV 3/5; 30/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 30/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.825, test=0.451) total time= 1.1min\n",
      "[CV 4/5; 30/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 30/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.951, test=0.548) total time= 1.1min\n",
      "[CV 5/5; 30/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 30/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.899, test=0.536) total time= 1.2min\n",
      "[CV 1/5; 31/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 31/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.999, test=0.481) total time= 1.6min\n",
      "[CV 2/5; 31/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 31/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.998, test=0.501) total time= 1.5min\n",
      "[CV 3/5; 31/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 31/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.998, test=0.511) total time= 1.6min\n",
      "[CV 4/5; 31/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 31/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.998, test=0.508) total time= 1.4min\n",
      "[CV 5/5; 31/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 31/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.999, test=0.500) total time= 1.3min\n",
      "[CV 1/5; 32/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 1/5; 32/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=1.000, test=0.486) total time=  43.4s\n",
      "[CV 2/5; 32/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 2/5; 32/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.995, test=0.528) total time=  50.3s\n",
      "[CV 3/5; 32/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 3/5; 32/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.965, test=0.532) total time=  49.6s\n",
      "[CV 4/5; 32/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 4/5; 32/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=1.000, test=0.546) total time=  47.0s\n",
      "[CV 5/5; 32/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 5/5; 32/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.972, test=0.549) total time=  50.5s\n",
      "[CV 1/5; 33/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 1/5; 33/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.862, test=0.537) total time=  40.9s\n",
      "[CV 2/5; 33/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 2/5; 33/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.853, test=0.484) total time=  46.1s\n",
      "[CV 3/5; 33/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 3/5; 33/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.860, test=0.476) total time=  40.2s\n",
      "[CV 4/5; 33/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 4/5; 33/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.969, test=0.543) total time=  39.6s\n",
      "[CV 5/5; 33/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 5/5; 33/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.908, test=0.570) total time=  38.8s\n",
      "[CV 1/5; 34/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 34/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.858, test=0.508) total time= 1.2min\n",
      "[CV 2/5; 34/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 34/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.944, test=0.497) total time= 1.1min\n",
      "[CV 3/5; 34/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 34/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.809, test=0.444) total time= 1.2min\n",
      "[CV 4/5; 34/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 34/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.860, test=0.552) total time= 1.1min\n",
      "[CV 5/5; 34/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 34/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.850, test=0.546) total time= 1.2min\n",
      "[CV 1/5; 35/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 35/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.993, test=0.556) total time=  52.4s\n",
      "[CV 2/5; 35/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 35/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.996, test=0.499) total time=  49.3s\n",
      "[CV 3/5; 35/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 35/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.997, test=0.498) total time=  48.0s\n",
      "[CV 4/5; 35/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 35/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=1.000, test=0.513) total time=  45.2s\n",
      "[CV 5/5; 35/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 35/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.994, test=0.571) total time=  51.5s\n",
      "[CV 1/5; 36/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 36/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.829, test=0.526) total time=  37.8s\n",
      "[CV 2/5; 36/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 36/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.825, test=0.545) total time=  37.2s\n",
      "[CV 3/5; 36/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 36/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.790, test=0.486) total time=  38.5s\n",
      "[CV 4/5; 36/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 36/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.768, test=0.527) total time=  38.2s\n",
      "[CV 5/5; 36/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 36/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.854, test=0.555) total time=  43.2s\n",
      "[CV 1/5; 37/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 1/5; 37/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.814, test=0.549) total time= 1.6min\n",
      "[CV 2/5; 37/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 2/5; 37/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.804, test=0.626) total time= 1.5min\n",
      "[CV 3/5; 37/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 3/5; 37/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.793, test=0.531) total time= 1.6min\n",
      "[CV 4/5; 37/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 4/5; 37/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.804, test=0.611) total time= 1.5min\n",
      "[CV 5/5; 37/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 5/5; 37/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.802, test=0.595) total time= 1.5min\n",
      "[CV 1/5; 38/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 38/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.832, test=0.544) total time=  43.1s\n",
      "[CV 2/5; 38/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 38/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.785, test=0.545) total time=  43.6s\n",
      "[CV 3/5; 38/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 38/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.886, test=0.573) total time=  41.3s\n",
      "[CV 4/5; 38/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 38/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.802, test=0.530) total time=  42.9s\n",
      "[CV 5/5; 38/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 38/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.906, test=0.528) total time=  36.5s\n",
      "[CV 1/5; 39/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 39/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.995, test=0.518) total time= 1.3min\n",
      "[CV 2/5; 39/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 39/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.994, test=0.505) total time= 1.2min\n",
      "[CV 3/5; 39/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 39/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.882, test=0.497) total time= 1.3min\n",
      "[CV 4/5; 39/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 39/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.996, test=0.511) total time= 1.3min\n",
      "[CV 5/5; 39/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 39/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.941, test=0.538) total time= 1.4min\n",
      "[CV 1/5; 40/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 40/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.901, test=0.539) total time= 1.8min\n",
      "[CV 2/5; 40/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 40/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.709, test=0.494) total time= 1.8min\n",
      "[CV 3/5; 40/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 40/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.715, test=0.455) total time= 1.8min\n",
      "[CV 4/5; 40/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 40/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.927, test=0.577) total time= 1.8min\n",
      "[CV 5/5; 40/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 40/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.715, test=0.544) total time= 1.8min\n",
      "[CV 1/5; 41/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 41/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.993, test=0.556) total time=  57.8s\n",
      "[CV 2/5; 41/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 41/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.978, test=0.517) total time=  58.9s\n",
      "[CV 3/5; 41/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 41/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.998, test=0.512) total time=  57.4s\n",
      "[CV 4/5; 41/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 41/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.984, test=0.486) total time=  59.9s\n",
      "[CV 5/5; 41/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 41/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.1;, score=(train=0.999, test=0.502) total time=  56.5s\n",
      "[CV 1/5; 42/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 42/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.998, test=0.550) total time=  56.8s\n",
      "[CV 2/5; 42/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 42/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.998, test=0.514) total time=  57.6s\n",
      "[CV 3/5; 42/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 42/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.996, test=0.521) total time=  56.9s\n",
      "[CV 4/5; 42/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 42/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.979, test=0.526) total time=  59.0s\n",
      "[CV 5/5; 42/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 42/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.996, test=0.522) total time=  57.0s\n",
      "[CV 1/5; 43/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 43/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.771, test=0.540) total time= 1.4min\n",
      "[CV 2/5; 43/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 43/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.860, test=0.571) total time= 1.3min\n",
      "[CV 3/5; 43/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 43/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.785, test=0.562) total time= 1.4min\n",
      "[CV 4/5; 43/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 43/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.789, test=0.600) total time= 1.4min\n",
      "[CV 5/5; 43/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 43/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.797, test=0.601) total time= 1.4min\n",
      "[CV 1/5; 44/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 1/5; 44/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.507) total time= 1.6min\n",
      "[CV 2/5; 44/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 2/5; 44/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.499) total time= 1.6min\n",
      "[CV 3/5; 44/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 3/5; 44/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.502) total time= 1.6min\n",
      "[CV 4/5; 44/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 4/5; 44/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.535) total time= 1.3min\n",
      "[CV 5/5; 44/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 5/5; 44/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.563) total time= 1.6min\n",
      "[CV 1/5; 45/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 45/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.991, test=0.535) total time=  57.5s\n",
      "[CV 2/5; 45/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 45/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.998, test=0.454) total time=  56.7s\n",
      "[CV 3/5; 45/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 45/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.998, test=0.474) total time=  53.8s\n",
      "[CV 4/5; 45/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 45/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=0.961, test=0.525) total time=  58.6s\n",
      "[CV 5/5; 45/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 45/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.508) total time=  50.8s\n",
      "[CV 1/5; 46/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 1/5; 46/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.530) total time= 1.7min\n",
      "[CV 2/5; 46/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 2/5; 46/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.527) total time= 1.4min\n",
      "[CV 3/5; 46/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 3/5; 46/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.982, test=0.468) total time= 1.8min\n",
      "[CV 4/5; 46/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 4/5; 46/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.548) total time= 1.2min\n",
      "[CV 5/5; 46/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[CV 5/5; 46/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.500) total time= 1.7min\n",
      "[CV 1/5; 47/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 47/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.446) total time= 1.4min\n",
      "[CV 2/5; 47/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 47/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.523) total time= 1.6min\n",
      "[CV 3/5; 47/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 47/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.986, test=0.517) total time= 1.4min\n",
      "[CV 4/5; 47/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 47/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.505) total time= 1.4min\n",
      "[CV 5/5; 47/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 47/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.985, test=0.510) total time= 1.4min\n",
      "[CV 1/5; 48/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 1/5; 48/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.806, test=0.558) total time= 1.1min\n",
      "[CV 2/5; 48/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 2/5; 48/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.818, test=0.568) total time= 1.1min\n",
      "[CV 3/5; 48/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 3/5; 48/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.674, test=0.439) total time= 1.3min\n",
      "[CV 4/5; 48/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 4/5; 48/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.842, test=0.573) total time= 1.1min\n",
      "[CV 5/5; 48/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[CV 5/5; 48/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.820, test=0.593) total time= 1.2min\n",
      "[CV 1/5; 49/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 1/5; 49/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.995, test=0.536) total time= 1.4min\n",
      "[CV 2/5; 49/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 2/5; 49/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.501) total time= 1.3min\n",
      "[CV 3/5; 49/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 3/5; 49/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=0.980, test=0.480) total time= 1.5min\n",
      "[CV 4/5; 49/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 4/5; 49/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.541) total time= 1.3min\n",
      "[CV 5/5; 49/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001\n",
      "[CV 5/5; 49/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.529) total time= 1.5min\n",
      "[CV 1/5; 50/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 1/5; 50/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.846, test=0.540) total time= 1.3min\n",
      "[CV 2/5; 50/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 2/5; 50/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.880, test=0.593) total time= 1.2min\n",
      "[CV 3/5; 50/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 3/5; 50/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.885, test=0.551) total time= 1.5min\n",
      "[CV 4/5; 50/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 4/5; 50/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.876, test=0.595) total time= 1.5min\n",
      "[CV 5/5; 50/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[CV 5/5; 50/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.859, test=0.575) total time= 1.7min\n",
      "Number of selected features XGBoost Binary 3\n",
      "Selected features XGBoost Binary: ['rainfall_max_6h', 'dis_track_min', 'vmax']\n",
      "Selected parameters XGBoost Binary: {'estimator__reg_lambda': 1, 'estimator__n_estimators': 200, 'estimator__max_depth': 6, 'estimator__learning_rate': 0.1, 'estimator__gamma': 0.1, 'estimator__colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtaining performance estimate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the selected features for XGB --> based on outcome previous cell\r\n",
    "selected_features_xgb_binary = [\r\n",
    "    'rice_area', \r\n",
    "    'mean_slope', \r\n",
    "    'mean_elevation_m', \r\n",
    "    'ruggedness_stdev', \r\n",
    "    'mean_ruggedness', \r\n",
    "    'slope_stdev', \r\n",
    "    'area_km2', \r\n",
    "    'poverty_perc', \r\n",
    "    'with_coast', \r\n",
    "    'coast_length', \r\n",
    "    'perimeter', \r\n",
    "    'glat', \r\n",
    "    'glon', \r\n",
    "    'coast_peri_ratio', \r\n",
    "    'rainfall_sum', \r\n",
    "    'rainfall_max', \r\n",
    "    'dis_track_min', \r\n",
    "    'vmax_sust'\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Setting the XGBoost search grid\r\n",
    "xgb_search_space = [\r\n",
    "    {\r\n",
    "        \"xgb__learning_rate\": [0.1, 0.5, 1],\r\n",
    "        \"xgb__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"xgb__max_depth\": [6, 8],\r\n",
    "        \"xgb__reg_lambda\": [0.001, 0.1, 1],\r\n",
    "        \"xgb__n_estimators\": [100, 200],\r\n",
    "        \"xgb__colsample_bytree\": [0.5, 0.7],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "# Obtaining the performance estimate\r\n",
    "df_predicted_xgb_binary, selected_params_xgb_binary = xgb_binary_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    features=selected_features_xgb_binary,\r\n",
    "    search_space=xgb_search_space,\r\n",
    "    stratK=True,\r\n",
    "    cv_splits=5,\r\n",
    "    objective=\"binary:hinge\",\r\n",
    "    GS_score=\"f1\",\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=50,\r\n",
    "    verbose=10,\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running for 1 out of a total of 5\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5; 1/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 1/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.994, test=0.510) total time=   0.3s\n",
      "[CV 2/5; 1/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 1/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.996, test=0.509) total time=   0.2s\n",
      "[CV 3/5; 1/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 1/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.996, test=0.478) total time=   0.3s\n",
      "[CV 4/5; 1/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 1/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.989, test=0.522) total time=   0.2s\n",
      "[CV 5/5; 1/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 1/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.982, test=0.550) total time=   0.3s\n",
      "[CV 1/5; 2/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 2/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.916, test=0.570) total time=   0.1s\n",
      "[CV 2/5; 2/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 2/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.897, test=0.569) total time=   0.1s\n",
      "[CV 3/5; 2/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 2/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.924, test=0.527) total time=   0.1s\n",
      "[CV 4/5; 2/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 2/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.920, test=0.563) total time=   0.1s\n",
      "[CV 5/5; 2/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 2/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.889, test=0.598) total time=   0.1s\n",
      "[CV 1/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.849, test=0.582) total time=   0.1s\n",
      "[CV 2/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.836, test=0.597) total time=   0.1s\n",
      "[CV 3/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.849, test=0.582) total time=   0.1s\n",
      "[CV 4/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.804, test=0.626) total time=   0.1s\n",
      "[CV 5/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.873, test=0.647) total time=   0.1s\n",
      "[CV 1/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.907, test=0.556) total time=   0.1s\n",
      "[CV 2/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.964, test=0.608) total time=   0.1s\n",
      "[CV 3/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.895, test=0.502) total time=   0.1s\n",
      "[CV 4/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.920, test=0.603) total time=   0.1s\n",
      "[CV 5/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.923, test=0.575) total time=   0.1s\n",
      "[CV 1/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.942, test=0.478) total time=   0.3s\n",
      "[CV 2/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.979, test=0.516) total time=   0.3s\n",
      "[CV 3/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.964, test=0.481) total time=   0.3s\n",
      "[CV 4/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.958, test=0.484) total time=   0.2s\n",
      "[CV 5/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.964, test=0.542) total time=   0.3s\n",
      "[CV 1/5; 6/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 6/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.857, test=0.601) total time=   0.1s\n",
      "[CV 2/5; 6/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 6/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.826, test=0.614) total time=   0.1s\n",
      "[CV 3/5; 6/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 6/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.856, test=0.581) total time=   0.2s\n",
      "[CV 4/5; 6/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 6/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.820, test=0.640) total time=   0.1s\n",
      "[CV 5/5; 6/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 6/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.865, test=0.645) total time=   0.2s\n",
      "[CV 1/5; 7/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 7/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=1.000, test=0.543) total time=   0.2s\n",
      "[CV 2/5; 7/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 7/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=1.000, test=0.589) total time=   0.2s\n",
      "[CV 3/5; 7/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 7/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=1.000, test=0.518) total time=   0.2s\n",
      "[CV 4/5; 7/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 7/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=1.000, test=0.568) total time=   0.2s\n",
      "[CV 5/5; 7/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 7/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=1.000, test=0.571) total time=   0.2s\n",
      "[CV 1/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.940, test=0.564) total time=   0.2s\n",
      "[CV 2/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.943, test=0.623) total time=   0.2s\n",
      "[CV 3/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.939, test=0.581) total time=   0.2s\n",
      "[CV 4/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.934, test=0.632) total time=   0.2s\n",
      "[CV 5/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.938, test=0.606) total time=   0.2s\n",
      "[CV 1/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.498) total time=   0.4s\n",
      "[CV 2/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.643) total time=   0.4s\n",
      "[CV 3/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.518) total time=   0.4s\n",
      "[CV 4/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.540) total time=   0.4s\n",
      "[CV 5/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.553) total time=   0.3s\n",
      "[CV 1/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.975, test=0.538) total time=   0.3s\n",
      "[CV 2/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.959, test=0.590) total time=   0.3s\n",
      "[CV 3/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.961, test=0.510) total time=   0.3s\n",
      "[CV 4/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.978, test=0.574) total time=   0.3s\n",
      "[CV 5/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.984, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 11/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 11/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.605) total time=   0.2s\n",
      "[CV 2/5; 11/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 11/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.591) total time=   0.2s\n",
      "[CV 3/5; 11/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 11/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.498) total time=   0.2s\n",
      "[CV 4/5; 11/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 11/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.995, test=0.553) total time=   0.2s\n",
      "[CV 5/5; 11/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 11/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.577) total time=   0.2s\n",
      "[CV 1/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.552) total time=   0.3s\n",
      "[CV 2/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.580) total time=   0.3s\n",
      "[CV 3/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.541) total time=   0.4s\n",
      "[CV 4/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.588) total time=   0.5s\n",
      "[CV 5/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.524) total time=   0.3s\n",
      "[CV 1/5; 13/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 13/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.985, test=0.560) total time=   0.5s\n",
      "[CV 2/5; 13/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 13/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.982, test=0.609) total time=   0.5s\n",
      "[CV 3/5; 13/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 13/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.986, test=0.538) total time=   0.5s\n",
      "[CV 4/5; 13/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 13/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.983, test=0.582) total time=   0.5s\n",
      "[CV 5/5; 13/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 13/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.974, test=0.581) total time=   0.5s\n",
      "[CV 1/5; 14/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 14/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.991, test=0.504) total time=   0.3s\n",
      "[CV 2/5; 14/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 14/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.990, test=0.526) total time=   0.3s\n",
      "[CV 3/5; 14/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 14/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.997, test=0.516) total time=   0.3s\n",
      "[CV 4/5; 14/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 14/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.989, test=0.501) total time=   0.3s\n",
      "[CV 5/5; 14/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 14/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.994, test=0.563) total time=   0.3s\n",
      "[CV 1/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.910, test=0.505) total time=   0.2s\n",
      "[CV 2/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.920, test=0.540) total time=   0.2s\n",
      "[CV 3/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.904, test=0.557) total time=   0.3s\n",
      "[CV 4/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.904, test=0.563) total time=   0.3s\n",
      "[CV 5/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.910, test=0.561) total time=   0.3s\n",
      "[CV 1/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.943, test=0.483) total time=   0.1s\n",
      "[CV 2/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.904, test=0.532) total time=   0.2s\n",
      "[CV 3/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.957, test=0.486) total time=   0.1s\n",
      "[CV 4/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.952, test=0.499) total time=   0.1s\n",
      "[CV 5/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.929, test=0.524) total time=   0.1s\n",
      "[CV 1/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.996, test=0.503) total time=   0.2s\n",
      "[CV 2/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.532) total time=   0.2s\n",
      "[CV 3/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.994, test=0.481) total time=   0.2s\n",
      "[CV 4/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.994, test=0.509) total time=   0.2s\n",
      "[CV 5/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.996, test=0.566) total time=   0.2s\n",
      "[CV 1/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.904, test=0.487) total time=   0.1s\n",
      "[CV 2/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.884, test=0.523) total time=   0.1s\n",
      "[CV 3/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.926, test=0.472) total time=   0.1s\n",
      "[CV 4/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.908, test=0.510) total time=   0.1s\n",
      "[CV 5/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.890, test=0.588) total time=   0.1s\n",
      "[CV 1/5; 19/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 19/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.498) total time=   0.4s\n",
      "[CV 2/5; 19/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 19/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.603) total time=   0.4s\n",
      "[CV 3/5; 19/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 19/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.535) total time=   0.3s\n",
      "[CV 4/5; 19/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 19/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.582) total time=   0.3s\n",
      "[CV 5/5; 19/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 19/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.560) total time=   0.3s\n",
      "[CV 1/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.562) total time=   0.2s\n",
      "[CV 2/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.591) total time=   0.2s\n",
      "[CV 3/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.520) total time=   0.2s\n",
      "[CV 4/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.591) total time=   0.2s\n",
      "[CV 5/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.579) total time=   0.2s\n",
      "[CV 1/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.560) total time=   0.2s\n",
      "[CV 2/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.614) total time=   0.2s\n",
      "[CV 3/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.552) total time=   0.2s\n",
      "[CV 4/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.509) total time=   0.2s\n",
      "[CV 5/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.570) total time=   0.2s\n",
      "[CV 1/5; 22/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 22/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.502) total time=   0.4s\n",
      "[CV 2/5; 22/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 22/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.537) total time=   0.4s\n",
      "[CV 3/5; 22/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 22/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.517) total time=   0.4s\n",
      "[CV 4/5; 22/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 22/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.508) total time=   0.4s\n",
      "[CV 5/5; 22/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 22/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.533) total time=   0.4s\n",
      "[CV 1/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.903, test=0.569) total time=   0.1s\n",
      "[CV 2/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.922, test=0.530) total time=   0.1s\n",
      "[CV 3/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.949, test=0.523) total time=   0.1s\n",
      "[CV 4/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.895, test=0.562) total time=   0.1s\n",
      "[CV 5/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.928, test=0.584) total time=   0.1s\n",
      "[CV 1/5; 24/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 24/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.985, test=0.578) total time=   0.5s\n",
      "[CV 2/5; 24/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 24/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.955, test=0.608) total time=   0.5s\n",
      "[CV 3/5; 24/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 24/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.977, test=0.540) total time=   0.5s\n",
      "[CV 4/5; 24/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 24/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.969, test=0.583) total time=   0.5s\n",
      "[CV 5/5; 24/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 24/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.978, test=0.601) total time=   0.5s\n",
      "[CV 1/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.814, test=0.515) total time=   0.1s\n",
      "[CV 2/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.820, test=0.581) total time=   0.2s\n",
      "[CV 3/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.813, test=0.557) total time=   0.1s\n",
      "[CV 4/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.799, test=0.570) total time=   0.1s\n",
      "[CV 5/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.811, test=0.573) total time=   0.2s\n",
      "[CV 1/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.497) total time=   0.2s\n",
      "[CV 2/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=1.000, test=0.503) total time=   0.2s\n",
      "[CV 3/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.476) total time=   0.2s\n",
      "[CV 4/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.517) total time=   0.2s\n",
      "[CV 5/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.530) total time=   0.2s\n",
      "[CV 1/5; 27/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 27/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.808, test=0.542) total time=   0.2s\n",
      "[CV 2/5; 27/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 27/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.821, test=0.618) total time=   0.1s\n",
      "[CV 3/5; 27/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 27/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.813, test=0.568) total time=   0.1s\n",
      "[CV 4/5; 27/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 27/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.794, test=0.592) total time=   0.1s\n",
      "[CV 5/5; 27/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 27/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.806, test=0.581) total time=   0.1s\n",
      "[CV 1/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.491) total time=   0.4s\n",
      "[CV 2/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.530) total time=   0.4s\n",
      "[CV 3/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.522) total time=   0.4s\n",
      "[CV 4/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.515) total time=   0.4s\n",
      "[CV 5/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.521) total time=   0.4s\n",
      "[CV 1/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.949, test=0.513) total time=   0.1s\n",
      "[CV 2/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.945, test=0.496) total time=   0.1s\n",
      "[CV 3/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.922, test=0.521) total time=   0.1s\n",
      "[CV 4/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.944, test=0.517) total time=   0.1s\n",
      "[CV 5/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.951, test=0.575) total time=   0.1s\n",
      "[CV 1/5; 30/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 30/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.569) total time=   0.3s\n",
      "[CV 2/5; 30/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 30/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.591) total time=   0.3s\n",
      "[CV 3/5; 30/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 30/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.571) total time=   0.3s\n",
      "[CV 4/5; 30/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 30/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.554) total time=   0.3s\n",
      "[CV 5/5; 30/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 30/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.596) total time=   0.3s\n",
      "[CV 1/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.841, test=0.514) total time=   0.1s\n",
      "[CV 2/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.871, test=0.571) total time=   0.2s\n",
      "[CV 3/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.879, test=0.544) total time=   0.1s\n",
      "[CV 4/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.866, test=0.543) total time=   0.1s\n",
      "[CV 5/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.868, test=0.560) total time=   0.1s\n",
      "[CV 1/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.790, test=0.539) total time=   0.2s\n",
      "[CV 2/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.789, test=0.606) total time=   0.1s\n",
      "[CV 3/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.798, test=0.614) total time=   0.2s\n",
      "[CV 4/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.780, test=0.584) total time=   0.2s\n",
      "[CV 5/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.792, test=0.586) total time=   0.1s\n",
      "[CV 1/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=1.000, test=0.539) total time=   0.2s\n",
      "[CV 2/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.606) total time=   0.2s\n",
      "[CV 3/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.544) total time=   0.2s\n",
      "[CV 4/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.599) total time=   0.2s\n",
      "[CV 5/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.558) total time=   0.2s\n",
      "[CV 1/5; 34/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 34/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.936, test=0.490) total time=   0.1s\n",
      "[CV 2/5; 34/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 34/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.923, test=0.524) total time=   0.1s\n",
      "[CV 3/5; 34/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 34/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.934, test=0.504) total time=   0.1s\n",
      "[CV 4/5; 34/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 34/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.936, test=0.513) total time=   0.1s\n",
      "[CV 5/5; 34/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 34/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.912, test=0.549) total time=   0.1s\n",
      "[CV 1/5; 35/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 35/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.522) total time=   0.2s\n",
      "[CV 2/5; 35/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 35/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.628) total time=   0.2s\n",
      "[CV 3/5; 35/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 35/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.517) total time=   0.2s\n",
      "[CV 4/5; 35/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 35/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.551) total time=   0.2s\n",
      "[CV 5/5; 35/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 35/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.557) total time=   0.2s\n",
      "[CV 1/5; 36/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 36/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.565) total time=   0.3s\n",
      "[CV 2/5; 36/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 36/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.565) total time=   0.3s\n",
      "[CV 3/5; 36/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 36/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.518) total time=   0.3s\n",
      "[CV 4/5; 36/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 36/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.549) total time=   0.3s\n",
      "[CV 5/5; 36/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 36/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.577) total time=   0.3s\n",
      "[CV 1/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.996, test=0.516) total time=   0.3s\n",
      "[CV 2/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.992, test=0.526) total time=   0.3s\n",
      "[CV 3/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.506) total time=   0.3s\n",
      "[CV 4/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.991, test=0.477) total time=   0.3s\n",
      "[CV 5/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.983, test=0.553) total time=   0.3s\n",
      "[CV 1/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.502) total time=   0.4s\n",
      "[CV 2/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.507) total time=   0.4s\n",
      "[CV 3/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.473) total time=   0.4s\n",
      "[CV 4/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.568) total time=   0.4s\n",
      "[CV 5/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.530) total time=   0.4s\n",
      "[CV 1/5; 39/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 39/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.994, test=0.487) total time=   0.3s\n",
      "[CV 2/5; 39/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 39/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.995, test=0.516) total time=   0.4s\n",
      "[CV 3/5; 39/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 39/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.994, test=0.479) total time=   0.3s\n",
      "[CV 4/5; 39/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 39/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.990, test=0.543) total time=   0.3s\n",
      "[CV 5/5; 39/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 39/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.994, test=0.522) total time=   0.4s\n",
      "[CV 1/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.529) total time=   0.3s\n",
      "[CV 2/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.477) total time=   0.3s\n",
      "[CV 3/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.506) total time=   0.3s\n",
      "[CV 4/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.450) total time=   0.3s\n",
      "[CV 5/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.520) total time=   0.3s\n",
      "[CV 1/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.985, test=0.545) total time=   0.1s\n",
      "[CV 2/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.975, test=0.499) total time=   0.1s\n",
      "[CV 3/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.982, test=0.531) total time=   0.1s\n",
      "[CV 4/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.967, test=0.507) total time=   0.1s\n",
      "[CV 5/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.976, test=0.551) total time=   0.1s\n",
      "[CV 1/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.927, test=0.480) total time=   0.1s\n",
      "[CV 2/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.936, test=0.527) total time=   0.1s\n",
      "[CV 3/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.934, test=0.493) total time=   0.2s\n",
      "[CV 4/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.916, test=0.494) total time=   0.1s\n",
      "[CV 5/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.924, test=0.536) total time=   0.1s\n",
      "[CV 1/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.498) total time=   0.2s\n",
      "[CV 2/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.524) total time=   0.2s\n",
      "[CV 3/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.491) total time=   0.2s\n",
      "[CV 4/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.994, test=0.514) total time=   0.2s\n",
      "[CV 5/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.995, test=0.543) total time=   0.2s\n",
      "[CV 1/5; 44/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 44/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.998, test=0.555) total time=   0.2s\n",
      "[CV 2/5; 44/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 44/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=1.000, test=0.590) total time=   0.2s\n",
      "[CV 3/5; 44/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 44/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.997, test=0.513) total time=   0.2s\n",
      "[CV 4/5; 44/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 44/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.996, test=0.539) total time=   0.2s\n",
      "[CV 5/5; 44/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 44/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.551) total time=   0.2s\n",
      "[CV 1/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.492) total time=   0.2s\n",
      "[CV 2/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.615) total time=   0.2s\n",
      "[CV 3/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.559) total time=   0.2s\n",
      "[CV 4/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.538) total time=   0.2s\n",
      "[CV 5/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.552) total time=   0.2s\n",
      "[CV 1/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.971, test=0.491) total time=   0.1s\n",
      "[CV 2/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.974, test=0.530) total time=   0.1s\n",
      "[CV 3/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.988, test=0.463) total time=   0.1s\n",
      "[CV 4/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.984, test=0.496) total time=   0.2s\n",
      "[CV 5/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.974, test=0.540) total time=   0.1s\n",
      "[CV 1/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.822, test=0.528) total time=   0.4s\n",
      "[CV 2/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.814, test=0.583) total time=   0.3s\n",
      "[CV 3/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.836, test=0.598) total time=   0.3s\n",
      "[CV 4/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.829, test=0.569) total time=   0.4s\n",
      "[CV 5/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.817, test=0.577) total time=   0.3s\n",
      "[CV 1/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.995, test=0.451) total time=   0.2s\n",
      "[CV 2/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.996, test=0.528) total time=   0.2s\n",
      "[CV 3/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.998, test=0.455) total time=   0.2s\n",
      "[CV 4/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.996, test=0.500) total time=   0.2s\n",
      "[CV 5/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.994, test=0.491) total time=   0.2s\n",
      "[CV 1/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.975, test=0.510) total time=   0.1s\n",
      "[CV 2/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.991, test=0.580) total time=   0.1s\n",
      "[CV 3/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.986, test=0.491) total time=   0.1s\n",
      "[CV 4/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.964, test=0.518) total time=   0.1s\n",
      "[CV 5/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.976, test=0.588) total time=   0.1s\n",
      "[CV 1/5; 50/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 50/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.824, test=0.531) total time=   0.3s\n",
      "[CV 2/5; 50/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 50/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.784, test=0.574) total time=   0.3s\n",
      "[CV 3/5; 50/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 50/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.809, test=0.572) total time=   0.4s\n",
      "[CV 4/5; 50/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 50/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.804, test=0.535) total time=   0.4s\n",
      "[CV 5/5; 50/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 50/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.801, test=0.577) total time=   0.4s\n",
      "Selected Parameters: {'xgb__reg_lambda': 0.1, 'xgb__n_estimators': 100, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__colsample_bytree': 0.7}\n",
      "Train score: 0.8410256410256411\n",
      "Test score: 0.6882591093117408\n",
      "Running for 2 out of a total of 5\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.928, test=0.635) total time=   0.3s\n",
      "[CV 2/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.938, test=0.597) total time=   1.3s\n",
      "[CV 3/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.944, test=0.622) total time=   0.7s\n",
      "[CV 4/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.936, test=0.640) total time=   0.4s\n",
      "[CV 5/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.923, test=0.609) total time=   0.4s\n",
      "[CV 1/5; 2/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 2/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.997, test=0.586) total time=   0.3s\n",
      "[CV 2/5; 2/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 2/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.561) total time=   0.3s\n",
      "[CV 3/5; 2/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 2/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.604) total time=   0.3s\n",
      "[CV 4/5; 2/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 2/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.549) total time=   0.3s\n",
      "[CV 5/5; 2/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 2/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.531) total time=   0.3s\n",
      "[CV 1/5; 3/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 3/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.985, test=0.599) total time=   0.2s\n",
      "[CV 2/5; 3/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 3/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.991, test=0.551) total time=   0.2s\n",
      "[CV 3/5; 3/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 3/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.990, test=0.494) total time=   0.2s\n",
      "[CV 4/5; 3/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 3/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.981, test=0.554) total time=   0.2s\n",
      "[CV 5/5; 3/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 3/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.994, test=0.486) total time=   0.3s\n",
      "[CV 1/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.891, test=0.610) total time=   0.2s\n",
      "[CV 2/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.904, test=0.607) total time=   0.2s\n",
      "[CV 3/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.900, test=0.612) total time=   0.2s\n",
      "[CV 4/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.903, test=0.600) total time=   0.2s\n",
      "[CV 5/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.899, test=0.614) total time=   0.2s\n",
      "[CV 1/5; 5/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 5/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.956, test=0.620) total time=   0.4s\n",
      "[CV 2/5; 5/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 5/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.958, test=0.610) total time=   0.4s\n",
      "[CV 3/5; 5/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 5/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.952, test=0.609) total time=   0.4s\n",
      "[CV 4/5; 5/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 5/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.943, test=0.597) total time=   0.4s\n",
      "[CV 5/5; 5/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 5/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.938, test=0.575) total time=   0.4s\n",
      "[CV 1/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.889, test=0.576) total time=   1.0s\n",
      "[CV 2/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.886, test=0.569) total time=   0.3s\n",
      "[CV 3/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.898, test=0.545) total time=   0.3s\n",
      "[CV 4/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.871, test=0.612) total time=   0.3s\n",
      "[CV 5/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.913, test=0.548) total time=   0.5s\n",
      "[CV 1/5; 7/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 7/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.963, test=0.589) total time=   0.9s\n",
      "[CV 2/5; 7/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 7/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.951, test=0.578) total time=   0.8s\n",
      "[CV 3/5; 7/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 7/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.950, test=0.616) total time=   0.7s\n",
      "[CV 4/5; 7/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 7/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.951, test=0.620) total time=   0.7s\n",
      "[CV 5/5; 7/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 7/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.964, test=0.556) total time=   0.7s\n",
      "[CV 1/5; 8/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 8/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.844, test=0.592) total time=   0.5s\n",
      "[CV 2/5; 8/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 8/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.857, test=0.588) total time=   0.7s\n",
      "[CV 3/5; 8/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 8/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.864, test=0.565) total time=   0.5s\n",
      "[CV 4/5; 8/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 8/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.848, test=0.603) total time=   0.5s\n",
      "[CV 5/5; 8/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 8/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.868, test=0.542) total time=   0.5s\n",
      "[CV 1/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.607) total time=   0.3s\n",
      "[CV 2/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.552) total time=   0.3s\n",
      "[CV 3/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.564) total time=   0.3s\n",
      "[CV 4/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.564) total time=   0.8s\n",
      "[CV 5/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.554) total time=   0.3s\n",
      "[CV 1/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.976, test=0.575) total time=   0.3s\n",
      "[CV 2/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.991, test=0.599) total time=   0.4s\n",
      "[CV 3/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.983, test=0.602) total time=   0.3s\n",
      "[CV 4/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.991, test=0.597) total time=   0.3s\n",
      "[CV 5/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.990, test=0.568) total time=   0.3s\n",
      "[CV 1/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.996, test=0.558) total time=   0.5s\n",
      "[CV 2/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.524) total time=   0.4s\n",
      "[CV 3/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.996, test=0.530) total time=   0.4s\n",
      "[CV 4/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.996, test=0.546) total time=   0.4s\n",
      "[CV 5/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.998, test=0.448) total time=   1.0s\n",
      "[CV 1/5; 12/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 12/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.836, test=0.575) total time=   0.4s\n",
      "[CV 2/5; 12/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 12/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.869, test=0.573) total time=   0.2s\n",
      "[CV 3/5; 12/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 12/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.866, test=0.538) total time=   0.2s\n",
      "[CV 4/5; 12/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 12/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.873, test=0.589) total time=   0.2s\n",
      "[CV 5/5; 12/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 12/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.865, test=0.559) total time=   0.2s\n",
      "[CV 1/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.990, test=0.524) total time=   0.3s\n",
      "[CV 2/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.994, test=0.534) total time=   0.3s\n",
      "[CV 3/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.994, test=0.502) total time=   0.2s\n",
      "[CV 4/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.985, test=0.531) total time=   0.2s\n",
      "[CV 5/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.520) total time=   0.3s\n",
      "[CV 1/5; 14/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 14/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.838, test=0.580) total time=   0.4s\n",
      "[CV 2/5; 14/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 14/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.838, test=0.599) total time=   0.4s\n",
      "[CV 3/5; 14/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 14/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.872, test=0.577) total time=   0.5s\n",
      "[CV 4/5; 14/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 14/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.849, test=0.603) total time=   0.4s\n",
      "[CV 5/5; 14/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 14/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.862, test=0.553) total time=   0.5s\n",
      "[CV 1/5; 15/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 15/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.882, test=0.646) total time=   0.4s\n",
      "[CV 2/5; 15/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 15/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.851, test=0.610) total time=   0.5s\n",
      "[CV 3/5; 15/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 15/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.854, test=0.619) total time=   0.5s\n",
      "[CV 4/5; 15/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 15/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.846, test=0.638) total time=   0.5s\n",
      "[CV 5/5; 15/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 15/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.877, test=0.639) total time=   0.5s\n",
      "[CV 1/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.996, test=0.539) total time=   0.2s\n",
      "[CV 2/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.557) total time=   0.3s\n",
      "[CV 3/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.996, test=0.562) total time=   0.2s\n",
      "[CV 4/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.997, test=0.551) total time=   0.2s\n",
      "[CV 5/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.997, test=0.492) total time=   0.3s\n",
      "[CV 1/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.906, test=0.577) total time=   0.2s\n",
      "[CV 2/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.901, test=0.575) total time=   0.2s\n",
      "[CV 3/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.921, test=0.556) total time=   0.2s\n",
      "[CV 4/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.878, test=0.543) total time=   0.2s\n",
      "[CV 5/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.895, test=0.497) total time=   0.2s\n",
      "[CV 1/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.993, test=0.552) total time=   0.3s\n",
      "[CV 2/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.992, test=0.581) total time=   0.3s\n",
      "[CV 3/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.992, test=0.490) total time=   0.2s\n",
      "[CV 4/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.992, test=0.577) total time=   0.3s\n",
      "[CV 5/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.992, test=0.544) total time=   0.3s\n",
      "[CV 1/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.952, test=0.571) total time=   0.6s\n",
      "[CV 2/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.947, test=0.561) total time=   0.6s\n",
      "[CV 3/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.944, test=0.540) total time=   0.6s\n",
      "[CV 4/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.952, test=0.576) total time=   0.6s\n",
      "[CV 5/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.961, test=0.529) total time=   0.6s\n",
      "[CV 1/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.611) total time=   0.4s\n",
      "[CV 2/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.535) total time=   0.3s\n",
      "[CV 3/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.571) total time=   0.2s\n",
      "[CV 4/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.583) total time=   0.2s\n",
      "[CV 5/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.539) total time=   0.6s\n",
      "[CV 1/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.921, test=0.657) total time=   0.5s\n",
      "[CV 2/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.907, test=0.605) total time=   0.3s\n",
      "[CV 3/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.923, test=0.629) total time=   0.3s\n",
      "[CV 4/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.911, test=0.636) total time=   0.3s\n",
      "[CV 5/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.933, test=0.621) total time=   0.3s\n",
      "[CV 1/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.891, test=0.601) total time=   0.2s\n",
      "[CV 2/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.909, test=0.571) total time=   0.5s\n",
      "[CV 3/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.887, test=0.590) total time=   0.2s\n",
      "[CV 4/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.900, test=0.610) total time=   0.2s\n",
      "[CV 5/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.932, test=0.570) total time=   0.2s\n",
      "[CV 1/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.998, test=0.632) total time=   0.3s\n",
      "[CV 2/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.539) total time=   0.4s\n",
      "[CV 3/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.551) total time=   0.3s\n",
      "[CV 4/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.587) total time=   0.5s\n",
      "[CV 5/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.549) total time=   0.4s\n",
      "[CV 1/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.853, test=0.608) total time=   0.4s\n",
      "[CV 2/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.834, test=0.579) total time=   0.5s\n",
      "[CV 3/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.851, test=0.564) total time=   0.5s\n",
      "[CV 4/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.855, test=0.594) total time=   0.5s\n",
      "[CV 5/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.864, test=0.573) total time=   0.5s\n",
      "[CV 1/5; 25/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 25/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.629) total time=   0.3s\n",
      "[CV 2/5; 25/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 25/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.568) total time=   0.3s\n",
      "[CV 3/5; 25/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 25/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.564) total time=   0.3s\n",
      "[CV 4/5; 25/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 25/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.575) total time=   0.3s\n",
      "[CV 5/5; 25/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 25/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.547) total time=   0.3s\n",
      "[CV 1/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.934, test=0.558) total time=   0.6s\n",
      "[CV 2/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.953, test=0.585) total time=   0.6s\n",
      "[CV 3/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.959, test=0.498) total time=   0.6s\n",
      "[CV 4/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.949, test=0.592) total time=   0.6s\n",
      "[CV 5/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.959, test=0.537) total time=   0.6s\n",
      "[CV 1/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.849, test=0.664) total time=   0.2s\n",
      "[CV 2/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.817, test=0.624) total time=   0.2s\n",
      "[CV 3/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.832, test=0.618) total time=   0.2s\n",
      "[CV 4/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.840, test=0.638) total time=   0.2s\n",
      "[CV 5/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.849, test=0.609) total time=   0.2s\n",
      "[CV 1/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.979, test=0.549) total time=   0.4s\n",
      "[CV 2/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.985, test=0.570) total time=   0.4s\n",
      "[CV 3/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.989, test=0.547) total time=   0.4s\n",
      "[CV 4/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.992, test=0.559) total time=   0.4s\n",
      "[CV 5/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.994, test=0.502) total time=   0.5s\n",
      "[CV 1/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.799, test=0.606) total time=   0.2s\n",
      "[CV 2/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.793, test=0.592) total time=   0.2s\n",
      "[CV 3/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.805, test=0.576) total time=   0.2s\n",
      "[CV 4/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.795, test=0.630) total time=   0.2s\n",
      "[CV 5/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.808, test=0.585) total time=   0.2s\n",
      "[CV 1/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.945, test=0.573) total time=   0.2s\n",
      "[CV 2/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.955, test=0.535) total time=   0.2s\n",
      "[CV 3/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.958, test=0.506) total time=   0.2s\n",
      "[CV 4/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.965, test=0.566) total time=   0.2s\n",
      "[CV 5/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.960, test=0.503) total time=   0.2s\n",
      "[CV 1/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.923, test=0.567) total time=   0.4s\n",
      "[CV 2/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.938, test=0.554) total time=   0.4s\n",
      "[CV 3/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.942, test=0.546) total time=   0.4s\n",
      "[CV 4/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.918, test=0.557) total time=   0.4s\n",
      "[CV 5/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.941, test=0.497) total time=   0.4s\n",
      "[CV 1/5; 32/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 32/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.903, test=0.636) total time=   0.5s\n",
      "[CV 2/5; 32/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 32/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.870, test=0.607) total time=   0.5s\n",
      "[CV 3/5; 32/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 32/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.863, test=0.625) total time=   0.5s\n",
      "[CV 4/5; 32/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 32/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.865, test=0.633) total time=   0.4s\n",
      "[CV 5/5; 32/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 32/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.881, test=0.613) total time=   0.5s\n",
      "[CV 1/5; 33/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 33/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.987, test=0.556) total time=   0.3s\n",
      "[CV 2/5; 33/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 33/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.980, test=0.557) total time=   0.3s\n",
      "[CV 3/5; 33/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 33/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.990, test=0.503) total time=   0.2s\n",
      "[CV 4/5; 33/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 33/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.990, test=0.558) total time=   0.2s\n",
      "[CV 5/5; 33/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 33/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.985, test=0.526) total time=   0.3s\n",
      "[CV 1/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.944, test=0.619) total time=   0.7s\n",
      "[CV 2/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.951, test=0.592) total time=   0.6s\n",
      "[CV 3/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.947, test=0.615) total time=   0.6s\n",
      "[CV 4/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.949, test=0.628) total time=   0.6s\n",
      "[CV 5/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.947, test=0.586) total time=   0.6s\n",
      "[CV 1/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.998, test=0.538) total time=   0.3s\n",
      "[CV 2/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.589) total time=   0.2s\n",
      "[CV 3/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.998, test=0.501) total time=   0.3s\n",
      "[CV 4/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.998, test=0.570) total time=   0.3s\n",
      "[CV 5/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.998, test=0.553) total time=   0.3s\n",
      "[CV 1/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.847, test=0.597) total time=   0.5s\n",
      "[CV 2/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.849, test=0.577) total time=   0.5s\n",
      "[CV 3/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.865, test=0.561) total time=   0.5s\n",
      "[CV 4/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.863, test=0.606) total time=   0.5s\n",
      "[CV 5/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.862, test=0.551) total time=   0.5s\n",
      "[CV 1/5; 37/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 37/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.921, test=0.635) total time=   0.3s\n",
      "[CV 2/5; 37/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 37/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.917, test=0.589) total time=   0.3s\n",
      "[CV 3/5; 37/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 37/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.934, test=0.624) total time=   0.4s\n",
      "[CV 4/5; 37/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 37/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.937, test=0.611) total time=   0.3s\n",
      "[CV 5/5; 37/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 37/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.931, test=0.601) total time=   0.3s\n",
      "[CV 1/5; 38/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 38/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.943, test=0.572) total time=   0.2s\n",
      "[CV 2/5; 38/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 38/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.968, test=0.582) total time=   0.2s\n",
      "[CV 3/5; 38/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 38/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.944, test=0.546) total time=   0.2s\n",
      "[CV 4/5; 38/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 38/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.962, test=0.599) total time=   0.2s\n",
      "[CV 5/5; 38/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 38/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.968, test=0.592) total time=   0.2s\n",
      "[CV 1/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.973, test=0.590) total time=   0.2s\n",
      "[CV 2/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.986, test=0.578) total time=   0.2s\n",
      "[CV 3/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.948, test=0.575) total time=   0.4s\n",
      "[CV 4/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.987, test=0.595) total time=   0.2s\n",
      "[CV 5/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.990, test=0.560) total time=   0.2s\n",
      "[CV 1/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.761, test=0.611) total time=   0.2s\n",
      "[CV 2/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.751, test=0.606) total time=   0.2s\n",
      "[CV 3/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.771, test=0.580) total time=   0.2s\n",
      "[CV 4/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.763, test=0.617) total time=   0.2s\n",
      "[CV 5/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.776, test=0.598) total time=   0.2s\n",
      "[CV 1/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.911, test=0.565) total time=   0.2s\n",
      "[CV 2/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.940, test=0.553) total time=   0.2s\n",
      "[CV 3/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.921, test=0.559) total time=   0.2s\n",
      "[CV 4/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.916, test=0.586) total time=   0.2s\n",
      "[CV 5/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.961, test=0.503) total time=   0.2s\n",
      "[CV 1/5; 42/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 42/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.993, test=0.566) total time=   0.4s\n",
      "[CV 2/5; 42/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 42/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.998, test=0.559) total time=   0.4s\n",
      "[CV 3/5; 42/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 42/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.996, test=0.584) total time=   0.6s\n",
      "[CV 4/5; 42/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 42/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.583) total time=   0.4s\n",
      "[CV 5/5; 42/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 42/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.541) total time=   0.4s\n",
      "[CV 1/5; 43/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 43/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.558) total time=   0.5s\n",
      "[CV 2/5; 43/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 43/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.577) total time=   0.4s\n",
      "[CV 3/5; 43/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 43/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.573) total time=   0.4s\n",
      "[CV 4/5; 43/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 43/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.998, test=0.611) total time=   0.4s\n",
      "[CV 5/5; 43/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 43/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.534) total time=   0.6s\n",
      "[CV 1/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.951, test=0.547) total time=   0.2s\n",
      "[CV 2/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.940, test=0.581) total time=   0.2s\n",
      "[CV 3/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.968, test=0.529) total time=   0.2s\n",
      "[CV 4/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.945, test=0.583) total time=   0.2s\n",
      "[CV 5/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.966, test=0.501) total time=   0.3s\n",
      "[CV 1/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.838, test=0.659) total time=   0.2s\n",
      "[CV 2/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.822, test=0.629) total time=   0.2s\n",
      "[CV 3/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.831, test=0.626) total time=   0.3s\n",
      "[CV 4/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.821, test=0.642) total time=   0.2s\n",
      "[CV 5/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.848, test=0.644) total time=   0.2s\n",
      "[CV 1/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.853, test=0.587) total time=   0.8s\n",
      "[CV 2/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.845, test=0.599) total time=   0.3s\n",
      "[CV 3/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.873, test=0.566) total time=   0.3s\n",
      "[CV 4/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.852, test=0.610) total time=   0.3s\n",
      "[CV 5/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.884, test=0.569) total time=   0.4s\n",
      "[CV 1/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.571) total time=   0.6s\n",
      "[CV 2/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.528) total time=   0.5s\n",
      "[CV 3/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.535) total time=   0.6s\n",
      "[CV 4/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.571) total time=   0.5s\n",
      "[CV 5/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.520) total time=   0.5s\n",
      "[CV 1/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.962, test=0.577) total time=   0.7s\n",
      "[CV 2/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.950, test=0.578) total time=   2.2s\n",
      "[CV 3/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.954, test=0.527) total time=   3.3s\n",
      "[CV 4/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.951, test=0.579) total time=   2.7s\n",
      "[CV 5/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.956, test=0.512) total time=   1.1s\n",
      "[CV 1/5; 49/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 49/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.549) total time=   0.6s\n",
      "[CV 2/5; 49/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 49/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.513) total time=   0.7s\n",
      "[CV 3/5; 49/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 49/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.499) total time=   0.6s\n",
      "[CV 4/5; 49/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 49/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.998, test=0.588) total time=   0.7s\n",
      "[CV 5/5; 49/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 49/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.562) total time=   1.0s\n",
      "[CV 1/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.836, test=0.667) total time=   0.3s\n",
      "[CV 2/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.802, test=0.631) total time=   0.3s\n",
      "[CV 3/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.831, test=0.632) total time=   0.2s\n",
      "[CV 4/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.815, test=0.669) total time=   0.2s\n",
      "[CV 5/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.846, test=0.632) total time=   0.2s\n",
      "Selected Parameters: {'xgb__reg_lambda': 1, 'xgb__n_estimators': 100, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 2, 'xgb__colsample_bytree': 0.7}\n",
      "Train score: 0.8152866242038217\n",
      "Test score: 0.5263157894736843\n",
      "Running for 3 out of a total of 5\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.854, test=0.669) total time=   0.5s\n",
      "[CV 2/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.849, test=0.630) total time=   0.5s\n",
      "[CV 3/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.850, test=0.644) total time=   0.5s\n",
      "[CV 4/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.853, test=0.635) total time=   0.5s\n",
      "[CV 5/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.882, test=0.595) total time=   0.5s\n",
      "[CV 1/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.554) total time=   0.9s\n",
      "[CV 2/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.566) total time=   0.6s\n",
      "[CV 3/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.990, test=0.514) total time=   0.6s\n",
      "[CV 4/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.996, test=0.520) total time=   0.6s\n",
      "[CV 5/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.549) total time=   0.6s\n",
      "[CV 1/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.586) total time=   0.6s\n",
      "[CV 2/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.570) total time=   0.6s\n",
      "[CV 3/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.589) total time=   0.6s\n",
      "[CV 4/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.567) total time=   0.5s\n",
      "[CV 5/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.593) total time=   0.5s\n",
      "[CV 1/5; 4/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 4/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.993, test=0.548) total time=   0.3s\n",
      "[CV 2/5; 4/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 4/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.532) total time=   0.3s\n",
      "[CV 3/5; 4/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 4/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.996, test=0.549) total time=   0.5s\n",
      "[CV 4/5; 4/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 4/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.994, test=0.543) total time=   0.3s\n",
      "[CV 5/5; 4/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 4/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.538) total time=   0.3s\n",
      "[CV 1/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.878, test=0.550) total time=   0.2s\n",
      "[CV 2/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.901, test=0.570) total time=   0.2s\n",
      "[CV 3/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.885, test=0.554) total time=   0.3s\n",
      "[CV 4/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.884, test=0.497) total time=   0.2s\n",
      "[CV 5/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.897, test=0.574) total time=   0.2s\n",
      "[CV 1/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.793, test=0.620) total time=   0.2s\n",
      "[CV 2/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.799, test=0.607) total time=   0.2s\n",
      "[CV 3/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.791, test=0.597) total time=   0.2s\n",
      "[CV 4/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.777, test=0.601) total time=   0.2s\n",
      "[CV 5/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.799, test=0.610) total time=   0.2s\n",
      "[CV 1/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.959, test=0.551) total time=   0.2s\n",
      "[CV 2/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.945, test=0.562) total time=   0.2s\n",
      "[CV 3/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.928, test=0.516) total time=   0.2s\n",
      "[CV 4/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.950, test=0.523) total time=   0.2s\n",
      "[CV 5/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.956, test=0.559) total time=   0.2s\n",
      "[CV 1/5; 8/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 8/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.933, test=0.562) total time=   0.2s\n",
      "[CV 2/5; 8/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 8/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.949, test=0.574) total time=   0.2s\n",
      "[CV 3/5; 8/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 8/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.919, test=0.517) total time=   0.2s\n",
      "[CV 4/5; 8/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 8/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.951, test=0.534) total time=   0.2s\n",
      "[CV 5/5; 8/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 8/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.947, test=0.584) total time=   0.2s\n",
      "[CV 1/5; 9/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 9/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.983, test=0.536) total time=   0.2s\n",
      "[CV 2/5; 9/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 9/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.987, test=0.556) total time=   0.3s\n",
      "[CV 3/5; 9/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 9/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.986, test=0.540) total time=   0.3s\n",
      "[CV 4/5; 9/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 9/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.989, test=0.499) total time=   0.3s\n",
      "[CV 5/5; 9/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 9/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.990, test=0.565) total time=   0.5s\n",
      "[CV 1/5; 10/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 10/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.947, test=0.567) total time=   0.4s\n",
      "[CV 2/5; 10/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 10/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.934, test=0.580) total time=   0.4s\n",
      "[CV 3/5; 10/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 10/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.941, test=0.536) total time=   0.4s\n",
      "[CV 4/5; 10/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 10/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.945, test=0.509) total time=   0.4s\n",
      "[CV 5/5; 10/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 10/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.958, test=0.552) total time=   0.4s\n",
      "[CV 1/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.526) total time=   0.6s\n",
      "[CV 2/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.602) total time=   0.6s\n",
      "[CV 3/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.528) total time=   0.6s\n",
      "[CV 4/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.502) total time=   0.6s\n",
      "[CV 5/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.571) total time=   0.6s\n",
      "[CV 1/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.926, test=0.647) total time=   0.6s\n",
      "[CV 2/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.930, test=0.635) total time=   0.6s\n",
      "[CV 3/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.937, test=0.591) total time=   0.6s\n",
      "[CV 4/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.939, test=0.609) total time=   0.6s\n",
      "[CV 5/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.935, test=0.595) total time=   0.6s\n",
      "[CV 1/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.963, test=0.552) total time=   0.4s\n",
      "[CV 2/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.959, test=0.558) total time=   0.4s\n",
      "[CV 3/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.958, test=0.574) total time=   0.5s\n",
      "[CV 4/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.966, test=0.513) total time=   0.4s\n",
      "[CV 5/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.968, test=0.578) total time=   0.4s\n",
      "[CV 1/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.927, test=0.633) total time=   0.2s\n",
      "[CV 2/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.901, test=0.614) total time=   0.4s\n",
      "[CV 3/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.891, test=0.602) total time=   0.3s\n",
      "[CV 4/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.911, test=0.584) total time=   0.2s\n",
      "[CV 5/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.924, test=0.586) total time=   0.2s\n",
      "[CV 1/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.875, test=0.617) total time=   0.6s\n",
      "[CV 2/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.892, test=0.611) total time=   0.6s\n",
      "[CV 3/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.880, test=0.567) total time=   0.6s\n",
      "[CV 4/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.879, test=0.574) total time=   0.6s\n",
      "[CV 5/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.903, test=0.608) total time=   0.7s\n",
      "[CV 1/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.869, test=0.588) total time=   0.2s\n",
      "[CV 2/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.884, test=0.572) total time=   0.2s\n",
      "[CV 3/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.868, test=0.564) total time=   0.2s\n",
      "[CV 4/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.879, test=0.513) total time=   0.2s\n",
      "[CV 5/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.896, test=0.595) total time=   0.2s\n",
      "[CV 1/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.933, test=0.583) total time=   0.2s\n",
      "[CV 2/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.954, test=0.534) total time=   0.2s\n",
      "[CV 3/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.936, test=0.513) total time=   0.2s\n",
      "[CV 4/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.955, test=0.518) total time=   0.2s\n",
      "[CV 5/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.936, test=0.554) total time=   0.2s\n",
      "[CV 1/5; 18/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 18/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.581) total time=   0.5s\n",
      "[CV 2/5; 18/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 18/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.590) total time=   0.5s\n",
      "[CV 3/5; 18/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 18/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.556) total time=   0.5s\n",
      "[CV 4/5; 18/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 18/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.537) total time=   0.6s\n",
      "[CV 5/5; 18/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 18/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.537) total time=   0.5s\n",
      "[CV 1/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.866, test=0.600) total time=   0.2s\n",
      "[CV 2/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.853, test=0.596) total time=   0.2s\n",
      "[CV 3/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.831, test=0.562) total time=   0.2s\n",
      "[CV 4/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.831, test=0.549) total time=   0.3s\n",
      "[CV 5/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.856, test=0.562) total time=   0.3s\n",
      "[CV 1/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.994, test=0.582) total time=   0.4s\n",
      "[CV 2/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.986, test=0.610) total time=   0.5s\n",
      "[CV 3/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.997, test=0.572) total time=   0.4s\n",
      "[CV 4/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.997, test=0.570) total time=   0.4s\n",
      "[CV 5/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.998, test=0.607) total time=   0.5s\n",
      "[CV 1/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.922, test=0.656) total time=   0.7s\n",
      "[CV 2/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.934, test=0.614) total time=   0.6s\n",
      "[CV 3/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.921, test=0.628) total time=   0.6s\n",
      "[CV 4/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.930, test=0.639) total time=   0.6s\n",
      "[CV 5/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.932, test=0.593) total time=   0.6s\n",
      "[CV 1/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.970, test=0.614) total time=   0.5s\n",
      "[CV 2/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.951, test=0.549) total time=   0.4s\n",
      "[CV 3/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.950, test=0.591) total time=   0.4s\n",
      "[CV 4/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.951, test=0.582) total time=   0.4s\n",
      "[CV 5/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.987, test=0.585) total time=   0.4s\n",
      "[CV 1/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.595) total time=   0.3s\n",
      "[CV 2/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.556) total time=   0.3s\n",
      "[CV 3/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.583) total time=   0.3s\n",
      "[CV 4/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.569) total time=   0.3s\n",
      "[CV 5/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.562) total time=   0.3s\n",
      "[CV 1/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.844, test=0.608) total time=   0.4s\n",
      "[CV 2/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.833, test=0.615) total time=   0.4s\n",
      "[CV 3/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.824, test=0.572) total time=   0.4s\n",
      "[CV 4/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.843, test=0.586) total time=   0.4s\n",
      "[CV 5/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.844, test=0.599) total time=   0.4s\n",
      "[CV 1/5; 25/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 25/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.626) total time=   0.5s\n",
      "[CV 2/5; 25/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 25/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.611) total time=   0.5s\n",
      "[CV 3/5; 25/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 25/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.604) total time=   0.5s\n",
      "[CV 4/5; 25/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 25/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.580) total time=   0.6s\n",
      "[CV 5/5; 25/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 25/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.584) total time=   0.5s\n",
      "[CV 1/5; 26/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 26/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.997, test=0.602) total time=   0.3s\n",
      "[CV 2/5; 26/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 26/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.977, test=0.581) total time=   0.3s\n",
      "[CV 3/5; 26/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 26/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.967, test=0.590) total time=   0.3s\n",
      "[CV 4/5; 26/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 26/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.966, test=0.594) total time=   0.5s\n",
      "[CV 5/5; 26/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 26/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.979, test=0.581) total time=   0.3s\n",
      "[CV 1/5; 27/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 27/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.894, test=0.625) total time=   0.3s\n",
      "[CV 2/5; 27/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 27/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.889, test=0.598) total time=   0.3s\n",
      "[CV 3/5; 27/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 27/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.897, test=0.574) total time=   0.3s\n",
      "[CV 4/5; 27/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 27/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.882, test=0.587) total time=   0.3s\n",
      "[CV 5/5; 27/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 27/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.899, test=0.575) total time=   0.3s\n",
      "[CV 1/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.939, test=0.598) total time=   0.7s\n",
      "[CV 2/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.935, test=0.607) total time=   0.7s\n",
      "[CV 3/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.947, test=0.561) total time=   0.6s\n",
      "[CV 4/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.924, test=0.565) total time=   0.7s\n",
      "[CV 5/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.946, test=0.567) total time=   0.6s\n",
      "[CV 1/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.997, test=0.534) total time=   0.3s\n",
      "[CV 2/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.998, test=0.559) total time=   0.3s\n",
      "[CV 3/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.996, test=0.531) total time=   0.3s\n",
      "[CV 4/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.997, test=0.518) total time=   0.3s\n",
      "[CV 5/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.997, test=0.586) total time=   0.3s\n",
      "[CV 1/5; 30/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 30/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.860, test=0.654) total time=   0.5s\n",
      "[CV 2/5; 30/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 30/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.836, test=0.638) total time=   0.4s\n",
      "[CV 3/5; 30/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 30/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.861, test=0.629) total time=   0.5s\n",
      "[CV 4/5; 30/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 30/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.847, test=0.622) total time=   0.4s\n",
      "[CV 5/5; 30/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 30/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.861, test=0.634) total time=   0.5s\n",
      "[CV 1/5; 31/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 31/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.997, test=0.584) total time=   0.7s\n",
      "[CV 2/5; 31/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 31/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.996, test=0.603) total time=   0.8s\n",
      "[CV 3/5; 31/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 31/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.997, test=0.562) total time=   0.4s\n",
      "[CV 4/5; 31/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 31/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.998, test=0.580) total time=   0.4s\n",
      "[CV 5/5; 31/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 31/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.998, test=0.559) total time=   0.5s\n",
      "[CV 1/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.970, test=0.516) total time=   0.4s\n",
      "[CV 2/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.980, test=0.553) total time=   0.4s\n",
      "[CV 3/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.985, test=0.534) total time=   0.4s\n",
      "[CV 4/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.981, test=0.545) total time=   0.4s\n",
      "[CV 5/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.978, test=0.522) total time=   0.4s\n",
      "[CV 1/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.943, test=0.594) total time=   0.2s\n",
      "[CV 2/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.946, test=0.582) total time=   0.2s\n",
      "[CV 3/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.921, test=0.595) total time=   0.2s\n",
      "[CV 4/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.932, test=0.558) total time=   0.2s\n",
      "[CV 5/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.935, test=0.573) total time=   0.2s\n",
      "[CV 1/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.843, test=0.690) total time=   0.2s\n",
      "[CV 2/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.835, test=0.656) total time=   0.2s\n",
      "[CV 3/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.832, test=0.640) total time=   0.2s\n",
      "[CV 4/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.821, test=0.656) total time=   0.2s\n",
      "[CV 5/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.843, test=0.633) total time=   0.2s\n",
      "[CV 1/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.886, test=0.603) total time=   0.3s\n",
      "[CV 2/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.885, test=0.608) total time=   0.3s\n",
      "[CV 3/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.894, test=0.584) total time=   0.3s\n",
      "[CV 4/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.886, test=0.570) total time=   0.3s\n",
      "[CV 5/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.893, test=0.573) total time=   0.3s\n",
      "[CV 1/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.910, test=0.574) total time=   0.3s\n",
      "[CV 2/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.910, test=0.567) total time=   0.2s\n",
      "[CV 3/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.886, test=0.583) total time=   0.2s\n",
      "[CV 4/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.883, test=0.519) total time=   0.2s\n",
      "[CV 5/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.901, test=0.557) total time=   0.2s\n",
      "[CV 1/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.531) total time=   0.6s\n",
      "[CV 2/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.574) total time=   0.6s\n",
      "[CV 3/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.519) total time=   0.5s\n",
      "[CV 4/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.512) total time=   0.5s\n",
      "[CV 5/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.555) total time=   0.5s\n",
      "[CV 1/5; 38/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 38/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.850, test=0.611) total time=   0.2s\n",
      "[CV 2/5; 38/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 38/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.870, test=0.579) total time=   0.2s\n",
      "[CV 3/5; 38/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 38/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.885, test=0.630) total time=   0.2s\n",
      "[CV 4/5; 38/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 38/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.875, test=0.578) total time=   0.2s\n",
      "[CV 5/5; 38/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 38/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.898, test=0.576) total time=   0.2s\n",
      "[CV 1/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.612) total time=   0.3s\n",
      "[CV 2/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=1.000, test=0.628) total time=   0.3s\n",
      "[CV 3/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.591) total time=   0.3s\n",
      "[CV 4/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.607) total time=   0.3s\n",
      "[CV 5/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.606) total time=   0.3s\n",
      "[CV 1/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.922, test=0.564) total time=   0.4s\n",
      "[CV 2/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.932, test=0.579) total time=   0.4s\n",
      "[CV 3/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.890, test=0.534) total time=   0.4s\n",
      "[CV 4/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.904, test=0.527) total time=   0.4s\n",
      "[CV 5/5; 40/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 40/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.923, test=0.531) total time=   0.5s\n",
      "[CV 1/5; 41/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 41/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.592) total time=   0.5s\n",
      "[CV 2/5; 41/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 41/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.590) total time=   0.5s\n",
      "[CV 3/5; 41/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 41/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.610) total time=   0.4s\n",
      "[CV 4/5; 41/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 41/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.551) total time=   0.5s\n",
      "[CV 5/5; 41/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 41/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.561) total time=   0.5s\n",
      "[CV 1/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.819, test=0.627) total time=   0.3s\n",
      "[CV 2/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.824, test=0.591) total time=   0.3s\n",
      "[CV 3/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.823, test=0.595) total time=   0.3s\n",
      "[CV 4/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.815, test=0.588) total time=   0.3s\n",
      "[CV 5/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.832, test=0.605) total time=   0.3s\n",
      "[CV 1/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.872, test=0.605) total time=   0.3s\n",
      "[CV 2/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.881, test=0.606) total time=   0.3s\n",
      "[CV 3/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.882, test=0.597) total time=   0.3s\n",
      "[CV 4/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.871, test=0.590) total time=   0.4s\n",
      "[CV 5/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.887, test=0.585) total time=   0.3s\n",
      "[CV 1/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.780, test=0.623) total time=   0.2s\n",
      "[CV 2/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.786, test=0.610) total time=   0.2s\n",
      "[CV 3/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.782, test=0.602) total time=   0.2s\n",
      "[CV 4/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.768, test=0.594) total time=   0.2s\n",
      "[CV 5/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.779, test=0.610) total time=   0.2s\n",
      "[CV 1/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.836, test=0.667) total time=   0.2s\n",
      "[CV 2/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.831, test=0.642) total time=   0.2s\n",
      "[CV 3/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.842, test=0.656) total time=   0.3s\n",
      "[CV 4/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.813, test=0.648) total time=   0.3s\n",
      "[CV 5/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.847, test=0.630) total time=   0.3s\n",
      "[CV 1/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.895, test=0.606) total time=   0.3s\n",
      "[CV 2/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.891, test=0.602) total time=   0.3s\n",
      "[CV 3/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.889, test=0.593) total time=   0.3s\n",
      "[CV 4/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.881, test=0.595) total time=   0.3s\n",
      "[CV 5/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.895, test=0.575) total time=   0.3s\n",
      "[CV 1/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.979, test=0.529) total time=   0.2s\n",
      "[CV 2/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.982, test=0.563) total time=   0.3s\n",
      "[CV 3/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.964, test=0.558) total time=   0.3s\n",
      "[CV 4/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.969, test=0.525) total time=   0.2s\n",
      "[CV 5/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.984, test=0.553) total time=   0.3s\n",
      "[CV 1/5; 48/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 48/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.998, test=0.581) total time=   0.4s\n",
      "[CV 2/5; 48/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 48/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.562) total time=   0.4s\n",
      "[CV 3/5; 48/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 48/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.988, test=0.584) total time=   0.4s\n",
      "[CV 4/5; 48/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 48/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.991, test=0.560) total time=   0.4s\n",
      "[CV 5/5; 48/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 48/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.998, test=0.548) total time=   0.4s\n",
      "[CV 1/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.862, test=0.648) total time=   0.4s\n",
      "[CV 2/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.838, test=0.642) total time=   0.4s\n",
      "[CV 3/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.873, test=0.639) total time=   0.5s\n",
      "[CV 4/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.840, test=0.622) total time=   0.5s\n",
      "[CV 5/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.881, test=0.602) total time=   0.6s\n",
      "[CV 1/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.897, test=0.667) total time=   0.3s\n",
      "[CV 2/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.909, test=0.664) total time=   0.3s\n",
      "[CV 3/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.905, test=0.644) total time=   0.3s\n",
      "[CV 4/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.924, test=0.638) total time=   0.3s\n",
      "[CV 5/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.922, test=0.607) total time=   0.3s\n",
      "Selected Parameters: {'xgb__reg_lambda': 1, 'xgb__n_estimators': 100, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.5, 'xgb__colsample_bytree': 0.7}\n",
      "Train score: 0.8241965973534972\n",
      "Test score: 0.39999999999999997\n",
      "Running for 4 out of a total of 5\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5; 1/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 1/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.991, test=0.535) total time=   0.4s\n",
      "[CV 2/5; 1/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 1/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.990, test=0.562) total time=   0.5s\n",
      "[CV 3/5; 1/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 1/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.988, test=0.555) total time=   0.5s\n",
      "[CV 4/5; 1/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 1/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.977, test=0.550) total time=   0.4s\n",
      "[CV 5/5; 1/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 1/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.990, test=0.552) total time=   0.5s\n",
      "[CV 1/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.811, test=0.596) total time=   0.5s\n",
      "[CV 2/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.830, test=0.593) total time=   0.5s\n",
      "[CV 3/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.800, test=0.567) total time=   0.5s\n",
      "[CV 4/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.827, test=0.573) total time=   0.5s\n",
      "[CV 5/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.815, test=0.604) total time=   0.5s\n",
      "[CV 1/5; 3/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 3/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.821, test=0.607) total time=   0.4s\n",
      "[CV 2/5; 3/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 3/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.809, test=0.597) total time=   0.4s\n",
      "[CV 3/5; 3/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 3/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.800, test=0.593) total time=   0.4s\n",
      "[CV 4/5; 3/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 3/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.820, test=0.557) total time=   0.4s\n",
      "[CV 5/5; 3/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 3/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.812, test=0.595) total time=   0.3s\n",
      "[CV 1/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.924, test=0.601) total time=   0.2s\n",
      "[CV 2/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.896, test=0.593) total time=   0.3s\n",
      "[CV 3/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.907, test=0.574) total time=   0.3s\n",
      "[CV 4/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.935, test=0.549) total time=   0.3s\n",
      "[CV 5/5; 4/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 4/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.937, test=0.567) total time=   0.2s\n",
      "[CV 1/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.903, test=0.552) total time=   0.2s\n",
      "[CV 2/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.906, test=0.541) total time=   0.2s\n",
      "[CV 3/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.911, test=0.556) total time=   0.2s\n",
      "[CV 4/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.912, test=0.551) total time=   0.2s\n",
      "[CV 5/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.923, test=0.529) total time=   0.2s\n",
      "[CV 1/5; 6/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 6/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.910, test=0.598) total time=   0.7s\n",
      "[CV 2/5; 6/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 6/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.918, test=0.610) total time=   0.6s\n",
      "[CV 3/5; 6/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 6/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.903, test=0.612) total time=   0.7s\n",
      "[CV 4/5; 6/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 6/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.935, test=0.585) total time=   0.7s\n",
      "[CV 5/5; 6/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 6/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.941, test=0.606) total time=   0.7s\n",
      "[CV 1/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.873, test=0.615) total time=   0.3s\n",
      "[CV 2/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.887, test=0.572) total time=   0.3s\n",
      "[CV 3/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.860, test=0.567) total time=   0.3s\n",
      "[CV 4/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.887, test=0.564) total time=   0.3s\n",
      "[CV 5/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.883, test=0.579) total time=   0.4s\n",
      "[CV 1/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.934, test=0.593) total time=   0.2s\n",
      "[CV 2/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.923, test=0.555) total time=   0.2s\n",
      "[CV 3/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.918, test=0.566) total time=   0.3s\n",
      "[CV 4/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.942, test=0.550) total time=   0.2s\n",
      "[CV 5/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.935, test=0.562) total time=   0.2s\n",
      "[CV 1/5; 9/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 9/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.520) total time=   0.6s\n",
      "[CV 2/5; 9/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 9/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.529) total time=   0.6s\n",
      "[CV 3/5; 9/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 9/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.551) total time=   0.6s\n",
      "[CV 4/5; 9/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 9/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.538) total time=   0.6s\n",
      "[CV 5/5; 9/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 9/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.576) total time=   0.6s\n",
      "[CV 1/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.861, test=0.612) total time=   0.2s\n",
      "[CV 2/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.847, test=0.564) total time=   0.2s\n",
      "[CV 3/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.867, test=0.621) total time=   0.2s\n",
      "[CV 4/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.887, test=0.573) total time=   0.2s\n",
      "[CV 5/5; 10/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 10/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.869, test=0.589) total time=   0.2s\n",
      "[CV 1/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.816, test=0.580) total time=   0.5s\n",
      "[CV 2/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.832, test=0.599) total time=   0.5s\n",
      "[CV 3/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.823, test=0.565) total time=   0.5s\n",
      "[CV 4/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.829, test=0.578) total time=   0.5s\n",
      "[CV 5/5; 11/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 11/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.824, test=0.594) total time=   0.5s\n",
      "[CV 1/5; 12/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 12/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.941, test=0.556) total time=   0.5s\n",
      "[CV 2/5; 12/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 12/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.952, test=0.519) total time=   0.4s\n",
      "[CV 3/5; 12/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 12/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.934, test=0.574) total time=   0.6s\n",
      "[CV 4/5; 12/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 12/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.953, test=0.562) total time=   0.5s\n",
      "[CV 5/5; 12/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 12/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.939, test=0.559) total time=   0.5s\n",
      "[CV 1/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.963, test=0.551) total time=   0.3s\n",
      "[CV 2/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.973, test=0.528) total time=   0.3s\n",
      "[CV 3/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.969, test=0.538) total time=   0.3s\n",
      "[CV 4/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.957, test=0.522) total time=   0.4s\n",
      "[CV 5/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.953, test=0.557) total time=   0.3s\n",
      "[CV 1/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.569) total time=   0.6s\n",
      "[CV 2/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.582) total time=   0.6s\n",
      "[CV 3/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.563) total time=   0.8s\n",
      "[CV 4/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.537) total time=   0.7s\n",
      "[CV 5/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.590) total time=   0.6s\n",
      "[CV 1/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.970, test=0.539) total time=   0.5s\n",
      "[CV 2/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.979, test=0.521) total time=   0.4s\n",
      "[CV 3/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.985, test=0.557) total time=   0.5s\n",
      "[CV 4/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.976, test=0.545) total time=   0.5s\n",
      "[CV 5/5; 15/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 15/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.989, test=0.552) total time=   0.5s\n",
      "[CV 1/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.995, test=0.545) total time=   0.3s\n",
      "[CV 2/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.996, test=0.537) total time=   0.3s\n",
      "[CV 3/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.995, test=0.577) total time=   0.3s\n",
      "[CV 4/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.996, test=0.543) total time=   0.4s\n",
      "[CV 5/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.994, test=0.563) total time=   0.4s\n",
      "[CV 1/5; 17/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 17/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.926, test=0.613) total time=   0.7s\n",
      "[CV 2/5; 17/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 17/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.938, test=0.609) total time=   0.7s\n",
      "[CV 3/5; 17/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 17/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.930, test=0.615) total time=   0.7s\n",
      "[CV 4/5; 17/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 17/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.939, test=0.580) total time=   0.7s\n",
      "[CV 5/5; 17/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 17/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.942, test=0.609) total time=   0.7s\n",
      "[CV 1/5; 18/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 18/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.816, test=0.655) total time=   0.3s\n",
      "[CV 2/5; 18/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 18/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.798, test=0.621) total time=   0.3s\n",
      "[CV 3/5; 18/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 18/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.802, test=0.628) total time=   0.2s\n",
      "[CV 4/5; 18/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 18/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.836, test=0.619) total time=   0.3s\n",
      "[CV 5/5; 18/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 18/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.820, test=0.670) total time=   0.2s\n",
      "[CV 1/5; 19/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 19/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.816, test=0.654) total time=   0.2s\n",
      "[CV 2/5; 19/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 19/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.799, test=0.619) total time=   0.3s\n",
      "[CV 3/5; 19/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 19/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.796, test=0.623) total time=   0.2s\n",
      "[CV 4/5; 19/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 19/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.819, test=0.624) total time=   0.2s\n",
      "[CV 5/5; 19/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 19/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.834, test=0.651) total time=   0.3s\n",
      "[CV 1/5; 20/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 20/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.814, test=0.587) total time=   0.6s\n",
      "[CV 2/5; 20/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 20/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.827, test=0.594) total time=   0.5s\n",
      "[CV 3/5; 20/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 20/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.822, test=0.584) total time=   0.5s\n",
      "[CV 4/5; 20/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 20/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.826, test=0.579) total time=   0.5s\n",
      "[CV 5/5; 20/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 20/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.821, test=0.587) total time=   0.5s\n",
      "[CV 1/5; 21/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 21/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.919, test=0.567) total time=   0.7s\n",
      "[CV 2/5; 21/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 21/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.926, test=0.549) total time=   0.7s\n",
      "[CV 3/5; 21/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 21/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.923, test=0.562) total time=   0.7s\n",
      "[CV 4/5; 21/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 21/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.935, test=0.540) total time=   0.7s\n",
      "[CV 5/5; 21/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 21/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.927, test=0.554) total time=   0.7s\n",
      "[CV 1/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.600) total time=   0.6s\n",
      "[CV 2/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.588) total time=   0.6s\n",
      "[CV 3/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.540) total time=   0.6s\n",
      "[CV 4/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.520) total time=   0.6s\n",
      "[CV 5/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.540) total time=   0.7s\n",
      "[CV 1/5; 23/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 23/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.951, test=0.545) total time=   1.1s\n",
      "[CV 2/5; 23/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 23/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.944, test=0.555) total time=   1.0s\n",
      "[CV 3/5; 23/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 23/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.947, test=0.544) total time=   1.0s\n",
      "[CV 4/5; 23/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 23/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.958, test=0.513) total time=   0.8s\n",
      "[CV 5/5; 23/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 23/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.947, test=0.574) total time=   0.8s\n",
      "[CV 1/5; 24/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 24/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.990, test=0.569) total time=   0.3s\n",
      "[CV 2/5; 24/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 24/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.994, test=0.567) total time=   0.3s\n",
      "[CV 3/5; 24/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 24/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.995, test=0.602) total time=   0.3s\n",
      "[CV 4/5; 24/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 24/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.999, test=0.522) total time=   0.3s\n",
      "[CV 5/5; 24/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 24/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.998, test=0.569) total time=   0.3s\n",
      "[CV 1/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.981, test=0.547) total time=   0.3s\n",
      "[CV 2/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.959, test=0.516) total time=   0.3s\n",
      "[CV 3/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.958, test=0.515) total time=   0.3s\n",
      "[CV 4/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.966, test=0.524) total time=   0.3s\n",
      "[CV 5/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.984, test=0.561) total time=   0.3s\n",
      "[CV 1/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.895, test=0.543) total time=   0.3s\n",
      "[CV 2/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.884, test=0.553) total time=   0.3s\n",
      "[CV 3/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.899, test=0.569) total time=   0.3s\n",
      "[CV 4/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.914, test=0.516) total time=   0.3s\n",
      "[CV 5/5; 26/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 26/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.901, test=0.582) total time=   0.3s\n",
      "[CV 1/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.871, test=0.618) total time=   0.5s\n",
      "[CV 2/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.835, test=0.628) total time=   0.5s\n",
      "[CV 3/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.842, test=0.627) total time=   0.5s\n",
      "[CV 4/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.853, test=0.617) total time=   0.6s\n",
      "[CV 5/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.855, test=0.633) total time=   0.5s\n",
      "[CV 1/5; 28/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 28/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.997, test=0.563) total time=   0.6s\n",
      "[CV 2/5; 28/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 28/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.535) total time=   0.6s\n",
      "[CV 3/5; 28/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 28/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.619) total time=   0.6s\n",
      "[CV 4/5; 28/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 28/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.556) total time=   0.6s\n",
      "[CV 5/5; 28/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 28/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.998, test=0.585) total time=   0.6s\n",
      "[CV 1/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.985, test=0.544) total time=   0.3s\n",
      "[CV 2/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.977, test=0.523) total time=   0.3s\n",
      "[CV 3/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.980, test=0.567) total time=   0.3s\n",
      "[CV 4/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.978, test=0.546) total time=   0.3s\n",
      "[CV 5/5; 29/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 29/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.984, test=0.537) total time=   0.3s\n",
      "[CV 1/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.521) total time=   0.6s\n",
      "[CV 2/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.509) total time=   0.6s\n",
      "[CV 3/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.545) total time=   0.7s\n",
      "[CV 4/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.494) total time=   0.6s\n",
      "[CV 5/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.546) total time=   0.6s\n",
      "[CV 1/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.880, test=0.547) total time=   0.2s\n",
      "[CV 2/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.870, test=0.548) total time=   0.2s\n",
      "[CV 3/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.851, test=0.537) total time=   0.3s\n",
      "[CV 4/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.869, test=0.539) total time=   0.2s\n",
      "[CV 5/5; 31/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 31/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.870, test=0.587) total time=   0.2s\n",
      "[CV 1/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.566) total time=   0.6s\n",
      "[CV 2/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.528) total time=   0.6s\n",
      "[CV 3/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.524) total time=   0.6s\n",
      "[CV 4/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.547) total time=   0.6s\n",
      "[CV 5/5; 32/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 32/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.998, test=0.540) total time=   0.6s\n",
      "[CV 1/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.900, test=0.580) total time=   0.5s\n",
      "[CV 2/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.898, test=0.574) total time=   0.5s\n",
      "[CV 3/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.925, test=0.563) total time=   0.5s\n",
      "[CV 4/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.899, test=0.563) total time=   0.4s\n",
      "[CV 5/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.914, test=0.595) total time=   0.4s\n",
      "[CV 1/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.889, test=0.619) total time=   0.3s\n",
      "[CV 2/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.896, test=0.625) total time=   0.3s\n",
      "[CV 3/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.892, test=0.625) total time=   0.3s\n",
      "[CV 4/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.896, test=0.602) total time=   0.3s\n",
      "[CV 5/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.885, test=0.637) total time=   0.4s\n",
      "[CV 1/5; 35/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 35/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.995, test=0.570) total time=   0.4s\n",
      "[CV 2/5; 35/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 35/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.532) total time=   0.4s\n",
      "[CV 3/5; 35/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 35/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.572) total time=   0.3s\n",
      "[CV 4/5; 35/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 35/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.549) total time=   0.3s\n",
      "[CV 5/5; 35/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 35/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.998, test=0.571) total time=   0.3s\n",
      "[CV 1/5; 36/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 36/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.914, test=0.598) total time=   0.7s\n",
      "[CV 2/5; 36/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 36/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.911, test=0.607) total time=   0.7s\n",
      "[CV 3/5; 36/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 36/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.922, test=0.613) total time=   0.6s\n",
      "[CV 4/5; 36/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 36/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.928, test=0.609) total time=   0.6s\n",
      "[CV 5/5; 36/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 36/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.916, test=0.626) total time=   0.6s\n",
      "[CV 1/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.956, test=0.533) total time=   0.3s\n",
      "[CV 2/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.957, test=0.535) total time=   1.5s\n",
      "[CV 3/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.966, test=0.521) total time=   1.4s\n",
      "[CV 4/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.959, test=0.526) total time=   0.4s\n",
      "[CV 5/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.950, test=0.564) total time=   0.4s\n",
      "[CV 1/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.886, test=0.571) total time=   0.2s\n",
      "[CV 2/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.884, test=0.568) total time=   0.2s\n",
      "[CV 3/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.877, test=0.528) total time=   0.2s\n",
      "[CV 4/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.859, test=0.543) total time=   0.2s\n",
      "[CV 5/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.880, test=0.557) total time=   0.2s\n",
      "[CV 1/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.805, test=0.668) total time=   0.2s\n",
      "[CV 2/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.806, test=0.623) total time=   0.3s\n",
      "[CV 3/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.802, test=0.618) total time=   0.2s\n",
      "[CV 4/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.806, test=0.615) total time=   0.3s\n",
      "[CV 5/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.808, test=0.664) total time=   0.3s\n",
      "[CV 1/5; 40/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 40/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.979, test=0.593) total time=   0.3s\n",
      "[CV 2/5; 40/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 40/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.966, test=0.555) total time=   0.3s\n",
      "[CV 3/5; 40/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 40/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.961, test=0.557) total time=   0.3s\n",
      "[CV 4/5; 40/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 40/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.978, test=0.541) total time=   0.3s\n",
      "[CV 5/5; 40/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 40/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.971, test=0.611) total time=   0.3s\n",
      "[CV 1/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.929, test=0.545) total time=   0.3s\n",
      "[CV 2/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.933, test=0.524) total time=   0.3s\n",
      "[CV 3/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.935, test=0.549) total time=   0.3s\n",
      "[CV 4/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.930, test=0.526) total time=   0.3s\n",
      "[CV 5/5; 41/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 41/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.926, test=0.556) total time=   0.3s\n",
      "[CV 1/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.839, test=0.582) total time=   0.7s\n",
      "[CV 2/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.829, test=0.586) total time=   0.7s\n",
      "[CV 3/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.835, test=0.577) total time=   0.7s\n",
      "[CV 4/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.860, test=0.551) total time=   0.7s\n",
      "[CV 5/5; 42/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 42/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.843, test=0.590) total time=   0.7s\n",
      "[CV 1/5; 43/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 43/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.942, test=0.612) total time=   0.3s\n",
      "[CV 2/5; 43/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 43/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.936, test=0.577) total time=   0.3s\n",
      "[CV 3/5; 43/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 43/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.912, test=0.587) total time=   0.3s\n",
      "[CV 4/5; 43/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 43/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.941, test=0.568) total time=   0.3s\n",
      "[CV 5/5; 43/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 43/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.937, test=0.600) total time=   0.3s\n",
      "[CV 1/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.927, test=0.547) total time=   0.5s\n",
      "[CV 2/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.918, test=0.501) total time=   0.5s\n",
      "[CV 3/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.925, test=0.539) total time=   0.4s\n",
      "[CV 4/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.925, test=0.526) total time=   0.4s\n",
      "[CV 5/5; 44/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 44/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.912, test=0.531) total time=   0.5s\n",
      "[CV 1/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.880, test=0.624) total time=   0.4s\n",
      "[CV 2/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.888, test=0.612) total time=   0.3s\n",
      "[CV 3/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.898, test=0.627) total time=   0.3s\n",
      "[CV 4/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.892, test=0.627) total time=   0.3s\n",
      "[CV 5/5; 45/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 45/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.893, test=0.636) total time=   0.3s\n",
      "[CV 1/5; 46/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 46/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.880, test=0.624) total time=   0.3s\n",
      "[CV 2/5; 46/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 46/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.883, test=0.628) total time=   0.3s\n",
      "[CV 3/5; 46/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 46/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.905, test=0.636) total time=   0.3s\n",
      "[CV 4/5; 46/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 46/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.898, test=0.611) total time=   0.3s\n",
      "[CV 5/5; 46/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 46/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.884, test=0.628) total time=   0.3s\n",
      "[CV 1/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.927, test=0.520) total time=   0.5s\n",
      "[CV 2/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.950, test=0.541) total time=   0.5s\n",
      "[CV 3/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.938, test=0.560) total time=   0.4s\n",
      "[CV 4/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.938, test=0.533) total time=   0.5s\n",
      "[CV 5/5; 47/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 47/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.937, test=0.570) total time=   0.5s\n",
      "[CV 1/5; 48/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 48/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.912, test=0.593) total time=   0.2s\n",
      "[CV 2/5; 48/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 48/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.904, test=0.579) total time=   0.2s\n",
      "[CV 3/5; 48/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 48/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.907, test=0.572) total time=   0.2s\n",
      "[CV 4/5; 48/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 48/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.899, test=0.562) total time=   0.2s\n",
      "[CV 5/5; 48/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 48/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.900, test=0.603) total time=   0.2s\n",
      "[CV 1/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.911, test=0.609) total time=   0.4s\n",
      "[CV 2/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.911, test=0.630) total time=   0.4s\n",
      "[CV 3/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.898, test=0.634) total time=   0.4s\n",
      "[CV 4/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.915, test=0.627) total time=   0.4s\n",
      "[CV 5/5; 49/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 49/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.907, test=0.622) total time=   0.4s\n",
      "[CV 1/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.854, test=0.602) total time=   0.2s\n",
      "[CV 2/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.836, test=0.591) total time=   0.2s\n",
      "[CV 3/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.862, test=0.587) total time=   0.2s\n",
      "[CV 4/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.867, test=0.579) total time=   0.2s\n",
      "[CV 5/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.863, test=0.581) total time=   0.2s\n",
      "Selected Parameters: {'xgb__reg_lambda': 1, 'xgb__n_estimators': 100, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.5, 'xgb__colsample_bytree': 0.7}\n",
      "Train score: 0.7919972404277338\n",
      "Test score: 0.5433962264150944\n",
      "Running for 5 out of a total of 5\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.575) total time=   0.7s\n",
      "[CV 2/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.985, test=0.534) total time=   0.7s\n",
      "[CV 3/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.982, test=0.577) total time=   0.7s\n",
      "[CV 4/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.529) total time=   0.6s\n",
      "[CV 5/5; 1/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 1/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.982, test=0.562) total time=   0.6s\n",
      "[CV 1/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.553) total time=   0.7s\n",
      "[CV 2/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.566) total time=   0.7s\n",
      "[CV 3/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.521) total time=   0.7s\n",
      "[CV 4/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.998, test=0.533) total time=   0.6s\n",
      "[CV 5/5; 2/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 2/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.523) total time=   0.7s\n",
      "[CV 1/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.892, test=0.580) total time=   0.2s\n",
      "[CV 2/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.896, test=0.569) total time=   0.2s\n",
      "[CV 3/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.922, test=0.595) total time=   0.2s\n",
      "[CV 4/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.914, test=0.573) total time=   0.2s\n",
      "[CV 5/5; 3/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 3/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.891, test=0.535) total time=   0.2s\n",
      "[CV 1/5; 4/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 4/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.911, test=0.599) total time=   0.7s\n",
      "[CV 2/5; 4/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 4/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.899, test=0.568) total time=   0.8s\n",
      "[CV 3/5; 4/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 4/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.909, test=0.573) total time=   0.7s\n",
      "[CV 4/5; 4/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 4/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.903, test=0.517) total time=   0.7s\n",
      "[CV 5/5; 4/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 4/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.911, test=0.530) total time=   0.7s\n",
      "[CV 1/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.762, test=0.645) total time=   0.5s\n",
      "[CV 2/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.761, test=0.585) total time=   0.6s\n",
      "[CV 3/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.768, test=0.603) total time=   0.5s\n",
      "[CV 4/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.775, test=0.527) total time=   0.5s\n",
      "[CV 5/5; 5/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 5/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.773, test=0.564) total time=   0.5s\n",
      "[CV 1/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.826, test=0.558) total time=   0.2s\n",
      "[CV 2/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.854, test=0.555) total time=   0.2s\n",
      "[CV 3/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.869, test=0.540) total time=   0.2s\n",
      "[CV 4/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.841, test=0.533) total time=   0.2s\n",
      "[CV 5/5; 6/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 6/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.846, test=0.506) total time=   0.2s\n",
      "[CV 1/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.880, test=0.536) total time=   0.2s\n",
      "[CV 2/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.883, test=0.546) total time=   0.2s\n",
      "[CV 3/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.898, test=0.533) total time=   0.2s\n",
      "[CV 4/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.875, test=0.534) total time=   0.3s\n",
      "[CV 5/5; 7/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 7/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.871, test=0.495) total time=   0.2s\n",
      "[CV 1/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.884, test=0.648) total time=   0.4s\n",
      "[CV 2/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.856, test=0.624) total time=   0.4s\n",
      "[CV 3/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.864, test=0.652) total time=   0.4s\n",
      "[CV 4/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.875, test=0.612) total time=   0.5s\n",
      "[CV 5/5; 8/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 8/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.870, test=0.588) total time=   0.5s\n",
      "[CV 1/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.905, test=0.632) total time=   0.8s\n",
      "[CV 2/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.891, test=0.612) total time=   0.8s\n",
      "[CV 3/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.891, test=0.623) total time=   0.8s\n",
      "[CV 4/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.889, test=0.605) total time=   0.7s\n",
      "[CV 5/5; 9/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 9/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.899, test=0.594) total time=   0.7s\n",
      "[CV 1/5; 10/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 10/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.858, test=0.559) total time=   0.5s\n",
      "[CV 2/5; 10/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 10/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.852, test=0.571) total time=   0.5s\n",
      "[CV 3/5; 10/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 10/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.851, test=0.542) total time=   0.5s\n",
      "[CV 4/5; 10/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 10/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.857, test=0.535) total time=   0.5s\n",
      "[CV 5/5; 10/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 10/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.873, test=0.528) total time=   0.6s\n",
      "[CV 1/5; 11/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 11/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.909, test=0.603) total time=   0.5s\n",
      "[CV 2/5; 11/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 11/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.911, test=0.595) total time=   0.5s\n",
      "[CV 3/5; 11/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 11/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.878, test=0.612) total time=   0.5s\n",
      "[CV 4/5; 11/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 11/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.887, test=0.548) total time=   0.5s\n",
      "[CV 5/5; 11/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 11/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.944, test=0.548) total time=   0.5s\n",
      "[CV 1/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.552) total time=   0.7s\n",
      "[CV 2/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.554) total time=   0.7s\n",
      "[CV 3/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.997, test=0.566) total time=   0.6s\n",
      "[CV 4/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.585) total time=   0.6s\n",
      "[CV 5/5; 12/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 12/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.536) total time=   0.7s\n",
      "[CV 1/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.996, test=0.538) total time=   0.7s\n",
      "[CV 2/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.527) total time=   0.7s\n",
      "[CV 3/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.546) total time=   0.7s\n",
      "[CV 4/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.517) total time=   0.8s\n",
      "[CV 5/5; 13/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 13/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.996, test=0.511) total time=   0.7s\n",
      "[CV 1/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.998, test=0.580) total time=   0.7s\n",
      "[CV 2/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.997, test=0.569) total time=   0.7s\n",
      "[CV 3/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.577) total time=   0.7s\n",
      "[CV 4/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.543) total time=   0.7s\n",
      "[CV 5/5; 14/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 14/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.519) total time=   0.7s\n",
      "[CV 1/5; 15/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 15/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.871, test=0.615) total time=   0.2s\n",
      "[CV 2/5; 15/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 15/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.861, test=0.585) total time=   0.2s\n",
      "[CV 3/5; 15/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 15/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.846, test=0.607) total time=   0.2s\n",
      "[CV 4/5; 15/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 15/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.851, test=0.565) total time=   0.2s\n",
      "[CV 5/5; 15/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 15/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.902, test=0.580) total time=   0.2s\n",
      "[CV 1/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.986, test=0.523) total time=   0.3s\n",
      "[CV 2/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.988, test=0.565) total time=   0.4s\n",
      "[CV 3/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.985, test=0.559) total time=   0.3s\n",
      "[CV 4/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.994, test=0.533) total time=   0.4s\n",
      "[CV 5/5; 16/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 16/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.996, test=0.497) total time=   0.4s\n",
      "[CV 1/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.938, test=0.534) total time=   0.3s\n",
      "[CV 2/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.918, test=0.572) total time=   0.3s\n",
      "[CV 3/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.949, test=0.557) total time=   0.3s\n",
      "[CV 4/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.956, test=0.492) total time=   0.3s\n",
      "[CV 5/5; 17/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 17/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.951, test=0.523) total time=   0.3s\n",
      "[CV 1/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.804, test=0.589) total time=   0.2s\n",
      "[CV 2/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.809, test=0.593) total time=   0.2s\n",
      "[CV 3/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.808, test=0.568) total time=   0.2s\n",
      "[CV 4/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.820, test=0.540) total time=   0.2s\n",
      "[CV 5/5; 18/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 18/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.829, test=0.558) total time=   0.3s\n",
      "[CV 1/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.998, test=0.553) total time=   0.6s\n",
      "[CV 2/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.998, test=0.543) total time=   0.7s\n",
      "[CV 3/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.504) total time=   0.7s\n",
      "[CV 4/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.497) total time=   0.8s\n",
      "[CV 5/5; 19/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 19/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.546) total time=   0.7s\n",
      "[CV 1/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.998, test=0.541) total time=   0.3s\n",
      "[CV 2/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.992, test=0.592) total time=   0.3s\n",
      "[CV 3/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.985, test=0.582) total time=   0.3s\n",
      "[CV 4/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.985, test=0.528) total time=   0.3s\n",
      "[CV 5/5; 20/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 20/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.990, test=0.550) total time=   0.3s\n",
      "[CV 1/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.965, test=0.577) total time=   0.5s\n",
      "[CV 2/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.967, test=0.574) total time=   0.5s\n",
      "[CV 3/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.954, test=0.550) total time=   0.5s\n",
      "[CV 4/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.962, test=0.537) total time=   0.5s\n",
      "[CV 5/5; 21/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 21/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.958, test=0.550) total time=   0.5s\n",
      "[CV 1/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.920, test=0.609) total time=   0.8s\n",
      "[CV 2/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.901, test=0.628) total time=   0.8s\n",
      "[CV 3/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.909, test=0.610) total time=   0.8s\n",
      "[CV 4/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.912, test=0.605) total time=   0.9s\n",
      "[CV 5/5; 22/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 22/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.914, test=0.590) total time=   0.7s\n",
      "[CV 1/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.797, test=0.668) total time=   0.5s\n",
      "[CV 2/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.819, test=0.641) total time=   0.5s\n",
      "[CV 3/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.819, test=0.638) total time=   0.5s\n",
      "[CV 4/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.812, test=0.613) total time=   0.6s\n",
      "[CV 5/5; 23/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 23/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.814, test=0.599) total time=   0.6s\n",
      "[CV 1/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.854, test=0.615) total time=   0.4s\n",
      "[CV 2/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.840, test=0.578) total time=   0.3s\n",
      "[CV 3/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.853, test=0.570) total time=   0.3s\n",
      "[CV 4/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.859, test=0.522) total time=   0.3s\n",
      "[CV 5/5; 24/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 24/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.875, test=0.553) total time=   0.4s\n",
      "[CV 1/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.894, test=0.519) total time=   0.5s\n",
      "[CV 2/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.881, test=0.572) total time=   0.5s\n",
      "[CV 3/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.917, test=0.535) total time=   0.5s\n",
      "[CV 4/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.914, test=0.475) total time=   0.5s\n",
      "[CV 5/5; 25/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 25/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.907, test=0.494) total time=   0.5s\n",
      "[CV 1/5; 26/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 26/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.869, test=0.603) total time=   0.2s\n",
      "[CV 2/5; 26/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 26/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.887, test=0.579) total time=   0.2s\n",
      "[CV 3/5; 26/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 26/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.850, test=0.596) total time=   0.2s\n",
      "[CV 4/5; 26/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 26/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.877, test=0.555) total time=   0.2s\n",
      "[CV 5/5; 26/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 26/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.871, test=0.561) total time=   0.2s\n",
      "[CV 1/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.854, test=0.608) total time=   0.5s\n",
      "[CV 2/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.849, test=0.621) total time=   0.5s\n",
      "[CV 3/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.871, test=0.611) total time=   0.5s\n",
      "[CV 4/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.906, test=0.579) total time=   0.5s\n",
      "[CV 5/5; 27/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 27/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.884, test=0.557) total time=   0.5s\n",
      "[CV 1/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.997, test=0.535) total time=   0.7s\n",
      "[CV 2/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.995, test=0.554) total time=   0.7s\n",
      "[CV 3/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.996, test=0.545) total time=   0.7s\n",
      "[CV 4/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.998, test=0.514) total time=   0.7s\n",
      "[CV 5/5; 28/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 28/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.503) total time=   0.7s\n",
      "[CV 1/5; 29/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 29/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.922, test=0.577) total time=   0.5s\n",
      "[CV 2/5; 29/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 29/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.901, test=0.618) total time=   0.5s\n",
      "[CV 3/5; 29/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 29/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.898, test=0.611) total time=   0.5s\n",
      "[CV 4/5; 29/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 29/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.906, test=0.549) total time=   0.5s\n",
      "[CV 5/5; 29/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 29/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.907, test=0.514) total time=   0.5s\n",
      "[CV 1/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.984, test=0.508) total time=   0.6s\n",
      "[CV 2/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.990, test=0.545) total time=   0.6s\n",
      "[CV 3/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.998, test=0.537) total time=   0.7s\n",
      "[CV 4/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.472) total time=   0.6s\n",
      "[CV 5/5; 30/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 30/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.513) total time=   0.7s\n",
      "[CV 1/5; 31/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 31/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.883, test=0.601) total time=   0.3s\n",
      "[CV 2/5; 31/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 31/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.862, test=0.619) total time=   0.2s\n",
      "[CV 3/5; 31/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 31/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.865, test=0.585) total time=   0.2s\n",
      "[CV 4/5; 31/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 31/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.867, test=0.578) total time=   0.3s\n",
      "[CV 5/5; 31/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 31/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.856, test=0.541) total time=   0.3s\n",
      "[CV 1/5; 32/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 32/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.908, test=0.644) total time=   0.7s\n",
      "[CV 2/5; 32/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 32/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.878, test=0.629) total time=   0.7s\n",
      "[CV 3/5; 32/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 32/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.879, test=0.642) total time=   0.7s\n",
      "[CV 4/5; 32/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 32/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.883, test=0.603) total time=   0.7s\n",
      "[CV 5/5; 32/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 32/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.893, test=0.607) total time=   0.7s\n",
      "[CV 1/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.821, test=0.629) total time=   0.3s\n",
      "[CV 2/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.818, test=0.636) total time=   0.2s\n",
      "[CV 3/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.838, test=0.601) total time=   0.2s\n",
      "[CV 4/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.865, test=0.549) total time=   0.2s\n",
      "[CV 5/5; 33/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 33/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.842, test=0.577) total time=   0.2s\n",
      "[CV 1/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.779, test=0.673) total time=   0.3s\n",
      "[CV 2/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.785, test=0.654) total time=   0.3s\n",
      "[CV 3/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.782, test=0.648) total time=   0.3s\n",
      "[CV 4/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.790, test=0.607) total time=   0.3s\n",
      "[CV 5/5; 34/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 34/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.787, test=0.620) total time=   0.3s\n",
      "[CV 1/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.875, test=0.530) total time=   0.2s\n",
      "[CV 2/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.844, test=0.562) total time=   0.2s\n",
      "[CV 3/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.884, test=0.534) total time=   0.3s\n",
      "[CV 4/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.880, test=0.515) total time=   0.2s\n",
      "[CV 5/5; 35/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 35/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.868, test=0.505) total time=   0.3s\n",
      "[CV 1/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.990, test=0.523) total time=   0.4s\n",
      "[CV 2/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.982, test=0.535) total time=   0.4s\n",
      "[CV 3/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.977, test=0.542) total time=   0.3s\n",
      "[CV 4/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.991, test=0.509) total time=   0.3s\n",
      "[CV 5/5; 36/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 36/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.981, test=0.509) total time=   0.3s\n",
      "[CV 1/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 1/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.848, test=0.630) total time=   0.4s\n",
      "[CV 2/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 2/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.843, test=0.596) total time=   0.4s\n",
      "[CV 3/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 3/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.852, test=0.582) total time=   0.4s\n",
      "[CV 4/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 4/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.853, test=0.529) total time=   0.4s\n",
      "[CV 5/5; 37/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1\n",
      "[CV 5/5; 37/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.1, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=1;, score=(train=0.851, test=0.571) total time=   0.4s\n",
      "[CV 1/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.549) total time=   0.6s\n",
      "[CV 2/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.995, test=0.550) total time=   0.6s\n",
      "[CV 3/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.995, test=0.528) total time=   0.6s\n",
      "[CV 4/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.999, test=0.515) total time=   0.7s\n",
      "[CV 5/5; 38/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 38/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=1.000, test=0.507) total time=   0.7s\n",
      "[CV 1/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.887, test=0.563) total time=   0.2s\n",
      "[CV 2/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.849, test=0.592) total time=   0.2s\n",
      "[CV 3/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.881, test=0.625) total time=   0.2s\n",
      "[CV 4/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.935, test=0.561) total time=   0.2s\n",
      "[CV 5/5; 39/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 39/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.1, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.898, test=0.563) total time=   0.2s\n",
      "[CV 1/5; 40/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 40/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.955, test=0.569) total time=   0.3s\n",
      "[CV 2/5; 40/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 40/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.979, test=0.569) total time=   0.3s\n",
      "[CV 3/5; 40/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 40/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.973, test=0.587) total time=   0.3s\n",
      "[CV 4/5; 40/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 40/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.984, test=0.561) total time=   0.3s\n",
      "[CV 5/5; 40/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 40/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.001;, score=(train=0.921, test=0.520) total time=   0.3s\n",
      "[CV 1/5; 41/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 41/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.879, test=0.609) total time=   0.5s\n",
      "[CV 2/5; 41/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 41/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.865, test=0.605) total time=   0.5s\n",
      "[CV 3/5; 41/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 41/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.892, test=0.584) total time=   0.5s\n",
      "[CV 4/5; 41/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 41/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.894, test=0.542) total time=   0.5s\n",
      "[CV 5/5; 41/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 41/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.882, test=0.588) total time=   0.5s\n",
      "[CV 1/5; 42/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 42/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.975, test=0.537) total time=   0.5s\n",
      "[CV 2/5; 42/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 42/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.966, test=0.600) total time=   0.5s\n",
      "[CV 3/5; 42/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 42/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.953, test=0.543) total time=   0.5s\n",
      "[CV 4/5; 42/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 42/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.975, test=0.564) total time=   0.5s\n",
      "[CV 5/5; 42/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 42/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.959, test=0.527) total time=   0.5s\n",
      "[CV 1/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.511) total time=   0.6s\n",
      "[CV 2/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.998, test=0.537) total time=   0.6s\n",
      "[CV 3/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.997, test=0.557) total time=   0.7s\n",
      "[CV 4/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.999, test=0.523) total time=   0.6s\n",
      "[CV 5/5; 43/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 43/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=1.000, test=0.552) total time=   0.7s\n",
      "[CV 1/5; 44/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 44/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.985, test=0.534) total time=   0.5s\n",
      "[CV 2/5; 44/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 44/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.991, test=0.592) total time=   0.6s\n",
      "[CV 3/5; 44/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 44/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.953, test=0.564) total time=   0.6s\n",
      "[CV 4/5; 44/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 44/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.982, test=0.504) total time=   0.6s\n",
      "[CV 5/5; 44/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 44/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.975, test=0.502) total time=   0.5s\n",
      "[CV 1/5; 45/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 45/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.857, test=0.627) total time=   0.4s\n",
      "[CV 2/5; 45/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 45/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.852, test=0.577) total time=   0.4s\n",
      "[CV 3/5; 45/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 45/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.859, test=0.611) total time=   0.4s\n",
      "[CV 4/5; 45/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 45/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.865, test=0.526) total time=   0.3s\n",
      "[CV 5/5; 45/50] START xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 45/50] END xgb__colsample_bytree=0.5, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=100, xgb__reg_lambda=0.1;, score=(train=0.868, test=0.578) total time=   0.4s\n",
      "[CV 1/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.978, test=0.543) total time=   0.6s\n",
      "[CV 2/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.971, test=0.536) total time=   0.7s\n",
      "[CV 3/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.962, test=0.556) total time=   0.7s\n",
      "[CV 4/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.985, test=0.510) total time=   0.8s\n",
      "[CV 5/5; 46/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 46/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.967, test=0.532) total time=   0.6s\n",
      "[CV 1/5; 47/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 1/5; 47/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.949, test=0.535) total time=   0.5s\n",
      "[CV 2/5; 47/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 2/5; 47/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.955, test=0.577) total time=   0.5s\n",
      "[CV 3/5; 47/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 3/5; 47/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.938, test=0.576) total time=   0.5s\n",
      "[CV 4/5; 47/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 4/5; 47/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.969, test=0.538) total time=   0.5s\n",
      "[CV 5/5; 47/50] START xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001\n",
      "[CV 5/5; 47/50] END xgb__colsample_bytree=0.7, xgb__gamma=2, xgb__learning_rate=1, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.001;, score=(train=0.944, test=0.542) total time=   0.5s\n",
      "[CV 1/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.828, test=0.595) total time=   0.8s\n",
      "[CV 2/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.804, test=0.606) total time=   0.8s\n",
      "[CV 3/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.825, test=0.578) total time=   0.8s\n",
      "[CV 4/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.823, test=0.534) total time=   0.8s\n",
      "[CV 5/5; 48/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 48/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.831, test=0.566) total time=   0.9s\n",
      "[CV 1/5; 49/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 1/5; 49/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.900, test=0.535) total time=   0.5s\n",
      "[CV 2/5; 49/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 2/5; 49/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.870, test=0.561) total time=   0.6s\n",
      "[CV 3/5; 49/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 3/5; 49/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.876, test=0.550) total time=   0.5s\n",
      "[CV 4/5; 49/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 4/5; 49/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.880, test=0.525) total time=   0.5s\n",
      "[CV 5/5; 49/50] START xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1\n",
      "[CV 5/5; 49/50] END xgb__colsample_bytree=0.5, xgb__gamma=2, xgb__learning_rate=0.5, xgb__max_depth=6, xgb__n_estimators=200, xgb__reg_lambda=0.1;, score=(train=0.860, test=0.492) total time=   0.5s\n",
      "[CV 1/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 1/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.584) total time=   0.6s\n",
      "[CV 2/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 2/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.999, test=0.580) total time=   1.1s\n",
      "[CV 3/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 3/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=0.998, test=0.583) total time=   0.9s\n",
      "[CV 4/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 4/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.534) total time=   0.7s\n",
      "[CV 5/5; 50/50] START xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1\n",
      "[CV 5/5; 50/50] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=1, xgb__max_depth=8, xgb__n_estimators=200, xgb__reg_lambda=1;, score=(train=1.000, test=0.548) total time=   0.6s\n",
      "Selected Parameters: {'xgb__reg_lambda': 0.001, 'xgb__n_estimators': 100, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.5, 'xgb__colsample_bytree': 0.7}\n",
      "Train score: 0.7726569749458707\n",
      "Test score: 0.3192182410423453\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_xgb_binary.p\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "pickle.dump(selected_params_xgb_binary, open(path, \"wb\"))\r\n",
    "\r\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_xgb_binary.csv\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "df_predicted_xgb_binary.to_csv(path, index=False)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:3: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_xgb_binary.p'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmark"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# Random unweighted predictions\r\n",
    "df_predicted_random = pd.DataFrame(columns=[\"year\", \"actual\", \"predicted\"])\r\n",
    "\r\n",
    "for i in range(len(df_train_list)):\r\n",
    "\r\n",
    "    train = df_train_list[i]\r\n",
    "    test = df_test_list[i]\r\n",
    "\r\n",
    "    y_train = train[\"class_value_binary\"]\r\n",
    "    y_test = test[\"class_value_binary\"]\r\n",
    "\r\n",
    "    y_pred_test = unweighted_random(y_train, y_test)\r\n",
    "    df_predicted_temp = pd.DataFrame(\r\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_pred_test}\r\n",
    "    )\r\n",
    "\r\n",
    "    df_predicted_random = pd.concat([df_predicted_random, df_predicted_temp])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# Random Weighted Predictions\r\n",
    "df_predicted_random_weighted = pd.DataFrame(columns=[\"year\", \"actual\", \"predicted\"])\r\n",
    "for i in range(len(df_train_list)):\r\n",
    "\r\n",
    "    train = df_train_list[i]\r\n",
    "    test = df_test_list[i]\r\n",
    "\r\n",
    "    y_train = train[\"class_value_binary\"]\r\n",
    "    y_test = test[\"class_value_binary\"]\r\n",
    "\r\n",
    "    y_pred_test = weighted_random(y_train, y_test)\r\n",
    "    df_predicted_temp = pd.DataFrame(\r\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_pred_test}\r\n",
    "    )\r\n",
    "\r\n",
    "    df_predicted_random_weighted = pd.concat(\r\n",
    "        [df_predicted_random_weighted, df_predicted_temp]\r\n",
    "    )\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "models = {\r\n",
    "    \"Random Fores\": df_predicted_rf_binary,\r\n",
    "    \"XGBoost\": df_predicted_xgb_binary,\r\n",
    "    \"Random\": df_predicted_random,\r\n",
    "    \"Weighted Random\": df_predicted_random_weighted,\r\n",
    "}\r\n",
    "\r\n",
    "f1 = []\r\n",
    "precision = []\r\n",
    "recall = []\r\n",
    "\r\n",
    "# add 'list' if error\r\n",
    "for df_temp in models.values():\r\n",
    "    f1.append(f1_score(list(df_temp[\"actual\"]), list(df_temp[\"predicted\"])))\r\n",
    "    precision.append(precision_score(list(df_temp[\"actual\"]), list(df_temp[\"predicted\"])))\r\n",
    "    recall.append(recall_score(list(df_temp[\"actual\"]), list(df_temp[\"predicted\"])))\r\n",
    "\r\n",
    "df_results_binary = pd.DataFrame(\r\n",
    "    {\"Models\": list(models.keys()), \"F1 score\": f1, \"Recall\": recall, \"Precision\": precision}\r\n",
    ")\r\n",
    "\r\n",
    "display(df_results_binary)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Fores</td>\n",
       "      <td>0.527349</td>\n",
       "      <td>0.535613</td>\n",
       "      <td>0.519337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.518862</td>\n",
       "      <td>0.558405</td>\n",
       "      <td>0.484549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random</td>\n",
       "      <td>0.377255</td>\n",
       "      <td>0.491453</td>\n",
       "      <td>0.306122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weighted Random</td>\n",
       "      <td>0.329497</td>\n",
       "      <td>0.387464</td>\n",
       "      <td>0.286617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Models  F1 score    Recall  Precision\n",
       "0     Random Fores  0.527349  0.535613   0.519337\n",
       "1          XGBoost  0.518862  0.558405   0.484549\n",
       "2           Random  0.377255  0.491453   0.306122\n",
       "3  Weighted Random  0.329497  0.387464   0.286617"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Optimal Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "### Training the optimal model\r\n",
    "rf = RandomForestClassifier(\r\n",
    "    class_weight=\"balanced\",\r\n",
    "    n_estimators=250,\r\n",
    "    max_depth=20,\r\n",
    "    min_samples_leaf=5,\r\n",
    "    min_samples_split=15,\r\n",
    ")\r\n",
    "\r\n",
    "selected_features_rf_binary = [\r\n",
    "    \"rainfall_max_6h\",\r\n",
    "    \"dis_track_min\",\r\n",
    "    \"vmax\",\r\n",
    "]\r\n",
    "\r\n",
    "rf_fitted = rf.fit(X[selected_features_rf_binary], y)\r\n",
    "\r\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_binary_rf.sav\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "pickle.dump(rf_fitted, open(path, \"wb\"))\r\n",
    "\r\n",
    "# # Display feature importance\r\n",
    "# importances = rf_fitted.feature_importances_\r\n",
    "# forest_importances = pd.Series(importances, index=selected_features_rf_binary)\r\n",
    "# fig, ax = plt.subplots()\r\n",
    "# forest_importances.plot.bar(ax=ax)\r\n",
    "# ax.set_title(\"Feature importances using MDI\")\r\n",
    "# ax.set_ylabel(\"Mean decrease in impurity\")\r\n",
    "# fig.tight_layout()\r\n",
    "# plt.show()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:20: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_binary_rf.sav'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multiclass Classification\r\n",
    "\r\n",
    "This section obtains the optimal Multiclass Classification models and the performance estimates, with three classes. Two models are implemented: Random Forest Classifier, XGBoost Classifier. First, the model is trained on the full dataset to obtain the optimal features followed by a model that obtains the performance estimate using Nested Cross Validation. The classes are:\r\n",
    "- 0 - 30%\r\n",
    "- 30% - 80%\r\n",
    "- 80% - 100% <br> <br>\r\n",
    "\r\n",
    "\r\n",
    "- Performance Metric\r\n",
    "- Nested Cross Validation\r\n",
    "- Benchmark Models\r\n",
    "- Main findings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "# Setting class value\r\n",
    "# Set final boundary slightly over 1 so 1's are included as well\r\n",
    "df_multi = df[df['perc_loss'].notnull()]\r\n",
    "classes = {\"0\": [0, 0.3], \"1\": [0.3, 0.8], \"2\": [0.8, 1.1]}\r\n",
    "df_multi[\"class_value_multi\"] = df_multi[\"perc_loss\"].apply(\r\n",
    "    lambda x: determine_class(x, classes=classes)\r\n",
    ")\r\n",
    "\r\n",
    "# Setting for feature seleciton on full data set\r\n",
    "X = df_multi[features]\r\n",
    "y = df_multi[\"class_value_multi\"]\r\n",
    "\r\n",
    "# Setting train and test set for obtaining performance estimate\r\n",
    "df_train_list, df_test_list = splitting_train_test(df_multi)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting the optimal hyperparameters and features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of features selected in RF multiclass: 14\r\n",
    "\r\n",
    "The selected features ares:\r\n",
    "- mean_slope\r\n",
    "- mean_elevation_m\r\n",
    "- ruggedness_stdev\r\n",
    "- mean_ruggedness\r\n",
    "- slope_stdev\r\n",
    "- area_km2\r\n",
    "- poverty_perc\r\n",
    "- perimeter\r\n",
    "- glat\r\n",
    "- glon\r\n",
    "- rainfall_max_6h\r\n",
    "- rainfall_max_24h\r\n",
    "- dis_track_min\r\n",
    "- vmax\r\n",
    "\r\n",
    "Selected Parameters in RF multiclass: \r\n",
    "- max_depth = None\r\n",
    "- min_samples_leaf = 3\r\n",
    "- min_samples_split = 15\r\n",
    "- n_estimators = 50"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Setting the random forest search grid\r\n",
    "rf_search_space = [\r\n",
    "    {\r\n",
    "        \"estimator__n_estimators\": [50, 100, 150],\r\n",
    "        \"estimator__max_depth\": [20, None],\r\n",
    "        \"estimator__min_samples_split\": [2, 10, 15],\r\n",
    "        \"estimator__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "selected_features_rf_multi, selected_params_rf_multi_full = rf_multi_features(\r\n",
    "    X=X,\r\n",
    "    y=y,\r\n",
    "    features=features,\r\n",
    "    search_space=rf_search_space,\r\n",
    "    cv_splits=5,\r\n",
    "    class_weight=\"balanced\",\r\n",
    "    min_features_to_select=1,\r\n",
    "    GS_score=\"f1_macro\",\r\n",
    "    GS_randomized=False,\r\n",
    "    GS_n_iter=10,\r\n",
    "    verbose=10,\r\n",
    ")\r\n",
    "\r\n",
    "print(\r\n",
    "    f\"Number of features selected in RF multiclass: {len(selected_features_rf_multi)}\"\r\n",
    ")\r\n",
    "print(f\"Selected features RF multiclass: {selected_features_rf_multi}\")\r\n",
    "print(f\"Selected Parameters in RF multiclass: {selected_params_rf_multi_full}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5; 1/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 1/5; 1/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.999, test=0.420) total time=  25.2s\n",
      "[CV 2/5; 1/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 2/5; 1/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=1.000, test=0.403) total time=  24.9s\n",
      "[CV 3/5; 1/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 3/5; 1/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=1.000, test=0.480) total time=  26.8s\n",
      "[CV 4/5; 1/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 4/5; 1/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=1.000, test=0.416) total time=  25.8s\n",
      "[CV 5/5; 1/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 5/5; 1/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=1.000, test=0.437) total time=  26.1s\n",
      "[CV 1/5; 2/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 2/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.437) total time=  50.1s\n",
      "[CV 2/5; 2/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 2/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.413) total time=  50.9s\n",
      "[CV 3/5; 2/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 2/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.409) total time=  51.1s\n",
      "[CV 4/5; 2/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 2/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.439) total time=  52.0s\n",
      "[CV 5/5; 2/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 2/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.418) total time=  50.7s\n",
      "[CV 1/5; 3/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 1/5; 3/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=1.000, test=0.457) total time= 1.2min\n",
      "[CV 2/5; 3/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 2/5; 3/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=1.000, test=0.399) total time= 1.2min\n",
      "[CV 3/5; 3/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 3/5; 3/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=1.000, test=0.396) total time= 1.3min\n",
      "[CV 4/5; 3/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 4/5; 3/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=1.000, test=0.435) total time= 1.2min\n",
      "[CV 5/5; 3/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 5/5; 3/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=1.000, test=0.415) total time= 1.2min\n",
      "[CV 1/5; 4/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 1/5; 4/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.949, test=0.459) total time=  21.6s\n",
      "[CV 2/5; 4/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 2/5; 4/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.874, test=0.478) total time=  25.0s\n",
      "[CV 3/5; 4/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 3/5; 4/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.951, test=0.445) total time=  22.9s\n",
      "[CV 4/5; 4/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 4/5; 4/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.947, test=0.446) total time=  26.4s\n",
      "[CV 5/5; 4/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 5/5; 4/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.947, test=0.460) total time=  23.0s\n",
      "[CV 1/5; 5/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 5/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.951, test=0.491) total time=  47.8s\n",
      "[CV 2/5; 5/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 5/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.960, test=0.442) total time=  46.1s\n",
      "[CV 3/5; 5/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 5/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.960, test=0.431) total time=  42.5s\n",
      "[CV 4/5; 5/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 5/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.965, test=0.455) total time=  45.7s\n",
      "[CV 5/5; 5/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 5/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.958, test=0.475) total time=  45.9s\n",
      "[CV 1/5; 6/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 1/5; 6/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.914, test=0.511) total time= 1.2min\n",
      "[CV 2/5; 6/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 2/5; 6/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.961, test=0.448) total time= 1.1min\n",
      "[CV 3/5; 6/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 3/5; 6/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.960, test=0.440) total time=  59.1s\n",
      "[CV 4/5; 6/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 4/5; 6/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.966, test=0.472) total time= 1.0min\n",
      "[CV 5/5; 6/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 5/5; 6/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.959, test=0.461) total time= 1.1min\n",
      "[CV 1/5; 7/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 1/5; 7/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.894, test=0.481) total time=  20.9s\n",
      "[CV 2/5; 7/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 2/5; 7/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.823, test=0.478) total time=  24.1s\n",
      "[CV 3/5; 7/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 3/5; 7/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.901, test=0.437) total time=  21.9s\n",
      "[CV 4/5; 7/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 4/5; 7/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.885, test=0.466) total time=  21.9s\n",
      "[CV 5/5; 7/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 5/5; 7/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.895, test=0.472) total time=  21.7s\n",
      "[CV 1/5; 8/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 8/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.907, test=0.485) total time=  41.9s\n",
      "[CV 2/5; 8/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 8/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.911, test=0.468) total time=  39.3s\n",
      "[CV 3/5; 8/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 8/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.899, test=0.447) total time=  41.4s\n",
      "[CV 4/5; 8/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 8/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.906, test=0.469) total time=  42.8s\n",
      "[CV 5/5; 8/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 8/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.902, test=0.488) total time=  46.0s\n",
      "[CV 1/5; 9/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 1/5; 9/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.896, test=0.469) total time= 1.1min\n",
      "[CV 2/5; 9/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 2/5; 9/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.913, test=0.457) total time= 1.0min\n",
      "[CV 3/5; 9/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 3/5; 9/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.909, test=0.453) total time= 1.1min\n",
      "[CV 4/5; 9/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 4/5; 9/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.904, test=0.471) total time=  59.4s\n",
      "[CV 5/5; 9/54] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 5/5; 9/54] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.901, test=0.476) total time= 1.0min\n",
      "[CV 1/5; 10/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 1/5; 10/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.949, test=0.485) total time=  20.7s\n",
      "[CV 2/5; 10/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 2/5; 10/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.956, test=0.444) total time=  21.2s\n",
      "[CV 3/5; 10/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 3/5; 10/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.956, test=0.438) total time=  21.9s\n",
      "[CV 4/5; 10/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 4/5; 10/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.960, test=0.481) total time=  22.6s\n",
      "[CV 5/5; 10/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 5/5; 10/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.963, test=0.443) total time=  22.7s\n",
      "[CV 1/5; 11/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 11/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.969, test=0.475) total time=  36.2s\n",
      "[CV 2/5; 11/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 11/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.964, test=0.439) total time=  44.9s\n",
      "[CV 3/5; 11/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 11/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.957, test=0.443) total time=  45.7s\n",
      "[CV 4/5; 11/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 11/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.968, test=0.466) total time=  43.6s\n",
      "[CV 5/5; 11/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 11/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.972, test=0.451) total time=  45.7s\n",
      "[CV 1/5; 12/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 1/5; 12/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.964, test=0.495) total time= 1.1min\n",
      "[CV 2/5; 12/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 2/5; 12/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.961, test=0.446) total time= 1.2min\n",
      "[CV 3/5; 12/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 3/5; 12/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.967, test=0.439) total time= 1.1min\n",
      "[CV 4/5; 12/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 4/5; 12/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.974, test=0.487) total time= 1.2min\n",
      "[CV 5/5; 12/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 5/5; 12/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.971, test=0.468) total time= 1.1min\n",
      "[CV 1/5; 13/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 1/5; 13/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.924, test=0.476) total time=  22.0s\n",
      "[CV 2/5; 13/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 2/5; 13/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.833, test=0.463) total time=  24.1s\n",
      "[CV 3/5; 13/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 3/5; 13/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.917, test=0.453) total time=  21.5s\n",
      "[CV 4/5; 13/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 4/5; 13/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.922, test=0.468) total time=  22.7s\n",
      "[CV 5/5; 13/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 5/5; 13/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.922, test=0.479) total time=  22.4s\n",
      "[CV 1/5; 14/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 14/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.937, test=0.479) total time=  43.5s\n",
      "[CV 2/5; 14/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 14/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.933, test=0.460) total time=  44.2s\n",
      "[CV 3/5; 14/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 14/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.924, test=0.437) total time=  43.8s\n",
      "[CV 4/5; 14/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 14/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.928, test=0.484) total time=  42.4s\n",
      "[CV 5/5; 14/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 14/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.924, test=0.474) total time=  44.5s\n",
      "[CV 1/5; 15/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 1/5; 15/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.908, test=0.499) total time= 1.1min\n",
      "[CV 2/5; 15/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 2/5; 15/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.937, test=0.447) total time= 1.1min\n",
      "[CV 3/5; 15/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 3/5; 15/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.923, test=0.443) total time=  56.6s\n",
      "[CV 4/5; 15/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 4/5; 15/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.932, test=0.466) total time= 1.1min\n",
      "[CV 5/5; 15/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 5/5; 15/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.846, test=0.478) total time= 1.2min\n",
      "[CV 1/5; 16/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 1/5; 16/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.816, test=0.499) total time=  23.4s\n",
      "[CV 2/5; 16/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 2/5; 16/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.793, test=0.476) total time=  23.3s\n",
      "[CV 3/5; 16/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 3/5; 16/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.861, test=0.421) total time=  18.7s\n",
      "[CV 4/5; 16/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 4/5; 16/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.865, test=0.466) total time=  21.3s\n",
      "[CV 5/5; 16/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 5/5; 16/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.859, test=0.456) total time=  20.3s\n",
      "[CV 1/5; 17/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 17/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.868, test=0.512) total time=  43.8s\n",
      "[CV 2/5; 17/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 17/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.878, test=0.451) total time=  40.0s\n",
      "[CV 3/5; 17/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 17/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.876, test=0.451) total time=  38.2s\n",
      "[CV 4/5; 17/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 17/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.866, test=0.468) total time=  38.9s\n",
      "[CV 5/5; 17/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 17/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.873, test=0.472) total time=  39.9s\n",
      "[CV 1/5; 18/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 1/5; 18/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.873, test=0.491) total time= 1.2min\n",
      "[CV 2/5; 18/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 2/5; 18/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.890, test=0.465) total time= 1.1min\n",
      "[CV 3/5; 18/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 3/5; 18/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.884, test=0.444) total time=  56.5s\n",
      "[CV 4/5; 18/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 4/5; 18/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.876, test=0.470) total time=  56.5s\n",
      "[CV 5/5; 18/54] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 5/5; 18/54] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.877, test=0.474) total time= 1.1min\n",
      "[CV 1/5; 19/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 1/5; 19/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.823, test=0.498) total time=  23.1s\n",
      "[CV 2/5; 19/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 2/5; 19/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.890, test=0.461) total time=  19.4s\n",
      "[CV 3/5; 19/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 3/5; 19/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.883, test=0.439) total time=  17.2s\n",
      "[CV 4/5; 19/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 4/5; 19/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.881, test=0.470) total time=  20.3s\n",
      "[CV 5/5; 19/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 5/5; 19/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.891, test=0.479) total time=  21.7s\n",
      "[CV 1/5; 20/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 20/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.876, test=0.506) total time=  43.6s\n",
      "[CV 2/5; 20/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 20/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.902, test=0.451) total time=  42.1s\n",
      "[CV 3/5; 20/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 20/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.899, test=0.450) total time=  41.8s\n",
      "[CV 4/5; 20/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 20/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.892, test=0.454) total time=  40.2s\n",
      "[CV 5/5; 20/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 20/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.881, test=0.474) total time=  43.0s\n",
      "[CV 1/5; 21/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 1/5; 21/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.894, test=0.477) total time= 1.1min\n",
      "[CV 2/5; 21/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 2/5; 21/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.810, test=0.471) total time= 1.2min\n",
      "[CV 3/5; 21/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 3/5; 21/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.897, test=0.434) total time= 1.0min\n",
      "[CV 4/5; 21/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 4/5; 21/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.890, test=0.477) total time=  57.1s\n",
      "[CV 5/5; 21/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 5/5; 21/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.896, test=0.479) total time= 1.0min\n",
      "[CV 1/5; 22/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 1/5; 22/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.887, test=0.501) total time=  20.9s\n",
      "[CV 2/5; 22/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 2/5; 22/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.887, test=0.431) total time=  21.7s\n",
      "[CV 3/5; 22/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 3/5; 22/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.885, test=0.459) total time=  20.7s\n",
      "[CV 4/5; 22/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 4/5; 22/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.883, test=0.468) total time=  21.4s\n",
      "[CV 5/5; 22/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 5/5; 22/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.867, test=0.472) total time=  19.9s\n",
      "[CV 1/5; 23/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 23/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.888, test=0.497) total time=  41.9s\n",
      "[CV 2/5; 23/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 23/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.886, test=0.459) total time=  43.3s\n",
      "[CV 3/5; 23/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 23/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.879, test=0.438) total time=  38.0s\n",
      "[CV 4/5; 23/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 23/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.893, test=0.481) total time=  41.2s\n",
      "[CV 5/5; 23/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 23/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.893, test=0.480) total time=  42.6s\n",
      "[CV 1/5; 24/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 1/5; 24/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.872, test=0.505) total time= 1.1min\n",
      "[CV 2/5; 24/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 2/5; 24/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.899, test=0.452) total time= 1.0min\n",
      "[CV 3/5; 24/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 3/5; 24/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.892, test=0.444) total time= 1.0min\n",
      "[CV 4/5; 24/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 4/5; 24/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.887, test=0.455) total time= 1.0min\n",
      "[CV 5/5; 24/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 5/5; 24/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.898, test=0.469) total time= 1.0min\n",
      "[CV 1/5; 25/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 1/5; 25/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.835, test=0.487) total time=  20.0s\n",
      "[CV 2/5; 25/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 2/5; 25/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.757, test=0.482) total time=  22.6s\n",
      "[CV 3/5; 25/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 3/5; 25/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.834, test=0.436) total time=  22.0s\n",
      "[CV 4/5; 25/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 4/5; 25/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.833, test=0.479) total time=  20.9s\n",
      "[CV 5/5; 25/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 5/5; 25/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.831, test=0.481) total time=  19.4s\n",
      "[CV 1/5; 26/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 26/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.833, test=0.486) total time=  41.9s\n",
      "[CV 2/5; 26/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 26/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.850, test=0.458) total time=  39.5s\n",
      "[CV 3/5; 26/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 26/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.853, test=0.452) total time=  40.0s\n",
      "[CV 4/5; 26/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 26/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.850, test=0.459) total time=  37.4s\n",
      "[CV 5/5; 26/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 26/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.854, test=0.481) total time=  40.9s\n",
      "[CV 1/5; 27/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 1/5; 27/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.842, test=0.493) total time= 1.0min\n",
      "[CV 2/5; 27/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 2/5; 27/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.844, test=0.460) total time= 1.1min\n",
      "[CV 3/5; 27/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 3/5; 27/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.858, test=0.455) total time=  54.7s\n",
      "[CV 4/5; 27/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 4/5; 27/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.844, test=0.482) total time=  54.4s\n",
      "[CV 5/5; 27/54] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 5/5; 27/54] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.837, test=0.459) total time=  56.0s\n",
      "[CV 1/5; 28/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 1/5; 28/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=1.000, test=0.449) total time=  26.5s\n",
      "[CV 2/5; 28/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 2/5; 28/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=1.000, test=0.419) total time=  24.6s\n",
      "[CV 3/5; 28/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 3/5; 28/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=1.000, test=0.400) total time=  22.9s\n",
      "[CV 4/5; 28/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 4/5; 28/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=1.000, test=0.432) total time=  24.2s\n",
      "[CV 5/5; 28/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 5/5; 28/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=1.000, test=0.399) total time=  25.7s\n",
      "[CV 1/5; 29/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 29/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.442) total time=  51.8s\n",
      "[CV 2/5; 29/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 29/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.446) total time=  53.0s\n",
      "[CV 3/5; 29/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 29/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.405) total time=  48.3s\n",
      "[CV 4/5; 29/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 29/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.412) total time=  51.4s\n",
      "[CV 5/5; 29/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 29/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=1.000, test=0.414) total time=  52.0s\n",
      "[CV 1/5; 30/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 1/5; 30/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=1.000, test=0.402) total time= 1.2min\n",
      "[CV 2/5; 30/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 2/5; 30/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=1.000, test=0.391) total time= 1.2min\n",
      "[CV 3/5; 30/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 3/5; 30/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=1.000, test=0.417) total time= 1.3min\n",
      "[CV 4/5; 30/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 4/5; 30/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=1.000, test=0.429) total time= 1.3min\n",
      "[CV 5/5; 30/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 5/5; 30/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=1.000, test=0.411) total time= 1.3min\n",
      "[CV 1/5; 31/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 1/5; 31/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.958, test=0.487) total time=  23.0s\n",
      "[CV 2/5; 31/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 2/5; 31/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.946, test=0.444) total time=  21.2s\n",
      "[CV 3/5; 31/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 3/5; 31/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.937, test=0.438) total time=  23.4s\n",
      "[CV 4/5; 31/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 4/5; 31/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.949, test=0.458) total time=  24.0s\n",
      "[CV 5/5; 31/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 5/5; 31/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.950, test=0.446) total time=  20.3s\n",
      "[CV 1/5; 32/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 32/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.952, test=0.505) total time=  47.7s\n",
      "[CV 2/5; 32/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 32/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.955, test=0.442) total time=  47.3s\n",
      "[CV 3/5; 32/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 32/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.958, test=0.430) total time=  43.5s\n",
      "[CV 4/5; 32/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 32/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.966, test=0.465) total time=  46.8s\n",
      "[CV 5/5; 32/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 32/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.952, test=0.462) total time=  47.1s\n",
      "[CV 1/5; 33/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 1/5; 33/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.966, test=0.475) total time= 1.1min\n",
      "[CV 2/5; 33/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 2/5; 33/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.965, test=0.436) total time= 1.1min\n",
      "[CV 3/5; 33/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 3/5; 33/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.964, test=0.437) total time= 1.1min\n",
      "[CV 4/5; 33/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 4/5; 33/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.965, test=0.452) total time= 1.1min\n",
      "[CV 5/5; 33/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 5/5; 33/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.961, test=0.467) total time= 1.2min\n",
      "[CV 1/5; 34/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 1/5; 34/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.885, test=0.487) total time=  23.0s\n",
      "[CV 2/5; 34/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 2/5; 34/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.884, test=0.477) total time=  23.7s\n",
      "[CV 3/5; 34/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 3/5; 34/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.895, test=0.441) total time=  21.7s\n",
      "[CV 4/5; 34/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 4/5; 34/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.894, test=0.465) total time=  21.7s\n",
      "[CV 5/5; 34/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 5/5; 34/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.874, test=0.445) total time=  20.1s\n",
      "[CV 1/5; 35/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 35/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.912, test=0.498) total time=  43.7s\n",
      "[CV 2/5; 35/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 35/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.823, test=0.476) total time=  47.7s\n",
      "[CV 3/5; 35/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 35/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.908, test=0.440) total time=  44.0s\n",
      "[CV 4/5; 35/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 35/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.906, test=0.464) total time=  43.1s\n",
      "[CV 5/5; 35/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 35/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.908, test=0.467) total time=  39.0s\n",
      "[CV 1/5; 36/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 1/5; 36/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.899, test=0.502) total time= 1.1min\n",
      "[CV 2/5; 36/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 2/5; 36/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.905, test=0.452) total time=  57.8s\n",
      "[CV 3/5; 36/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 3/5; 36/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.900, test=0.437) total time=  59.2s\n",
      "[CV 4/5; 36/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 4/5; 36/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.909, test=0.479) total time= 1.1min\n",
      "[CV 5/5; 36/54] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 5/5; 36/54] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.902, test=0.467) total time= 1.0min\n",
      "[CV 1/5; 37/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 1/5; 37/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.952, test=0.479) total time=  23.3s\n",
      "[CV 2/5; 37/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 2/5; 37/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.952, test=0.469) total time=  23.4s\n",
      "[CV 3/5; 37/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 3/5; 37/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.960, test=0.413) total time=  22.9s\n",
      "[CV 4/5; 37/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 4/5; 37/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.947, test=0.457) total time=  25.2s\n",
      "[CV 5/5; 37/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 5/5; 37/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.963, test=0.462) total time=  23.2s\n",
      "[CV 1/5; 38/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 38/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.966, test=0.467) total time=  42.6s\n",
      "[CV 2/5; 38/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 38/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.953, test=0.450) total time=  47.4s\n",
      "[CV 3/5; 38/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 38/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.967, test=0.430) total time=  42.2s\n",
      "[CV 4/5; 38/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 38/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.967, test=0.450) total time=  43.7s\n",
      "[CV 5/5; 38/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 38/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.962, test=0.451) total time=  46.8s\n",
      "[CV 1/5; 39/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 1/5; 39/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.975, test=0.480) total time=  59.1s\n",
      "[CV 2/5; 39/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 2/5; 39/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.963, test=0.463) total time= 1.2min\n",
      "[CV 3/5; 39/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 3/5; 39/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.968, test=0.444) total time= 1.1min\n",
      "[CV 4/5; 39/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 4/5; 39/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.966, test=0.464) total time= 1.0min\n",
      "[CV 5/5; 39/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 5/5; 39/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.974, test=0.445) total time= 1.1min\n",
      "[CV 1/5; 40/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 1/5; 40/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.924, test=0.475) total time=  21.7s\n",
      "[CV 2/5; 40/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 2/5; 40/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.924, test=0.463) total time=  22.5s\n",
      "[CV 3/5; 40/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 3/5; 40/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.927, test=0.439) total time=  21.5s\n",
      "[CV 4/5; 40/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 4/5; 40/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.924, test=0.471) total time=  22.6s\n",
      "[CV 5/5; 40/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 5/5; 40/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.923, test=0.474) total time=  22.4s\n",
      "[CV 1/5; 41/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 41/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.914, test=0.480) total time=  45.8s\n",
      "[CV 2/5; 41/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 41/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.932, test=0.452) total time=  38.3s\n",
      "[CV 3/5; 41/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 41/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.926, test=0.448) total time=  41.8s\n",
      "[CV 4/5; 41/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 41/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.930, test=0.478) total time=  42.5s\n",
      "[CV 5/5; 41/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 41/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.926, test=0.480) total time=  45.9s\n",
      "[CV 1/5; 42/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 1/5; 42/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.936, test=0.489) total time= 1.1min\n",
      "[CV 2/5; 42/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 2/5; 42/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.939, test=0.449) total time= 1.1min\n",
      "[CV 3/5; 42/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 3/5; 42/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.928, test=0.465) total time= 1.1min\n",
      "[CV 4/5; 42/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 4/5; 42/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.930, test=0.458) total time= 1.1min\n",
      "[CV 5/5; 42/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 5/5; 42/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.932, test=0.462) total time= 1.1min\n",
      "[CV 1/5; 43/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 1/5; 43/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.866, test=0.494) total time=  18.9s\n",
      "[CV 2/5; 43/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 2/5; 43/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.784, test=0.465) total time=  23.3s\n",
      "[CV 3/5; 43/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 3/5; 43/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.861, test=0.470) total time=  20.2s\n",
      "[CV 4/5; 43/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 4/5; 43/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.867, test=0.463) total time=  21.3s\n",
      "[CV 5/5; 43/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 5/5; 43/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.854, test=0.477) total time=  22.5s\n",
      "[CV 1/5; 44/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 44/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.868, test=0.487) total time=  43.4s\n",
      "[CV 2/5; 44/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 44/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.793, test=0.467) total time=  46.1s\n",
      "[CV 3/5; 44/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 44/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.874, test=0.437) total time=  36.4s\n",
      "[CV 4/5; 44/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 44/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.870, test=0.459) total time=  41.2s\n",
      "[CV 5/5; 44/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 44/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.868, test=0.460) total time=  38.0s\n",
      "[CV 1/5; 45/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 1/5; 45/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.820, test=0.508) total time= 1.1min\n",
      "[CV 2/5; 45/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 2/5; 45/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.885, test=0.464) total time=  55.5s\n",
      "[CV 3/5; 45/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 3/5; 45/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.883, test=0.448) total time=  56.4s\n",
      "[CV 4/5; 45/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 4/5; 45/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.875, test=0.473) total time=  57.3s\n",
      "[CV 5/5; 45/54] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 5/5; 45/54] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.890, test=0.474) total time= 1.1min\n",
      "[CV 1/5; 46/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 1/5; 46/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.821, test=0.507) total time=  23.2s\n",
      "[CV 2/5; 46/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 2/5; 46/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.887, test=0.460) total time=  20.9s\n",
      "[CV 3/5; 46/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 3/5; 46/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.883, test=0.437) total time=  20.8s\n",
      "[CV 4/5; 46/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 4/5; 46/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.876, test=0.463) total time=  20.5s\n",
      "[CV 5/5; 46/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50\n",
      "[CV 5/5; 46/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=50;, score=(train=0.866, test=0.474) total time=  22.2s\n",
      "[CV 1/5; 47/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 47/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.891, test=0.465) total time=  41.4s\n",
      "[CV 2/5; 47/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 47/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.803, test=0.463) total time=  45.8s\n",
      "[CV 3/5; 47/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 47/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.892, test=0.440) total time=  42.3s\n",
      "[CV 4/5; 47/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 47/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.888, test=0.475) total time=  41.6s\n",
      "[CV 5/5; 47/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 47/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=0.901, test=0.481) total time=  42.6s\n",
      "[CV 1/5; 48/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 1/5; 48/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.872, test=0.495) total time= 1.1min\n",
      "[CV 2/5; 48/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 2/5; 48/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.903, test=0.440) total time= 1.0min\n",
      "[CV 3/5; 48/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 3/5; 48/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.882, test=0.453) total time= 1.1min\n",
      "[CV 4/5; 48/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 4/5; 48/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.897, test=0.468) total time= 1.1min\n",
      "[CV 5/5; 48/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150\n",
      "[CV 5/5; 48/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=150;, score=(train=0.897, test=0.479) total time= 1.1min\n",
      "[CV 1/5; 49/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 1/5; 49/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.864, test=0.493) total time=  22.4s\n",
      "[CV 2/5; 49/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 2/5; 49/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.883, test=0.460) total time=  18.9s\n",
      "[CV 3/5; 49/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 3/5; 49/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.881, test=0.459) total time=  19.0s\n",
      "[CV 4/5; 49/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 4/5; 49/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.876, test=0.459) total time=  20.8s\n",
      "[CV 5/5; 49/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50\n",
      "[CV 5/5; 49/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=50;, score=(train=0.883, test=0.471) total time=  21.4s\n",
      "[CV 1/5; 50/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 50/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.872, test=0.507) total time=  43.8s\n",
      "[CV 2/5; 50/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 50/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.806, test=0.457) total time=  45.7s\n",
      "[CV 3/5; 50/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 50/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.886, test=0.431) total time=  40.9s\n",
      "[CV 4/5; 50/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 50/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.887, test=0.460) total time=  37.8s\n",
      "[CV 5/5; 50/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 50/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=0.891, test=0.473) total time=  41.1s\n",
      "[CV 1/5; 51/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 1/5; 51/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.830, test=0.515) total time= 1.1min\n",
      "[CV 2/5; 51/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 2/5; 51/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.902, test=0.462) total time= 1.0min\n",
      "[CV 3/5; 51/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 3/5; 51/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.891, test=0.442) total time= 1.0min\n",
      "[CV 4/5; 51/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 4/5; 51/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.893, test=0.469) total time=  57.1s\n",
      "[CV 5/5; 51/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150\n",
      "[CV 5/5; 51/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=150;, score=(train=0.895, test=0.462) total time=  59.2s\n",
      "[CV 1/5; 52/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 1/5; 52/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.840, test=0.473) total time=  20.7s\n",
      "[CV 2/5; 52/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 2/5; 52/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.768, test=0.465) total time=  22.6s\n",
      "[CV 3/5; 52/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 3/5; 52/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.838, test=0.443) total time=  20.0s\n",
      "[CV 4/5; 52/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 4/5; 52/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.832, test=0.480) total time=  20.3s\n",
      "[CV 5/5; 52/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50\n",
      "[CV 5/5; 52/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=50;, score=(train=0.846, test=0.481) total time=  20.1s\n",
      "[CV 1/5; 53/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 1/5; 53/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.842, test=0.486) total time=  38.2s\n",
      "[CV 2/5; 53/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 2/5; 53/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.845, test=0.456) total time=  37.5s\n",
      "[CV 3/5; 53/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 3/5; 53/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.853, test=0.442) total time=  40.1s\n",
      "[CV 4/5; 53/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 4/5; 53/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.843, test=0.484) total time=  38.0s\n",
      "[CV 5/5; 53/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100\n",
      "[CV 5/5; 53/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=100;, score=(train=0.851, test=0.470) total time=  40.2s\n",
      "[CV 1/5; 54/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 1/5; 54/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.855, test=0.504) total time= 1.0min\n",
      "[CV 2/5; 54/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 2/5; 54/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.857, test=0.446) total time=  54.0s\n",
      "[CV 3/5; 54/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 3/5; 54/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.858, test=0.448) total time=  57.5s\n",
      "[CV 4/5; 54/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 4/5; 54/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.833, test=0.468) total time=  58.6s\n",
      "[CV 5/5; 54/54] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150\n",
      "[CV 5/5; 54/54] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=15, estimator__n_estimators=150;, score=(train=0.847, test=0.471) total time=  59.0s\n",
      "Number of features selected in RF multiclass: 14\n",
      "Selected features RF multiclass: ['mean_slope', 'mean_elevation_m', 'ruggedness_stdev', 'mean_ruggedness', 'slope_stdev', 'area_km2', 'poverty_perc', 'perimeter', 'glat', 'glon', 'rainfall_max_6h', 'rainfall_max_24h', 'dis_track_min', 'vmax']\n",
      "Selected Parameters in RF multiclass: {'estimator__max_depth': None, 'estimator__min_samples_leaf': 3, 'estimator__min_samples_split': 15, 'estimator__n_estimators': 50}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtaining the performance estimate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the selected features for RF --> based on output previous cell\r\n",
    "selected_features_rf_multi = [\r\n",
    "    \"rice_area\",\r\n",
    "    \"mean_slope\",\r\n",
    "    \"mean_elevation_m\",\r\n",
    "    \"ruggedness_stdev\",\r\n",
    "    \"mean_ruggedness\",\r\n",
    "    \"slope_stdev\",\r\n",
    "    \"area_km2\",\r\n",
    "    \"poverty_perc\",\r\n",
    "    \"with_coast\",\r\n",
    "    \"coast_length\",\r\n",
    "    \"perimeter\",\r\n",
    "    \"glat\",\r\n",
    "    \"glon\",\r\n",
    "    \"coast_peri_ratio\",\r\n",
    "    \"rainfall_sum\",\r\n",
    "    \"rainfall_max\",\r\n",
    "    \"dis_track_min\",\r\n",
    "    \"vmax_sust\",\r\n",
    "]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Obtain the performance estimate\r\n",
    "rf_search_space = [\r\n",
    "    {\r\n",
    "        \"rf__n_estimators\": [50, 100, 150],\r\n",
    "        \"rf__max_depth\": [20, None],\r\n",
    "        \"rf__min_samples_split\": [2, 10, 15],\r\n",
    "        \"rf__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "df_predicted_rf_multi, selected_params_rf_multi = rf_multi_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    features=selected_features_rf_multi,\r\n",
    "    search_space=rf_search_space,\r\n",
    "    stratK=True,\r\n",
    "    cv_splits=5,\r\n",
    "    class_weight=\"balanced\",\r\n",
    "    GS_score=\"f1_macro\",\r\n",
    "    GS_randomized=False,\r\n",
    "    GS_n_iter=10,\r\n",
    "    verbose=10,\r\n",
    ")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running for 1 out of a total of 5\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.416) total time=   0.1s\n",
      "[CV 2/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.404) total time=   0.1s\n",
      "[CV 3/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.408) total time=   0.1s\n",
      "[CV 4/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.458) total time=   0.1s\n",
      "[CV 5/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.411) total time=   0.1s\n",
      "[CV 1/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.405) total time=   0.3s\n",
      "[CV 2/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.432) total time=   0.3s\n",
      "[CV 3/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.419) total time=   0.3s\n",
      "[CV 4/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.457) total time=   0.3s\n",
      "[CV 5/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.421) total time=   0.3s\n",
      "[CV 1/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.407) total time=   0.5s\n",
      "[CV 2/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.437) total time=   0.5s\n",
      "[CV 3/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.436) total time=   0.6s\n",
      "[CV 4/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.494) total time=   0.5s\n",
      "[CV 5/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.447) total time=   0.5s\n",
      "[CV 1/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.948, test=0.429) total time=   0.1s\n",
      "[CV 2/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.958, test=0.474) total time=   0.1s\n",
      "[CV 3/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.954, test=0.439) total time=   0.1s\n",
      "[CV 4/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.950, test=0.505) total time=   0.1s\n",
      "[CV 5/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.955, test=0.444) total time=   0.1s\n",
      "[CV 1/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.963, test=0.438) total time=   0.3s\n",
      "[CV 2/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.963, test=0.448) total time=   0.2s\n",
      "[CV 3/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.961, test=0.442) total time=   0.3s\n",
      "[CV 4/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.962, test=0.470) total time=   0.3s\n",
      "[CV 5/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.960, test=0.484) total time=   0.2s\n",
      "[CV 1/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.961, test=0.425) total time=   0.4s\n",
      "[CV 2/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.961, test=0.460) total time=   0.4s\n",
      "[CV 3/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.966, test=0.423) total time=   0.5s\n",
      "[CV 4/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.960, test=0.506) total time=   0.6s\n",
      "[CV 5/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.972, test=0.461) total time=   0.5s\n",
      "[CV 1/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.895, test=0.455) total time=   0.1s\n",
      "[CV 2/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.907, test=0.453) total time=   0.1s\n",
      "[CV 3/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.917, test=0.448) total time=   0.1s\n",
      "[CV 4/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.906, test=0.497) total time=   0.1s\n",
      "[CV 5/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.909, test=0.451) total time=   0.1s\n",
      "[CV 1/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.892, test=0.444) total time=   0.3s\n",
      "[CV 2/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.907, test=0.458) total time=   0.3s\n",
      "[CV 3/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.912, test=0.469) total time=   0.3s\n",
      "[CV 4/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.910, test=0.515) total time=   0.3s\n",
      "[CV 5/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.917, test=0.458) total time=   0.3s\n",
      "[CV 1/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.911, test=0.425) total time=   0.5s\n",
      "[CV 2/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.910, test=0.427) total time=   0.5s\n",
      "[CV 3/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.923, test=0.452) total time=   0.5s\n",
      "[CV 4/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.919, test=0.485) total time=   0.5s\n",
      "[CV 5/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.923, test=0.470) total time=   0.5s\n",
      "[CV 1/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.963, test=0.430) total time=   0.1s\n",
      "[CV 2/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.958, test=0.458) total time=   0.1s\n",
      "[CV 3/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.967, test=0.438) total time=   0.1s\n",
      "[CV 4/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.965, test=0.465) total time=   0.1s\n",
      "[CV 5/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.961, test=0.456) total time=   0.1s\n",
      "[CV 1/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.967, test=0.449) total time=   0.3s\n",
      "[CV 2/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.965, test=0.461) total time=   0.3s\n",
      "[CV 3/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.974, test=0.450) total time=   0.3s\n",
      "[CV 4/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.971, test=0.482) total time=   0.3s\n",
      "[CV 5/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.970, test=0.468) total time=   0.3s\n",
      "[CV 1/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.965, test=0.441) total time=   0.5s\n",
      "[CV 2/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.975, test=0.443) total time=   0.5s\n",
      "[CV 3/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.970, test=0.408) total time=   0.5s\n",
      "[CV 4/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.971, test=0.478) total time=   0.5s\n",
      "[CV 5/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.973, test=0.473) total time=   0.5s\n",
      "[CV 1/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.927, test=0.434) total time=   0.1s\n",
      "[CV 2/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.920, test=0.457) total time=   0.1s\n",
      "[CV 3/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.931, test=0.439) total time=   0.1s\n",
      "[CV 4/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.924, test=0.480) total time=   0.1s\n",
      "[CV 5/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.933, test=0.470) total time=   0.1s\n",
      "[CV 1/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.929, test=0.421) total time=   0.3s\n",
      "[CV 2/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.939, test=0.448) total time=   0.3s\n",
      "[CV 3/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.934, test=0.458) total time=   0.3s\n",
      "[CV 4/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.937, test=0.491) total time=   0.3s\n",
      "[CV 5/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.936, test=0.499) total time=   0.3s\n",
      "[CV 1/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.936, test=0.447) total time=   0.5s\n",
      "[CV 2/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.936, test=0.447) total time=   0.5s\n",
      "[CV 3/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.951, test=0.433) total time=   0.5s\n",
      "[CV 4/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.938, test=0.497) total time=   0.5s\n",
      "[CV 5/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.944, test=0.491) total time=   0.5s\n",
      "[CV 1/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.868, test=0.457) total time=   0.1s\n",
      "[CV 2/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.874, test=0.449) total time=   0.1s\n",
      "[CV 3/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.876, test=0.461) total time=   0.1s\n",
      "[CV 4/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.873, test=0.476) total time=   0.1s\n",
      "[CV 5/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.884, test=0.489) total time=   0.1s\n",
      "[CV 1/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.872, test=0.441) total time=   0.3s\n",
      "[CV 2/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.879, test=0.478) total time=   0.3s\n",
      "[CV 3/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.883, test=0.459) total time=   0.3s\n",
      "[CV 4/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.900, test=0.482) total time=   0.3s\n",
      "[CV 5/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.895, test=0.496) total time=   0.3s\n",
      "[CV 1/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.883, test=0.441) total time=   0.5s\n",
      "[CV 2/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.886, test=0.448) total time=   0.5s\n",
      "[CV 3/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.893, test=0.439) total time=   0.5s\n",
      "[CV 4/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.889, test=0.480) total time=   0.5s\n",
      "[CV 5/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.891, test=0.478) total time=   0.5s\n",
      "[CV 1/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.885, test=0.452) total time=   0.1s\n",
      "[CV 2/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.883, test=0.464) total time=   0.1s\n",
      "[CV 3/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.888, test=0.468) total time=   0.1s\n",
      "[CV 4/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.896, test=0.471) total time=   0.1s\n",
      "[CV 5/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.892, test=0.472) total time=   0.1s\n",
      "[CV 1/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.889, test=0.438) total time=   0.3s\n",
      "[CV 2/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.905, test=0.456) total time=   0.3s\n",
      "[CV 3/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.903, test=0.452) total time=   0.3s\n",
      "[CV 4/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.900, test=0.490) total time=   0.3s\n",
      "[CV 5/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.900, test=0.491) total time=   0.3s\n",
      "[CV 1/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.892, test=0.430) total time=   0.5s\n",
      "[CV 2/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.901, test=0.466) total time=   0.5s\n",
      "[CV 3/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.905, test=0.447) total time=   0.5s\n",
      "[CV 4/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.896, test=0.480) total time=   0.5s\n",
      "[CV 5/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.906, test=0.507) total time=   0.5s\n",
      "[CV 1/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.880, test=0.440) total time=   0.1s\n",
      "[CV 2/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.883, test=0.440) total time=   0.1s\n",
      "[CV 3/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.884, test=0.476) total time=   0.1s\n",
      "[CV 4/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.884, test=0.490) total time=   0.1s\n",
      "[CV 5/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.894, test=0.469) total time=   0.1s\n",
      "[CV 1/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.893, test=0.450) total time=   0.3s\n",
      "[CV 2/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.903, test=0.448) total time=   0.3s\n",
      "[CV 3/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.905, test=0.444) total time=   0.3s\n",
      "[CV 4/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.895, test=0.496) total time=   0.3s\n",
      "[CV 5/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.908, test=0.479) total time=   0.3s\n",
      "[CV 1/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.883, test=0.436) total time=   0.5s\n",
      "[CV 2/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.901, test=0.456) total time=   0.5s\n",
      "[CV 3/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.906, test=0.424) total time=   0.5s\n",
      "[CV 4/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.903, test=0.487) total time=   0.5s\n",
      "[CV 5/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.903, test=0.488) total time=   0.5s\n",
      "[CV 1/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.857, test=0.428) total time=   0.1s\n",
      "[CV 2/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.842, test=0.448) total time=   0.1s\n",
      "[CV 3/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.857, test=0.448) total time=   0.1s\n",
      "[CV 4/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.846, test=0.485) total time=   0.1s\n",
      "[CV 5/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.854, test=0.491) total time=   0.1s\n",
      "[CV 1/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.846, test=0.452) total time=   0.3s\n",
      "[CV 2/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.858, test=0.454) total time=   0.3s\n",
      "[CV 3/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.859, test=0.454) total time=   0.3s\n",
      "[CV 4/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.858, test=0.470) total time=   0.3s\n",
      "[CV 5/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.866, test=0.492) total time=   0.3s\n",
      "[CV 1/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.855, test=0.450) total time=   0.6s\n",
      "[CV 2/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.870, test=0.468) total time=   0.5s\n",
      "[CV 3/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.866, test=0.462) total time=   0.5s\n",
      "[CV 4/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.869, test=0.499) total time=   0.5s\n",
      "[CV 5/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.875, test=0.456) total time=   0.5s\n",
      "[CV 1/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.392) total time=   0.1s\n",
      "[CV 2/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.434) total time=   0.1s\n",
      "[CV 3/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.425) total time=   0.1s\n",
      "[CV 4/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.448) total time=   0.1s\n",
      "[CV 5/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.414) total time=   0.1s\n",
      "[CV 1/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.417) total time=   0.4s\n",
      "[CV 2/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.431) total time=   0.4s\n",
      "[CV 3/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.421) total time=   0.4s\n",
      "[CV 4/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.463) total time=   0.4s\n",
      "[CV 5/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.438) total time=   0.4s\n",
      "[CV 1/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.400) total time=   0.6s\n",
      "[CV 2/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.434) total time=   0.6s\n",
      "[CV 3/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.397) total time=   0.6s\n",
      "[CV 4/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.472) total time=   0.6s\n",
      "[CV 5/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.451) total time=   0.6s\n",
      "[CV 1/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.950, test=0.436) total time=   0.1s\n",
      "[CV 2/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.953, test=0.442) total time=   0.1s\n",
      "[CV 3/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.962, test=0.443) total time=   0.1s\n",
      "[CV 4/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.955, test=0.475) total time=   0.1s\n",
      "[CV 5/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.958, test=0.477) total time=   0.1s\n",
      "[CV 1/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.958, test=0.458) total time=   0.3s\n",
      "[CV 2/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.958, test=0.480) total time=   0.3s\n",
      "[CV 3/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.967, test=0.438) total time=   0.3s\n",
      "[CV 4/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.968, test=0.494) total time=   0.3s\n",
      "[CV 5/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.968, test=0.451) total time=   0.3s\n",
      "[CV 1/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.963, test=0.466) total time=   0.6s\n",
      "[CV 2/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.960, test=0.450) total time=   0.5s\n",
      "[CV 3/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.968, test=0.433) total time=   0.5s\n",
      "[CV 4/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.970, test=0.480) total time=   0.5s\n",
      "[CV 5/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.963, test=0.472) total time=   0.5s\n",
      "[CV 1/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.893, test=0.433) total time=   0.1s\n",
      "[CV 2/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.895, test=0.446) total time=   0.1s\n",
      "[CV 3/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.895, test=0.450) total time=   0.1s\n",
      "[CV 4/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.903, test=0.476) total time=   0.1s\n",
      "[CV 5/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.916, test=0.483) total time=   0.1s\n",
      "[CV 1/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.906, test=0.421) total time=   0.3s\n",
      "[CV 2/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.906, test=0.438) total time=   0.3s\n",
      "[CV 3/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.914, test=0.452) total time=   0.3s\n",
      "[CV 4/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.907, test=0.482) total time=   0.3s\n",
      "[CV 5/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.918, test=0.481) total time=   0.3s\n",
      "[CV 1/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.907, test=0.450) total time=   0.5s\n",
      "[CV 2/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.917, test=0.428) total time=   0.5s\n",
      "[CV 3/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.914, test=0.451) total time=   0.5s\n",
      "[CV 4/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.916, test=0.521) total time=   0.5s\n",
      "[CV 5/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.923, test=0.486) total time=   0.5s\n",
      "[CV 1/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.955, test=0.462) total time=   0.1s\n",
      "[CV 2/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.963, test=0.455) total time=   0.1s\n",
      "[CV 3/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.962, test=0.474) total time=   0.1s\n",
      "[CV 4/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.952, test=0.511) total time=   0.1s\n",
      "[CV 5/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.966, test=0.461) total time=   0.1s\n",
      "[CV 1/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.964, test=0.435) total time=   0.3s\n",
      "[CV 2/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.965, test=0.442) total time=   0.3s\n",
      "[CV 3/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.968, test=0.433) total time=   0.3s\n",
      "[CV 4/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.972, test=0.488) total time=   0.3s\n",
      "[CV 5/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.971, test=0.455) total time=   0.3s\n",
      "[CV 1/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.971, test=0.447) total time=   0.5s\n",
      "[CV 2/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.971, test=0.448) total time=   0.5s\n",
      "[CV 3/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.975, test=0.430) total time=   0.5s\n",
      "[CV 4/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.972, test=0.488) total time=   0.5s\n",
      "[CV 5/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.974, test=0.462) total time=   0.5s\n",
      "[CV 1/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.921, test=0.410) total time=   0.1s\n",
      "[CV 2/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.923, test=0.453) total time=   0.1s\n",
      "[CV 3/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.919, test=0.436) total time=   0.1s\n",
      "[CV 4/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.919, test=0.475) total time=   0.1s\n",
      "[CV 5/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.930, test=0.481) total time=   0.1s\n",
      "[CV 1/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.924, test=0.484) total time=   0.3s\n",
      "[CV 2/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.927, test=0.455) total time=   0.3s\n",
      "[CV 3/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.937, test=0.472) total time=   0.4s\n",
      "[CV 4/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.934, test=0.457) total time=   0.3s\n",
      "[CV 5/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.935, test=0.487) total time=   0.3s\n",
      "[CV 1/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.935, test=0.442) total time=   0.5s\n",
      "[CV 2/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.926, test=0.451) total time=   0.5s\n",
      "[CV 3/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.935, test=0.460) total time=   0.5s\n",
      "[CV 4/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.937, test=0.489) total time=   0.5s\n",
      "[CV 5/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.943, test=0.503) total time=   0.5s\n",
      "[CV 1/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.870, test=0.446) total time=   0.1s\n",
      "[CV 2/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.875, test=0.459) total time=   0.1s\n",
      "[CV 3/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.877, test=0.453) total time=   0.1s\n",
      "[CV 4/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.868, test=0.479) total time=   0.1s\n",
      "[CV 5/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.874, test=0.467) total time=   0.1s\n",
      "[CV 1/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.875, test=0.439) total time=   0.3s\n",
      "[CV 2/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.880, test=0.465) total time=   0.3s\n",
      "[CV 3/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.883, test=0.458) total time=   0.3s\n",
      "[CV 4/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.895, test=0.491) total time=   0.3s\n",
      "[CV 5/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.895, test=0.487) total time=   0.3s\n",
      "[CV 1/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.875, test=0.443) total time=   0.5s\n",
      "[CV 2/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.885, test=0.452) total time=   0.5s\n",
      "[CV 3/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.893, test=0.457) total time=   0.5s\n",
      "[CV 4/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.891, test=0.506) total time=   0.5s\n",
      "[CV 5/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.900, test=0.491) total time=   0.5s\n",
      "[CV 1/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.875, test=0.439) total time=   0.1s\n",
      "[CV 2/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.885, test=0.418) total time=   0.1s\n",
      "[CV 3/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.894, test=0.471) total time=   0.1s\n",
      "[CV 4/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.891, test=0.492) total time=   0.1s\n",
      "[CV 5/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.888, test=0.477) total time=   0.1s\n",
      "[CV 1/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.892, test=0.422) total time=   0.3s\n",
      "[CV 2/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.887, test=0.446) total time=   0.3s\n",
      "[CV 3/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.892, test=0.446) total time=   0.3s\n",
      "[CV 4/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.896, test=0.502) total time=   0.3s\n",
      "[CV 5/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.911, test=0.481) total time=   0.3s\n",
      "[CV 1/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.892, test=0.455) total time=   0.5s\n",
      "[CV 2/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.900, test=0.455) total time=   0.5s\n",
      "[CV 3/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.905, test=0.443) total time=   0.5s\n",
      "[CV 4/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.900, test=0.490) total time=   0.5s\n",
      "[CV 5/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.906, test=0.468) total time=   0.5s\n",
      "[CV 1/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.865, test=0.432) total time=   0.1s\n",
      "[CV 2/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.878, test=0.447) total time=   0.1s\n",
      "[CV 3/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.897, test=0.470) total time=   0.1s\n",
      "[CV 4/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.876, test=0.477) total time=   0.1s\n",
      "[CV 5/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.898, test=0.475) total time=   0.1s\n",
      "[CV 1/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.894, test=0.441) total time=   0.3s\n",
      "[CV 2/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.886, test=0.465) total time=   0.3s\n",
      "[CV 3/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.904, test=0.451) total time=   0.3s\n",
      "[CV 4/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.891, test=0.499) total time=   0.3s\n",
      "[CV 5/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.904, test=0.471) total time=   0.3s\n",
      "[CV 1/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.895, test=0.432) total time=   0.5s\n",
      "[CV 2/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.895, test=0.452) total time=   0.5s\n",
      "[CV 3/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.912, test=0.444) total time=   0.6s\n",
      "[CV 4/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.910, test=0.479) total time=   0.5s\n",
      "[CV 5/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.910, test=0.494) total time=   0.5s\n",
      "[CV 1/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.844, test=0.439) total time=   0.1s\n",
      "[CV 2/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.850, test=0.470) total time=   0.1s\n",
      "[CV 3/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.846, test=0.459) total time=   0.1s\n",
      "[CV 4/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.838, test=0.460) total time=   0.1s\n",
      "[CV 5/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.851, test=0.471) total time=   0.1s\n",
      "[CV 1/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.852, test=0.417) total time=   0.3s\n",
      "[CV 2/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.860, test=0.463) total time=   0.3s\n",
      "[CV 3/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.858, test=0.428) total time=   0.3s\n",
      "[CV 4/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.871, test=0.500) total time=   0.3s\n",
      "[CV 5/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.869, test=0.505) total time=   0.3s\n",
      "[CV 1/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.857, test=0.444) total time=   0.5s\n",
      "[CV 2/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.860, test=0.446) total time=   0.5s\n",
      "[CV 3/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.865, test=0.449) total time=   0.5s\n",
      "[CV 4/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.861, test=0.499) total time=   0.5s\n",
      "[CV 5/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.868, test=0.498) total time=   0.5s\n",
      "Selected Parameters: {'rf__max_depth': None, 'rf__min_samples_leaf': 3, 'rf__min_samples_split': 2, 'rf__n_estimators': 50}\n",
      "Train score: 0.9577626444493821\n",
      "Test score: 0.42914756694661005\n",
      "Running for 2 out of a total of 5\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.422) total time=   0.2s\n",
      "[CV 2/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.472) total time=   0.2s\n",
      "[CV 3/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.444) total time=   0.2s\n",
      "[CV 4/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.406) total time=   0.2s\n",
      "[CV 5/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.411) total time=   0.2s\n",
      "[CV 1/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.432) total time=   0.5s\n",
      "[CV 2/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.464) total time=   0.5s\n",
      "[CV 3/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.430) total time=   0.5s\n",
      "[CV 4/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.390) total time=   0.5s\n",
      "[CV 5/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.412) total time=   0.5s\n",
      "[CV 1/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.428) total time=   0.7s\n",
      "[CV 2/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.467) total time=   0.7s\n",
      "[CV 3/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.467) total time=   0.7s\n",
      "[CV 4/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.401) total time=   0.7s\n",
      "[CV 5/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.414) total time=   0.8s\n",
      "[CV 1/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.954, test=0.442) total time=   0.2s\n",
      "[CV 2/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.946, test=0.473) total time=   0.2s\n",
      "[CV 3/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.947, test=0.457) total time=   0.2s\n",
      "[CV 4/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.956, test=0.428) total time=   0.2s\n",
      "[CV 5/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.948, test=0.412) total time=   0.2s\n",
      "[CV 1/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.960, test=0.454) total time=   0.4s\n",
      "[CV 2/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.960, test=0.513) total time=   0.4s\n",
      "[CV 3/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.957, test=0.492) total time=   0.4s\n",
      "[CV 4/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.959, test=0.432) total time=   0.4s\n",
      "[CV 5/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.951, test=0.425) total time=   0.4s\n",
      "[CV 1/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.959, test=0.463) total time=   0.7s\n",
      "[CV 2/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.965, test=0.484) total time=   0.7s\n",
      "[CV 3/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.955, test=0.478) total time=   0.7s\n",
      "[CV 4/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.962, test=0.434) total time=   0.7s\n",
      "[CV 5/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.950, test=0.417) total time=   0.7s\n",
      "[CV 1/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.890, test=0.452) total time=   0.1s\n",
      "[CV 2/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.905, test=0.485) total time=   0.2s\n",
      "[CV 3/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.902, test=0.479) total time=   0.2s\n",
      "[CV 4/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.897, test=0.427) total time=   0.2s\n",
      "[CV 5/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.890, test=0.420) total time=   0.2s\n",
      "[CV 1/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.896, test=0.467) total time=   0.4s\n",
      "[CV 2/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.906, test=0.504) total time=   0.4s\n",
      "[CV 3/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.913, test=0.471) total time=   0.4s\n",
      "[CV 4/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.908, test=0.432) total time=   0.4s\n",
      "[CV 5/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.900, test=0.434) total time=   0.4s\n",
      "[CV 1/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.910, test=0.453) total time=   0.6s\n",
      "[CV 2/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.908, test=0.479) total time=   0.6s\n",
      "[CV 3/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.908, test=0.495) total time=   0.7s\n",
      "[CV 4/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.918, test=0.433) total time=   0.6s\n",
      "[CV 5/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.905, test=0.418) total time=   0.7s\n",
      "[CV 1/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.953, test=0.437) total time=   0.2s\n",
      "[CV 2/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.957, test=0.482) total time=   0.2s\n",
      "[CV 3/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.951, test=0.482) total time=   0.2s\n",
      "[CV 4/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.959, test=0.411) total time=   0.2s\n",
      "[CV 5/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.950, test=0.431) total time=   0.2s\n",
      "[CV 1/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.967, test=0.465) total time=   0.4s\n",
      "[CV 2/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.964, test=0.490) total time=   0.4s\n",
      "[CV 3/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.960, test=0.479) total time=   0.4s\n",
      "[CV 4/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.964, test=0.415) total time=   0.4s\n",
      "[CV 5/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.957, test=0.429) total time=   0.4s\n",
      "[CV 1/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.965, test=0.447) total time=   0.7s\n",
      "[CV 2/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.970, test=0.496) total time=   0.7s\n",
      "[CV 3/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.969, test=0.482) total time=   0.7s\n",
      "[CV 4/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.964, test=0.420) total time=   0.7s\n",
      "[CV 5/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.960, test=0.429) total time=   0.7s\n",
      "[CV 1/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.903, test=0.462) total time=   0.2s\n",
      "[CV 2/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.909, test=0.497) total time=   0.2s\n",
      "[CV 3/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.914, test=0.482) total time=   0.2s\n",
      "[CV 4/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.916, test=0.433) total time=   0.2s\n",
      "[CV 5/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.913, test=0.423) total time=   0.2s\n",
      "[CV 1/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.927, test=0.461) total time=   0.4s\n",
      "[CV 2/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.926, test=0.486) total time=   0.4s\n",
      "[CV 3/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.923, test=0.444) total time=   0.4s\n",
      "[CV 4/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.926, test=0.424) total time=   0.4s\n",
      "[CV 5/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.926, test=0.419) total time=   0.4s\n",
      "[CV 1/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.925, test=0.465) total time=   0.6s\n",
      "[CV 2/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.929, test=0.489) total time=   0.6s\n",
      "[CV 3/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.926, test=0.495) total time=   0.6s\n",
      "[CV 4/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.935, test=0.412) total time=   0.6s\n",
      "[CV 5/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.926, test=0.421) total time=   0.6s\n",
      "[CV 1/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.874, test=0.461) total time=   0.2s\n",
      "[CV 2/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.879, test=0.505) total time=   0.1s\n",
      "[CV 3/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.861, test=0.483) total time=   0.2s\n",
      "[CV 4/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.865, test=0.436) total time=   0.2s\n",
      "[CV 5/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.857, test=0.411) total time=   0.2s\n",
      "[CV 1/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.872, test=0.461) total time=   0.4s\n",
      "[CV 2/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.887, test=0.473) total time=   0.4s\n",
      "[CV 3/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.879, test=0.487) total time=   0.4s\n",
      "[CV 4/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.890, test=0.439) total time=   0.4s\n",
      "[CV 5/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.876, test=0.410) total time=   0.4s\n",
      "[CV 1/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.877, test=0.448) total time=   0.6s\n",
      "[CV 2/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.880, test=0.477) total time=   0.6s\n",
      "[CV 3/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.882, test=0.510) total time=   0.6s\n",
      "[CV 4/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.881, test=0.434) total time=   0.6s\n",
      "[CV 5/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.869, test=0.417) total time=   0.6s\n",
      "[CV 1/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.883, test=0.431) total time=   0.1s\n",
      "[CV 2/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.880, test=0.476) total time=   0.2s\n",
      "[CV 3/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.886, test=0.478) total time=   0.2s\n",
      "[CV 4/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.889, test=0.436) total time=   0.1s\n",
      "[CV 5/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.880, test=0.418) total time=   0.1s\n",
      "[CV 1/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.883, test=0.485) total time=   0.4s\n",
      "[CV 2/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.891, test=0.485) total time=   0.4s\n",
      "[CV 3/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.885, test=0.502) total time=   0.4s\n",
      "[CV 4/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.893, test=0.426) total time=   0.4s\n",
      "[CV 5/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.883, test=0.428) total time=   0.4s\n",
      "[CV 1/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.890, test=0.457) total time=   0.6s\n",
      "[CV 2/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.895, test=0.500) total time=   0.6s\n",
      "[CV 3/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.895, test=0.504) total time=   0.6s\n",
      "[CV 4/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.893, test=0.431) total time=   0.6s\n",
      "[CV 5/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.885, test=0.418) total time=   0.6s\n",
      "[CV 1/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.887, test=0.447) total time=   0.1s\n",
      "[CV 2/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.878, test=0.501) total time=   0.1s\n",
      "[CV 3/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.885, test=0.502) total time=   0.2s\n",
      "[CV 4/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.880, test=0.437) total time=   0.2s\n",
      "[CV 5/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.870, test=0.418) total time=   0.2s\n",
      "[CV 1/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.888, test=0.471) total time=   0.4s\n",
      "[CV 2/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.885, test=0.494) total time=   0.4s\n",
      "[CV 3/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.891, test=0.491) total time=   0.4s\n",
      "[CV 4/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.890, test=0.439) total time=   0.4s\n",
      "[CV 5/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.879, test=0.418) total time=   0.4s\n",
      "[CV 1/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.885, test=0.463) total time=   0.6s\n",
      "[CV 2/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.901, test=0.509) total time=   0.6s\n",
      "[CV 3/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.886, test=0.501) total time=   0.6s\n",
      "[CV 4/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.899, test=0.434) total time=   0.6s\n",
      "[CV 5/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.885, test=0.413) total time=   0.6s\n",
      "[CV 1/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.841, test=0.465) total time=   0.1s\n",
      "[CV 2/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.839, test=0.499) total time=   0.1s\n",
      "[CV 3/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.830, test=0.505) total time=   0.1s\n",
      "[CV 4/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.843, test=0.432) total time=   0.1s\n",
      "[CV 5/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.835, test=0.434) total time=   0.1s\n",
      "[CV 1/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.847, test=0.472) total time=   0.4s\n",
      "[CV 2/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.852, test=0.486) total time=   0.4s\n",
      "[CV 3/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.841, test=0.471) total time=   0.4s\n",
      "[CV 4/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.858, test=0.450) total time=   0.4s\n",
      "[CV 5/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.859, test=0.411) total time=   0.4s\n",
      "[CV 1/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.844, test=0.478) total time=   0.6s\n",
      "[CV 2/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.858, test=0.496) total time=   0.6s\n",
      "[CV 3/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.862, test=0.505) total time=   0.6s\n",
      "[CV 4/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.862, test=0.430) total time=   0.6s\n",
      "[CV 5/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.846, test=0.418) total time=   0.6s\n",
      "[CV 1/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.440) total time=   0.2s\n",
      "[CV 2/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.455) total time=   0.2s\n",
      "[CV 3/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.483) total time=   0.2s\n",
      "[CV 4/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.394) total time=   0.2s\n",
      "[CV 5/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.406) total time=   0.2s\n",
      "[CV 1/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.444) total time=   0.5s\n",
      "[CV 2/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.470) total time=   0.5s\n",
      "[CV 3/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.440) total time=   0.5s\n",
      "[CV 4/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.406) total time=   0.5s\n",
      "[CV 5/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.402) total time=   0.5s\n",
      "[CV 1/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.432) total time=   0.7s\n",
      "[CV 2/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.443) total time=   0.8s\n",
      "[CV 3/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.460) total time=   0.7s\n",
      "[CV 4/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.396) total time=   0.9s\n",
      "[CV 5/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.410) total time=   0.8s\n",
      "[CV 1/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.948, test=0.465) total time=   0.2s\n",
      "[CV 2/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.948, test=0.475) total time=   0.2s\n",
      "[CV 3/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.942, test=0.486) total time=   0.2s\n",
      "[CV 4/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.952, test=0.423) total time=   0.2s\n",
      "[CV 5/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.947, test=0.441) total time=   0.2s\n",
      "[CV 1/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.957, test=0.478) total time=   0.4s\n",
      "[CV 2/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.954, test=0.473) total time=   0.4s\n",
      "[CV 3/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.960, test=0.480) total time=   0.4s\n",
      "[CV 4/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.966, test=0.426) total time=   0.4s\n",
      "[CV 5/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.951, test=0.414) total time=   0.4s\n",
      "[CV 1/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.963, test=0.457) total time=   0.7s\n",
      "[CV 2/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.956, test=0.478) total time=   0.7s\n",
      "[CV 3/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.961, test=0.469) total time=   0.7s\n",
      "[CV 4/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.968, test=0.437) total time=   0.7s\n",
      "[CV 5/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.955, test=0.426) total time=   0.7s\n",
      "[CV 1/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.892, test=0.456) total time=   0.2s\n",
      "[CV 2/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.890, test=0.485) total time=   0.2s\n",
      "[CV 3/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.897, test=0.501) total time=   0.2s\n",
      "[CV 4/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.899, test=0.435) total time=   0.2s\n",
      "[CV 5/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.894, test=0.418) total time=   0.2s\n",
      "[CV 1/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.905, test=0.439) total time=   0.4s\n",
      "[CV 2/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.910, test=0.499) total time=   0.4s\n",
      "[CV 3/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.907, test=0.471) total time=   0.4s\n",
      "[CV 4/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.914, test=0.421) total time=   0.5s\n",
      "[CV 5/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.897, test=0.417) total time=   0.4s\n",
      "[CV 1/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.913, test=0.483) total time=   0.6s\n",
      "[CV 2/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.905, test=0.490) total time=   0.7s\n",
      "[CV 3/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.906, test=0.515) total time=   0.6s\n",
      "[CV 4/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.915, test=0.415) total time=   0.6s\n",
      "[CV 5/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.900, test=0.425) total time=   0.7s\n",
      "[CV 1/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.951, test=0.460) total time=   0.2s\n",
      "[CV 2/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.957, test=0.470) total time=   0.2s\n",
      "[CV 3/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.954, test=0.470) total time=   0.2s\n",
      "[CV 4/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.965, test=0.429) total time=   0.2s\n",
      "[CV 5/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.947, test=0.423) total time=   0.2s\n",
      "[CV 1/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.961, test=0.452) total time=   0.4s\n",
      "[CV 2/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.964, test=0.482) total time=   0.4s\n",
      "[CV 3/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.959, test=0.474) total time=   0.4s\n",
      "[CV 4/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.965, test=0.425) total time=   0.4s\n",
      "[CV 5/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.956, test=0.417) total time=   0.4s\n",
      "[CV 1/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.967, test=0.467) total time=   0.7s\n",
      "[CV 2/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.970, test=0.489) total time=   0.7s\n",
      "[CV 3/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.961, test=0.462) total time=   0.7s\n",
      "[CV 4/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.968, test=0.412) total time=   0.7s\n",
      "[CV 5/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.961, test=0.421) total time=   0.7s\n",
      "[CV 1/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.921, test=0.469) total time=   0.2s\n",
      "[CV 2/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.918, test=0.460) total time=   0.2s\n",
      "[CV 3/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.919, test=0.476) total time=   0.2s\n",
      "[CV 4/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.919, test=0.434) total time=   0.1s\n",
      "[CV 5/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.912, test=0.418) total time=   0.2s\n",
      "[CV 1/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.927, test=0.460) total time=   0.4s\n",
      "[CV 2/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.932, test=0.480) total time=   0.4s\n",
      "[CV 3/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.922, test=0.490) total time=   0.4s\n",
      "[CV 4/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.931, test=0.446) total time=   0.4s\n",
      "[CV 5/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.916, test=0.413) total time=   0.4s\n",
      "[CV 1/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.925, test=0.462) total time=   0.6s\n",
      "[CV 2/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.932, test=0.496) total time=   0.6s\n",
      "[CV 3/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.927, test=0.465) total time=   0.6s\n",
      "[CV 4/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.929, test=0.429) total time=   0.6s\n",
      "[CV 5/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.925, test=0.420) total time=   0.6s\n",
      "[CV 1/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.857, test=0.462) total time=   0.2s\n",
      "[CV 2/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.871, test=0.485) total time=   0.1s\n",
      "[CV 3/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.881, test=0.466) total time=   0.2s\n",
      "[CV 4/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.873, test=0.447) total time=   0.2s\n",
      "[CV 5/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.870, test=0.436) total time=   0.2s\n",
      "[CV 1/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.879, test=0.458) total time=   0.5s\n",
      "[CV 2/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.870, test=0.491) total time=   0.4s\n",
      "[CV 3/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.874, test=0.499) total time=   0.4s\n",
      "[CV 4/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.889, test=0.415) total time=   0.4s\n",
      "[CV 5/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.872, test=0.423) total time=   0.4s\n",
      "[CV 1/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.869, test=0.464) total time=   0.6s\n",
      "[CV 2/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.869, test=0.514) total time=   0.6s\n",
      "[CV 3/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.873, test=0.492) total time=   0.6s\n",
      "[CV 4/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.884, test=0.422) total time=   0.6s\n",
      "[CV 5/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.875, test=0.417) total time=   0.6s\n",
      "[CV 1/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.879, test=0.456) total time=   0.1s\n",
      "[CV 2/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.881, test=0.490) total time=   0.1s\n",
      "[CV 3/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.884, test=0.486) total time=   0.1s\n",
      "[CV 4/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.894, test=0.425) total time=   0.2s\n",
      "[CV 5/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.878, test=0.427) total time=   0.1s\n",
      "[CV 1/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.893, test=0.452) total time=   0.4s\n",
      "[CV 2/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.888, test=0.489) total time=   0.4s\n",
      "[CV 3/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.880, test=0.482) total time=   0.4s\n",
      "[CV 4/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.895, test=0.428) total time=   0.4s\n",
      "[CV 5/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.883, test=0.436) total time=   0.4s\n",
      "[CV 1/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.893, test=0.463) total time=   0.6s\n",
      "[CV 2/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.895, test=0.504) total time=   0.6s\n",
      "[CV 3/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.888, test=0.483) total time=   0.6s\n",
      "[CV 4/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.900, test=0.435) total time=   0.6s\n",
      "[CV 5/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.889, test=0.421) total time=   0.6s\n",
      "[CV 1/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.885, test=0.471) total time=   0.2s\n",
      "[CV 2/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.869, test=0.515) total time=   0.2s\n",
      "[CV 3/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.876, test=0.488) total time=   0.2s\n",
      "[CV 4/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.875, test=0.419) total time=   0.2s\n",
      "[CV 5/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.882, test=0.442) total time=   0.2s\n",
      "[CV 1/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.884, test=0.469) total time=   0.4s\n",
      "[CV 2/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.889, test=0.488) total time=   0.4s\n",
      "[CV 3/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.890, test=0.481) total time=   0.4s\n",
      "[CV 4/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.898, test=0.428) total time=   0.4s\n",
      "[CV 5/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.884, test=0.431) total time=   0.4s\n",
      "[CV 1/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.889, test=0.473) total time=   0.6s\n",
      "[CV 2/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.899, test=0.494) total time=   0.6s\n",
      "[CV 3/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.893, test=0.507) total time=   0.6s\n",
      "[CV 4/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.898, test=0.437) total time=   0.6s\n",
      "[CV 5/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.888, test=0.413) total time=   0.6s\n",
      "[CV 1/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.829, test=0.436) total time=   0.1s\n",
      "[CV 2/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.837, test=0.483) total time=   0.1s\n",
      "[CV 3/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.835, test=0.475) total time=   0.1s\n",
      "[CV 4/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.847, test=0.427) total time=   0.1s\n",
      "[CV 5/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.838, test=0.443) total time=   0.1s\n",
      "[CV 1/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.853, test=0.456) total time=   0.4s\n",
      "[CV 2/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.858, test=0.503) total time=   0.4s\n",
      "[CV 3/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.845, test=0.490) total time=   0.4s\n",
      "[CV 4/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.859, test=0.426) total time=   0.4s\n",
      "[CV 5/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.841, test=0.431) total time=   0.4s\n",
      "[CV 1/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.849, test=0.455) total time=   0.7s\n",
      "[CV 2/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.854, test=0.512) total time=   0.6s\n",
      "[CV 3/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.861, test=0.505) total time=   0.6s\n",
      "[CV 4/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.856, test=0.427) total time=   0.6s\n",
      "[CV 5/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.839, test=0.422) total time=   0.6s\n",
      "Selected Parameters: {'rf__max_depth': 20, 'rf__min_samples_leaf': 5, 'rf__min_samples_split': 15, 'rf__n_estimators': 50}\n",
      "Train score: 0.8460859293086767\n",
      "Test score: 0.3862687594451843\n",
      "Running for 3 out of a total of 5\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.448) total time=   0.2s\n",
      "[CV 2/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.401) total time=   0.2s\n",
      "[CV 3/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.429) total time=   0.2s\n",
      "[CV 4/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.438) total time=   0.2s\n",
      "[CV 5/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.448) total time=   0.2s\n",
      "[CV 1/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.454) total time=   0.5s\n",
      "[CV 2/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.400) total time=   0.5s\n",
      "[CV 3/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.438) total time=   0.5s\n",
      "[CV 4/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.436) total time=   0.5s\n",
      "[CV 5/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.452) total time=   0.5s\n",
      "[CV 1/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.450) total time=   0.8s\n",
      "[CV 2/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.412) total time=   0.8s\n",
      "[CV 3/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.438) total time=   1.0s\n",
      "[CV 4/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.461) total time=   0.8s\n",
      "[CV 5/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.437) total time=   0.8s\n",
      "[CV 1/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.938, test=0.465) total time=   0.2s\n",
      "[CV 2/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.953, test=0.479) total time=   0.2s\n",
      "[CV 3/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.948, test=0.446) total time=   0.2s\n",
      "[CV 4/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.947, test=0.437) total time=   0.2s\n",
      "[CV 5/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.952, test=0.455) total time=   0.3s\n",
      "[CV 1/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.951, test=0.467) total time=   0.5s\n",
      "[CV 2/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.961, test=0.453) total time=   0.5s\n",
      "[CV 3/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.955, test=0.445) total time=   0.5s\n",
      "[CV 4/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.956, test=0.452) total time=   0.5s\n",
      "[CV 5/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.953, test=0.453) total time=   0.5s\n",
      "[CV 1/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.958, test=0.465) total time=   0.7s\n",
      "[CV 2/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.963, test=0.443) total time=   0.7s\n",
      "[CV 3/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.964, test=0.471) total time=   0.7s\n",
      "[CV 4/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.960, test=0.445) total time=   0.7s\n",
      "[CV 5/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.959, test=0.461) total time=   0.7s\n",
      "[CV 1/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.886, test=0.457) total time=   0.2s\n",
      "[CV 2/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.898, test=0.452) total time=   0.2s\n",
      "[CV 3/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.903, test=0.484) total time=   0.2s\n",
      "[CV 4/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.897, test=0.452) total time=   0.2s\n",
      "[CV 5/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.891, test=0.439) total time=   0.2s\n",
      "[CV 1/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.900, test=0.461) total time=   0.4s\n",
      "[CV 2/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.906, test=0.448) total time=   0.4s\n",
      "[CV 3/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.910, test=0.477) total time=   0.4s\n",
      "[CV 4/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.900, test=0.465) total time=   0.5s\n",
      "[CV 5/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.893, test=0.470) total time=   0.5s\n",
      "[CV 1/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.901, test=0.452) total time=   0.7s\n",
      "[CV 2/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.908, test=0.439) total time=   0.7s\n",
      "[CV 3/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.911, test=0.472) total time=   0.7s\n",
      "[CV 4/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.902, test=0.438) total time=   0.7s\n",
      "[CV 5/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.912, test=0.434) total time=   0.7s\n",
      "[CV 1/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.950, test=0.474) total time=   0.2s\n",
      "[CV 2/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.954, test=0.454) total time=   0.2s\n",
      "[CV 3/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.958, test=0.487) total time=   0.2s\n",
      "[CV 4/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.955, test=0.448) total time=   0.2s\n",
      "[CV 5/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.953, test=0.450) total time=   0.2s\n",
      "[CV 1/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.962, test=0.465) total time=   0.5s\n",
      "[CV 2/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.967, test=0.464) total time=   0.4s\n",
      "[CV 3/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.966, test=0.449) total time=   0.5s\n",
      "[CV 4/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.959, test=0.458) total time=   0.4s\n",
      "[CV 5/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.960, test=0.445) total time=   0.4s\n",
      "[CV 1/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.959, test=0.447) total time=   0.7s\n",
      "[CV 2/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.973, test=0.420) total time=   0.7s\n",
      "[CV 3/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.969, test=0.463) total time=   0.7s\n",
      "[CV 4/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.958, test=0.462) total time=   0.8s\n",
      "[CV 5/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.965, test=0.447) total time=   0.7s\n",
      "[CV 1/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.898, test=0.478) total time=   0.2s\n",
      "[CV 2/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.918, test=0.444) total time=   0.2s\n",
      "[CV 3/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.923, test=0.447) total time=   0.2s\n",
      "[CV 4/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.916, test=0.472) total time=   0.2s\n",
      "[CV 5/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.915, test=0.449) total time=   0.2s\n",
      "[CV 1/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.916, test=0.450) total time=   0.4s\n",
      "[CV 2/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.924, test=0.440) total time=   0.4s\n",
      "[CV 3/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.923, test=0.458) total time=   0.4s\n",
      "[CV 4/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.925, test=0.440) total time=   0.4s\n",
      "[CV 5/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.922, test=0.462) total time=   0.4s\n",
      "[CV 1/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.932, test=0.468) total time=   0.7s\n",
      "[CV 2/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.931, test=0.445) total time=   0.8s\n",
      "[CV 3/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.929, test=0.467) total time=   0.7s\n",
      "[CV 4/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.923, test=0.465) total time=   0.7s\n",
      "[CV 5/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.929, test=0.431) total time=   0.7s\n",
      "[CV 1/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.872, test=0.474) total time=   0.2s\n",
      "[CV 2/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.880, test=0.463) total time=   0.2s\n",
      "[CV 3/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.872, test=0.483) total time=   0.2s\n",
      "[CV 4/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.856, test=0.466) total time=   0.2s\n",
      "[CV 5/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.851, test=0.451) total time=   0.2s\n",
      "[CV 1/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.872, test=0.469) total time=   0.4s\n",
      "[CV 2/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.878, test=0.462) total time=   0.4s\n",
      "[CV 3/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.877, test=0.462) total time=   0.4s\n",
      "[CV 4/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.865, test=0.460) total time=   0.4s\n",
      "[CV 5/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.874, test=0.461) total time=   0.4s\n",
      "[CV 1/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.871, test=0.462) total time=   0.7s\n",
      "[CV 2/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.883, test=0.448) total time=   0.7s\n",
      "[CV 3/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.879, test=0.478) total time=   0.7s\n",
      "[CV 4/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.874, test=0.462) total time=   0.7s\n",
      "[CV 5/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.875, test=0.444) total time=   0.7s\n",
      "[CV 1/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.879, test=0.460) total time=   0.2s\n",
      "[CV 2/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.886, test=0.459) total time=   0.2s\n",
      "[CV 3/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.900, test=0.461) total time=   0.2s\n",
      "[CV 4/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.874, test=0.451) total time=   0.2s\n",
      "[CV 5/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.877, test=0.442) total time=   0.2s\n",
      "[CV 1/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.883, test=0.471) total time=   0.4s\n",
      "[CV 2/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.892, test=0.455) total time=   0.4s\n",
      "[CV 3/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.899, test=0.452) total time=   0.4s\n",
      "[CV 4/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.893, test=0.457) total time=   0.4s\n",
      "[CV 5/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.882, test=0.443) total time=   0.4s\n",
      "[CV 1/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.891, test=0.453) total time=   0.7s\n",
      "[CV 2/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.894, test=0.439) total time=   0.7s\n",
      "[CV 3/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.898, test=0.455) total time=   0.7s\n",
      "[CV 4/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.882, test=0.462) total time=   0.7s\n",
      "[CV 5/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.888, test=0.451) total time=   0.7s\n",
      "[CV 1/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.867, test=0.470) total time=   0.2s\n",
      "[CV 2/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.885, test=0.462) total time=   0.2s\n",
      "[CV 3/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.892, test=0.451) total time=   0.2s\n",
      "[CV 4/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.875, test=0.458) total time=   0.2s\n",
      "[CV 5/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.871, test=0.458) total time=   0.2s\n",
      "[CV 1/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.889, test=0.480) total time=   0.4s\n",
      "[CV 2/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.894, test=0.452) total time=   0.4s\n",
      "[CV 3/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.891, test=0.459) total time=   0.4s\n",
      "[CV 4/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.885, test=0.453) total time=   0.4s\n",
      "[CV 5/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.882, test=0.447) total time=   0.4s\n",
      "[CV 1/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.886, test=0.465) total time=   0.7s\n",
      "[CV 2/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.897, test=0.442) total time=   0.7s\n",
      "[CV 3/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.900, test=0.467) total time=   0.8s\n",
      "[CV 4/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.897, test=0.443) total time=   0.7s\n",
      "[CV 5/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.888, test=0.458) total time=   0.7s\n",
      "[CV 1/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.830, test=0.478) total time=   0.2s\n",
      "[CV 2/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.847, test=0.446) total time=   0.2s\n",
      "[CV 3/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.846, test=0.469) total time=   0.2s\n",
      "[CV 4/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.841, test=0.439) total time=   0.2s\n",
      "[CV 5/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.827, test=0.444) total time=   0.2s\n",
      "[CV 1/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.852, test=0.453) total time=   0.4s\n",
      "[CV 2/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.854, test=0.441) total time=   0.4s\n",
      "[CV 3/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.856, test=0.476) total time=   0.4s\n",
      "[CV 4/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.843, test=0.444) total time=   0.4s\n",
      "[CV 5/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.848, test=0.448) total time=   0.4s\n",
      "[CV 1/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.853, test=0.455) total time=   0.6s\n",
      "[CV 2/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.848, test=0.447) total time=   0.7s\n",
      "[CV 3/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.856, test=0.479) total time=   0.6s\n",
      "[CV 4/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.848, test=0.462) total time=   0.6s\n",
      "[CV 5/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.846, test=0.455) total time=   0.6s\n",
      "[CV 1/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.463) total time=   0.3s\n",
      "[CV 2/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.413) total time=   0.2s\n",
      "[CV 3/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.454) total time=   0.2s\n",
      "[CV 4/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.434) total time=   0.2s\n",
      "[CV 5/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.441) total time=   0.2s\n",
      "[CV 1/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.462) total time=   0.5s\n",
      "[CV 2/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.422) total time=   0.5s\n",
      "[CV 3/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.432) total time=   0.5s\n",
      "[CV 4/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.424) total time=   0.5s\n",
      "[CV 5/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.434) total time=   0.5s\n",
      "[CV 1/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.453) total time=   0.8s\n",
      "[CV 2/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.394) total time=   0.8s\n",
      "[CV 3/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.450) total time=   0.8s\n",
      "[CV 4/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.427) total time=   0.9s\n",
      "[CV 5/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.410) total time=   0.9s\n",
      "[CV 1/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.946, test=0.459) total time=   0.2s\n",
      "[CV 2/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.958, test=0.451) total time=   0.2s\n",
      "[CV 3/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.950, test=0.443) total time=   0.2s\n",
      "[CV 4/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.954, test=0.449) total time=   0.2s\n",
      "[CV 5/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.947, test=0.435) total time=   0.2s\n",
      "[CV 1/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.957, test=0.468) total time=   0.5s\n",
      "[CV 2/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.966, test=0.444) total time=   0.5s\n",
      "[CV 3/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.958, test=0.457) total time=   0.5s\n",
      "[CV 4/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.953, test=0.431) total time=   0.5s\n",
      "[CV 5/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.959, test=0.454) total time=   0.5s\n",
      "[CV 1/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.956, test=0.469) total time=   0.7s\n",
      "[CV 2/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.961, test=0.461) total time=   0.7s\n",
      "[CV 3/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.966, test=0.472) total time=   0.8s\n",
      "[CV 4/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.955, test=0.458) total time=   0.8s\n",
      "[CV 5/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.964, test=0.453) total time=   0.7s\n",
      "[CV 1/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.888, test=0.459) total time=   0.2s\n",
      "[CV 2/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.892, test=0.460) total time=   0.2s\n",
      "[CV 3/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.900, test=0.449) total time=   0.2s\n",
      "[CV 4/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.882, test=0.448) total time=   0.2s\n",
      "[CV 5/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.888, test=0.440) total time=   0.2s\n",
      "[CV 1/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.896, test=0.470) total time=   0.5s\n",
      "[CV 2/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.911, test=0.456) total time=   0.4s\n",
      "[CV 3/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.902, test=0.473) total time=   0.4s\n",
      "[CV 4/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.901, test=0.447) total time=   0.4s\n",
      "[CV 5/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.902, test=0.442) total time=   0.4s\n",
      "[CV 1/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.900, test=0.457) total time=   0.7s\n",
      "[CV 2/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.921, test=0.452) total time=   0.7s\n",
      "[CV 3/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.912, test=0.478) total time=   0.7s\n",
      "[CV 4/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.909, test=0.463) total time=   0.7s\n",
      "[CV 5/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.903, test=0.456) total time=   0.7s\n",
      "[CV 1/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.952, test=0.465) total time=   0.2s\n",
      "[CV 2/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.954, test=0.441) total time=   0.2s\n",
      "[CV 3/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.953, test=0.446) total time=   0.2s\n",
      "[CV 4/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.957, test=0.438) total time=   0.2s\n",
      "[CV 5/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.958, test=0.455) total time=   0.2s\n",
      "[CV 1/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.959, test=0.469) total time=   0.5s\n",
      "[CV 2/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.967, test=0.430) total time=   0.5s\n",
      "[CV 3/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.964, test=0.451) total time=   0.5s\n",
      "[CV 4/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.962, test=0.461) total time=   0.5s\n",
      "[CV 5/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.960, test=0.472) total time=   0.4s\n",
      "[CV 1/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.966, test=0.475) total time=   0.7s\n",
      "[CV 2/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.971, test=0.418) total time=   0.7s\n",
      "[CV 3/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.970, test=0.445) total time=   0.9s\n",
      "[CV 4/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.964, test=0.451) total time=   0.9s\n",
      "[CV 5/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.968, test=0.451) total time=   0.7s\n",
      "[CV 1/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.912, test=0.452) total time=   0.2s\n",
      "[CV 2/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.923, test=0.455) total time=   0.2s\n",
      "[CV 3/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.917, test=0.460) total time=   0.2s\n",
      "[CV 4/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.908, test=0.464) total time=   0.2s\n",
      "[CV 5/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.911, test=0.463) total time=   0.2s\n",
      "[CV 1/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.918, test=0.483) total time=   0.4s\n",
      "[CV 2/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.923, test=0.456) total time=   0.4s\n",
      "[CV 3/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.932, test=0.481) total time=   0.4s\n",
      "[CV 4/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.923, test=0.453) total time=   0.4s\n",
      "[CV 5/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.929, test=0.446) total time=   0.4s\n",
      "[CV 1/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.925, test=0.465) total time=   0.7s\n",
      "[CV 2/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.926, test=0.465) total time=   0.7s\n",
      "[CV 3/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.928, test=0.495) total time=   0.7s\n",
      "[CV 4/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.925, test=0.452) total time=   0.7s\n",
      "[CV 5/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.929, test=0.456) total time=   0.7s\n",
      "[CV 1/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.859, test=0.476) total time=   0.2s\n",
      "[CV 2/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.865, test=0.432) total time=   0.2s\n",
      "[CV 3/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.870, test=0.463) total time=   0.2s\n",
      "[CV 4/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.865, test=0.451) total time=   0.2s\n",
      "[CV 5/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.863, test=0.454) total time=   0.2s\n",
      "[CV 1/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.876, test=0.467) total time=   0.5s\n",
      "[CV 2/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.882, test=0.452) total time=   0.4s\n",
      "[CV 3/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.874, test=0.474) total time=   0.4s\n",
      "[CV 4/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.876, test=0.426) total time=   0.4s\n",
      "[CV 5/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.883, test=0.463) total time=   0.4s\n",
      "[CV 1/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.872, test=0.469) total time=   0.7s\n",
      "[CV 2/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.882, test=0.465) total time=   0.7s\n",
      "[CV 3/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.890, test=0.473) total time=   0.7s\n",
      "[CV 4/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.875, test=0.453) total time=   0.7s\n",
      "[CV 5/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.884, test=0.453) total time=   0.7s\n",
      "[CV 1/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.880, test=0.464) total time=   0.2s\n",
      "[CV 2/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.887, test=0.449) total time=   0.2s\n",
      "[CV 3/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.888, test=0.474) total time=   0.2s\n",
      "[CV 4/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.871, test=0.463) total time=   0.2s\n",
      "[CV 5/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.880, test=0.439) total time=   0.2s\n",
      "[CV 1/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.879, test=0.484) total time=   0.4s\n",
      "[CV 2/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.899, test=0.423) total time=   0.4s\n",
      "[CV 3/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.899, test=0.460) total time=   0.4s\n",
      "[CV 4/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.890, test=0.452) total time=   0.4s\n",
      "[CV 5/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.886, test=0.453) total time=   0.4s\n",
      "[CV 1/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.888, test=0.463) total time=   0.7s\n",
      "[CV 2/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.902, test=0.456) total time=   0.7s\n",
      "[CV 3/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.897, test=0.468) total time=   0.7s\n",
      "[CV 4/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.890, test=0.445) total time=   0.7s\n",
      "[CV 5/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.884, test=0.441) total time=   0.7s\n",
      "[CV 1/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.872, test=0.483) total time=   0.2s\n",
      "[CV 2/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.877, test=0.441) total time=   0.2s\n",
      "[CV 3/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.884, test=0.472) total time=   0.2s\n",
      "[CV 4/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.879, test=0.451) total time=   0.2s\n",
      "[CV 5/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.879, test=0.463) total time=   0.2s\n",
      "[CV 1/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.889, test=0.458) total time=   0.4s\n",
      "[CV 2/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.884, test=0.434) total time=   0.4s\n",
      "[CV 3/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.890, test=0.456) total time=   0.4s\n",
      "[CV 4/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.888, test=0.457) total time=   0.5s\n",
      "[CV 5/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.891, test=0.461) total time=   0.4s\n",
      "[CV 1/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.892, test=0.441) total time=   0.7s\n",
      "[CV 2/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.902, test=0.446) total time=   0.7s\n",
      "[CV 3/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.896, test=0.464) total time=   0.7s\n",
      "[CV 4/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.888, test=0.446) total time=   0.7s\n",
      "[CV 5/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.884, test=0.460) total time=   0.7s\n",
      "[CV 1/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.848, test=0.471) total time=   0.2s\n",
      "[CV 2/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.847, test=0.467) total time=   0.2s\n",
      "[CV 3/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.845, test=0.482) total time=   0.2s\n",
      "[CV 4/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.833, test=0.450) total time=   0.2s\n",
      "[CV 5/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.830, test=0.425) total time=   0.2s\n",
      "[CV 1/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.846, test=0.486) total time=   0.4s\n",
      "[CV 2/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.851, test=0.449) total time=   0.4s\n",
      "[CV 3/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.854, test=0.453) total time=   0.4s\n",
      "[CV 4/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.853, test=0.459) total time=   0.4s\n",
      "[CV 5/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.838, test=0.461) total time=   0.4s\n",
      "[CV 1/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.853, test=0.469) total time=   0.7s\n",
      "[CV 2/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.858, test=0.451) total time=   0.6s\n",
      "[CV 3/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.865, test=0.478) total time=   0.6s\n",
      "[CV 4/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.862, test=0.433) total time=   0.7s\n",
      "[CV 5/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.849, test=0.458) total time=   0.6s\n",
      "Selected Parameters: {'rf__max_depth': 20, 'rf__min_samples_leaf': 3, 'rf__min_samples_split': 15, 'rf__n_estimators': 50}\n",
      "Train score: 0.8574769739912517\n",
      "Test score: 0.3444322089319242\n",
      "Running for 4 out of a total of 5\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.403) total time=   0.2s\n",
      "[CV 2/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.436) total time=   0.3s\n",
      "[CV 3/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.427) total time=   0.3s\n",
      "[CV 4/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.445) total time=   0.3s\n",
      "[CV 5/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.441) total time=   0.3s\n",
      "[CV 1/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.401) total time=   0.6s\n",
      "[CV 2/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.420) total time=   0.6s\n",
      "[CV 3/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.428) total time=   0.6s\n",
      "[CV 4/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.466) total time=   0.6s\n",
      "[CV 5/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.411) total time=   0.6s\n",
      "[CV 1/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.406) total time=   0.9s\n",
      "[CV 2/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.431) total time=   1.1s\n",
      "[CV 3/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.446) total time=   1.1s\n",
      "[CV 4/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.468) total time=   1.0s\n",
      "[CV 5/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.422) total time=   1.0s\n",
      "[CV 1/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.947, test=0.418) total time=   0.3s\n",
      "[CV 2/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.947, test=0.443) total time=   0.2s\n",
      "[CV 3/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.948, test=0.441) total time=   0.2s\n",
      "[CV 4/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.953, test=0.464) total time=   0.2s\n",
      "[CV 5/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.946, test=0.453) total time=   0.2s\n",
      "[CV 1/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.955, test=0.427) total time=   0.5s\n",
      "[CV 2/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.952, test=0.444) total time=   0.5s\n",
      "[CV 3/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.953, test=0.459) total time=   0.5s\n",
      "[CV 4/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.964, test=0.480) total time=   0.5s\n",
      "[CV 5/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.954, test=0.451) total time=   0.5s\n",
      "[CV 1/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.954, test=0.422) total time=   0.8s\n",
      "[CV 2/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.962, test=0.445) total time=   0.8s\n",
      "[CV 3/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.964, test=0.477) total time=   1.0s\n",
      "[CV 4/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.964, test=0.483) total time=   0.9s\n",
      "[CV 5/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.960, test=0.478) total time=   1.0s\n",
      "[CV 1/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.879, test=0.435) total time=   0.2s\n",
      "[CV 2/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.889, test=0.443) total time=   0.2s\n",
      "[CV 3/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.888, test=0.460) total time=   0.2s\n",
      "[CV 4/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.901, test=0.481) total time=   0.2s\n",
      "[CV 5/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.889, test=0.464) total time=   0.2s\n",
      "[CV 1/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.902, test=0.417) total time=   0.5s\n",
      "[CV 2/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.899, test=0.463) total time=   0.5s\n",
      "[CV 3/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.911, test=0.461) total time=   0.5s\n",
      "[CV 4/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.912, test=0.491) total time=   0.5s\n",
      "[CV 5/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.911, test=0.471) total time=   0.5s\n",
      "[CV 1/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.905, test=0.436) total time=   0.8s\n",
      "[CV 2/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.891, test=0.476) total time=   0.8s\n",
      "[CV 3/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.910, test=0.473) total time=   0.8s\n",
      "[CV 4/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.912, test=0.479) total time=   0.8s\n",
      "[CV 5/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.908, test=0.479) total time=   0.8s\n",
      "[CV 1/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.948, test=0.437) total time=   0.3s\n",
      "[CV 2/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.953, test=0.443) total time=   0.3s\n",
      "[CV 3/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.960, test=0.452) total time=   0.2s\n",
      "[CV 4/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.957, test=0.480) total time=   0.2s\n",
      "[CV 5/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.951, test=0.467) total time=   0.2s\n",
      "[CV 1/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.959, test=0.411) total time=   0.5s\n",
      "[CV 2/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.964, test=0.455) total time=   0.5s\n",
      "[CV 3/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.967, test=0.455) total time=   0.5s\n",
      "[CV 4/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.961, test=0.482) total time=   0.5s\n",
      "[CV 5/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.964, test=0.464) total time=   0.5s\n",
      "[CV 1/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.966, test=0.414) total time=   0.8s\n",
      "[CV 2/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.963, test=0.454) total time=   0.8s\n",
      "[CV 3/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.967, test=0.467) total time=   1.0s\n",
      "[CV 4/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.974, test=0.480) total time=   0.8s\n",
      "[CV 5/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.962, test=0.446) total time=   1.0s\n",
      "[CV 1/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.923, test=0.425) total time=   0.3s\n",
      "[CV 2/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.916, test=0.479) total time=   0.3s\n",
      "[CV 3/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.921, test=0.459) total time=   0.2s\n",
      "[CV 4/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.914, test=0.462) total time=   0.2s\n",
      "[CV 5/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.914, test=0.473) total time=   0.2s\n",
      "[CV 1/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.923, test=0.439) total time=   0.5s\n",
      "[CV 2/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.918, test=0.455) total time=   0.5s\n",
      "[CV 3/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.933, test=0.447) total time=   0.5s\n",
      "[CV 4/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.934, test=0.473) total time=   0.5s\n",
      "[CV 5/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.926, test=0.475) total time=   0.5s\n",
      "[CV 1/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.919, test=0.440) total time=   0.8s\n",
      "[CV 2/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.921, test=0.467) total time=   0.8s\n",
      "[CV 3/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.935, test=0.454) total time=   0.8s\n",
      "[CV 4/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.934, test=0.484) total time=   0.8s\n",
      "[CV 5/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.926, test=0.462) total time=   0.8s\n",
      "[CV 1/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.858, test=0.439) total time=   0.2s\n",
      "[CV 2/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.856, test=0.457) total time=   0.2s\n",
      "[CV 3/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.861, test=0.478) total time=   0.2s\n",
      "[CV 4/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.869, test=0.463) total time=   0.2s\n",
      "[CV 5/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.860, test=0.477) total time=   0.2s\n",
      "[CV 1/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.866, test=0.436) total time=   0.5s\n",
      "[CV 2/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.866, test=0.474) total time=   0.5s\n",
      "[CV 3/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.879, test=0.473) total time=   0.5s\n",
      "[CV 4/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.877, test=0.481) total time=   0.6s\n",
      "[CV 5/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.872, test=0.464) total time=   0.5s\n",
      "[CV 1/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.874, test=0.437) total time=   0.8s\n",
      "[CV 2/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.875, test=0.460) total time=   0.8s\n",
      "[CV 3/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.887, test=0.460) total time=   0.8s\n",
      "[CV 4/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.884, test=0.490) total time=   0.7s\n",
      "[CV 5/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.872, test=0.474) total time=   0.7s\n",
      "[CV 1/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.875, test=0.428) total time=   0.2s\n",
      "[CV 2/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.877, test=0.443) total time=   0.2s\n",
      "[CV 3/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.890, test=0.456) total time=   0.2s\n",
      "[CV 4/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.883, test=0.484) total time=   0.2s\n",
      "[CV 5/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.886, test=0.469) total time=   0.2s\n",
      "[CV 1/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.882, test=0.437) total time=   0.5s\n",
      "[CV 2/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.883, test=0.456) total time=   0.5s\n",
      "[CV 3/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.895, test=0.459) total time=   0.5s\n",
      "[CV 4/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.891, test=0.489) total time=   0.5s\n",
      "[CV 5/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.885, test=0.466) total time=   0.5s\n",
      "[CV 1/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.889, test=0.439) total time=   0.8s\n",
      "[CV 2/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.891, test=0.443) total time=   0.8s\n",
      "[CV 3/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.894, test=0.472) total time=   0.8s\n",
      "[CV 4/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.896, test=0.477) total time=   0.8s\n",
      "[CV 5/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.890, test=0.452) total time=   0.8s\n",
      "[CV 1/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.866, test=0.420) total time=   0.2s\n",
      "[CV 2/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.871, test=0.478) total time=   0.2s\n",
      "[CV 3/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.888, test=0.442) total time=   0.2s\n",
      "[CV 4/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.882, test=0.503) total time=   0.2s\n",
      "[CV 5/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.876, test=0.466) total time=   0.2s\n",
      "[CV 1/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.884, test=0.432) total time=   0.5s\n",
      "[CV 2/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.889, test=0.451) total time=   0.5s\n",
      "[CV 3/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.893, test=0.450) total time=   0.5s\n",
      "[CV 4/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.894, test=0.489) total time=   0.5s\n",
      "[CV 5/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.880, test=0.458) total time=   0.5s\n",
      "[CV 1/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.882, test=0.431) total time=   0.7s\n",
      "[CV 2/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.886, test=0.476) total time=   0.8s\n",
      "[CV 3/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.905, test=0.469) total time=   0.8s\n",
      "[CV 4/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.901, test=0.495) total time=   0.8s\n",
      "[CV 5/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.888, test=0.471) total time=   0.8s\n",
      "[CV 1/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.834, test=0.445) total time=   0.2s\n",
      "[CV 2/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.833, test=0.474) total time=   0.2s\n",
      "[CV 3/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.844, test=0.460) total time=   0.2s\n",
      "[CV 4/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.843, test=0.491) total time=   0.2s\n",
      "[CV 5/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.838, test=0.436) total time=   0.2s\n",
      "[CV 1/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.843, test=0.431) total time=   0.5s\n",
      "[CV 2/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.844, test=0.470) total time=   0.5s\n",
      "[CV 3/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.851, test=0.470) total time=   0.5s\n",
      "[CV 4/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.849, test=0.473) total time=   0.5s\n",
      "[CV 5/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.850, test=0.458) total time=   0.5s\n",
      "[CV 1/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.840, test=0.434) total time=   0.7s\n",
      "[CV 2/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.842, test=0.482) total time=   0.8s\n",
      "[CV 3/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.851, test=0.474) total time=   0.7s\n",
      "[CV 4/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.858, test=0.473) total time=   0.7s\n",
      "[CV 5/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.853, test=0.466) total time=   0.8s\n",
      "[CV 1/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.396) total time=   0.3s\n",
      "[CV 2/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.427) total time=   0.3s\n",
      "[CV 3/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.421) total time=   0.3s\n",
      "[CV 4/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.452) total time=   0.2s\n",
      "[CV 5/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.428) total time=   0.3s\n",
      "[CV 1/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.407) total time=   0.6s\n",
      "[CV 2/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.424) total time=   0.6s\n",
      "[CV 3/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.464) total time=   0.6s\n",
      "[CV 4/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.450) total time=   0.6s\n",
      "[CV 5/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.436) total time=   0.6s\n",
      "[CV 1/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.400) total time=   0.9s\n",
      "[CV 2/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.418) total time=   1.2s\n",
      "[CV 3/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.448) total time=   1.1s\n",
      "[CV 4/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.453) total time=   1.1s\n",
      "[CV 5/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.435) total time=   1.1s\n",
      "[CV 1/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.946, test=0.419) total time=   0.3s\n",
      "[CV 2/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.950, test=0.465) total time=   0.3s\n",
      "[CV 3/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.950, test=0.450) total time=   0.2s\n",
      "[CV 4/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.952, test=0.492) total time=   0.2s\n",
      "[CV 5/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.937, test=0.472) total time=   0.2s\n",
      "[CV 1/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.956, test=0.423) total time=   0.5s\n",
      "[CV 2/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.958, test=0.467) total time=   0.5s\n",
      "[CV 3/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.965, test=0.450) total time=   0.5s\n",
      "[CV 4/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.958, test=0.467) total time=   0.5s\n",
      "[CV 5/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.960, test=0.444) total time=   0.5s\n",
      "[CV 1/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.958, test=0.399) total time=   0.8s\n",
      "[CV 2/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.960, test=0.453) total time=   1.0s\n",
      "[CV 3/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.965, test=0.461) total time=   0.9s\n",
      "[CV 4/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.962, test=0.496) total time=   0.8s\n",
      "[CV 5/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.959, test=0.474) total time=   0.9s\n",
      "[CV 1/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.895, test=0.436) total time=   0.3s\n",
      "[CV 2/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.877, test=0.463) total time=   0.2s\n",
      "[CV 3/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.894, test=0.471) total time=   0.2s\n",
      "[CV 4/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.897, test=0.486) total time=   0.2s\n",
      "[CV 5/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.888, test=0.455) total time=   0.2s\n",
      "[CV 1/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.898, test=0.420) total time=   0.5s\n",
      "[CV 2/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.903, test=0.464) total time=   0.5s\n",
      "[CV 3/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.902, test=0.471) total time=   0.5s\n",
      "[CV 4/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.902, test=0.483) total time=   0.5s\n",
      "[CV 5/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.902, test=0.472) total time=   0.6s\n",
      "[CV 1/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.900, test=0.431) total time=   0.8s\n",
      "[CV 2/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.901, test=0.457) total time=   0.8s\n",
      "[CV 3/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.919, test=0.457) total time=   0.8s\n",
      "[CV 4/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.913, test=0.475) total time=   0.8s\n",
      "[CV 5/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.904, test=0.476) total time=   0.8s\n",
      "[CV 1/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.952, test=0.424) total time=   0.3s\n",
      "[CV 2/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.959, test=0.437) total time=   0.3s\n",
      "[CV 3/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.958, test=0.453) total time=   0.2s\n",
      "[CV 4/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.953, test=0.490) total time=   0.2s\n",
      "[CV 5/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.950, test=0.458) total time=   0.2s\n",
      "[CV 1/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.954, test=0.430) total time=   0.5s\n",
      "[CV 2/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.962, test=0.448) total time=   0.5s\n",
      "[CV 3/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.969, test=0.441) total time=   0.5s\n",
      "[CV 4/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.966, test=0.497) total time=   0.5s\n",
      "[CV 5/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.960, test=0.467) total time=   0.5s\n",
      "[CV 1/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.965, test=0.419) total time=   0.8s\n",
      "[CV 2/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.961, test=0.453) total time=   0.8s\n",
      "[CV 3/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.968, test=0.465) total time=   0.9s\n",
      "[CV 4/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.967, test=0.470) total time=   1.0s\n",
      "[CV 5/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.964, test=0.458) total time=   0.8s\n",
      "[CV 1/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.904, test=0.425) total time=   0.2s\n",
      "[CV 2/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.910, test=0.464) total time=   0.3s\n",
      "[CV 3/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.921, test=0.457) total time=   0.2s\n",
      "[CV 4/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.919, test=0.444) total time=   0.2s\n",
      "[CV 5/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.913, test=0.456) total time=   0.2s\n",
      "[CV 1/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.919, test=0.425) total time=   0.5s\n",
      "[CV 2/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.922, test=0.453) total time=   0.5s\n",
      "[CV 3/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.938, test=0.464) total time=   0.5s\n",
      "[CV 4/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.926, test=0.496) total time=   0.5s\n",
      "[CV 5/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.921, test=0.474) total time=   0.5s\n",
      "[CV 1/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.927, test=0.422) total time=   0.8s\n",
      "[CV 2/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.927, test=0.447) total time=   0.8s\n",
      "[CV 3/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.932, test=0.465) total time=   1.0s\n",
      "[CV 4/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.938, test=0.492) total time=   0.9s\n",
      "[CV 5/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.922, test=0.465) total time=   0.9s\n",
      "[CV 1/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.863, test=0.404) total time=   0.3s\n",
      "[CV 2/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.853, test=0.472) total time=   0.2s\n",
      "[CV 3/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.866, test=0.451) total time=   0.2s\n",
      "[CV 4/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.874, test=0.464) total time=   0.2s\n",
      "[CV 5/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.860, test=0.461) total time=   0.2s\n",
      "[CV 1/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.876, test=0.440) total time=   0.5s\n",
      "[CV 2/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.870, test=0.448) total time=   0.5s\n",
      "[CV 3/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.874, test=0.473) total time=   0.5s\n",
      "[CV 4/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.879, test=0.482) total time=   0.5s\n",
      "[CV 5/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.879, test=0.470) total time=   0.5s\n",
      "[CV 1/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.876, test=0.420) total time=   0.8s\n",
      "[CV 2/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.873, test=0.470) total time=   0.8s\n",
      "[CV 3/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.885, test=0.469) total time=   0.8s\n",
      "[CV 4/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.879, test=0.493) total time=   0.8s\n",
      "[CV 5/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.874, test=0.456) total time=   0.8s\n",
      "[CV 1/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.868, test=0.418) total time=   0.2s\n",
      "[CV 2/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.867, test=0.450) total time=   0.2s\n",
      "[CV 3/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.892, test=0.448) total time=   0.2s\n",
      "[CV 4/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.891, test=0.476) total time=   0.3s\n",
      "[CV 5/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.873, test=0.462) total time=   0.2s\n",
      "[CV 1/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.886, test=0.435) total time=   0.5s\n",
      "[CV 2/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.882, test=0.478) total time=   0.5s\n",
      "[CV 3/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.890, test=0.459) total time=   0.5s\n",
      "[CV 4/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.892, test=0.500) total time=   0.5s\n",
      "[CV 5/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.886, test=0.473) total time=   0.5s\n",
      "[CV 1/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.881, test=0.417) total time=   0.7s\n",
      "[CV 2/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.883, test=0.461) total time=   0.8s\n",
      "[CV 3/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.898, test=0.461) total time=   0.8s\n",
      "[CV 4/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.904, test=0.495) total time=   0.8s\n",
      "[CV 5/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.890, test=0.471) total time=   0.8s\n",
      "[CV 1/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.869, test=0.404) total time=   0.2s\n",
      "[CV 2/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.882, test=0.460) total time=   0.2s\n",
      "[CV 3/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.870, test=0.460) total time=   0.2s\n",
      "[CV 4/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.883, test=0.479) total time=   0.2s\n",
      "[CV 5/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.873, test=0.475) total time=   0.2s\n",
      "[CV 1/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.884, test=0.422) total time=   0.5s\n",
      "[CV 2/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.882, test=0.454) total time=   0.5s\n",
      "[CV 3/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.889, test=0.449) total time=   0.5s\n",
      "[CV 4/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.893, test=0.482) total time=   0.6s\n",
      "[CV 5/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.883, test=0.454) total time=   0.5s\n",
      "[CV 1/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.890, test=0.422) total time=   0.8s\n",
      "[CV 2/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.891, test=0.457) total time=   0.8s\n",
      "[CV 3/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.897, test=0.465) total time=   0.8s\n",
      "[CV 4/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.899, test=0.484) total time=   0.8s\n",
      "[CV 5/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.892, test=0.460) total time=   0.7s\n",
      "[CV 1/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.837, test=0.445) total time=   0.2s\n",
      "[CV 2/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.832, test=0.469) total time=   0.2s\n",
      "[CV 3/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.839, test=0.475) total time=   0.2s\n",
      "[CV 4/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.852, test=0.493) total time=   0.2s\n",
      "[CV 5/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.828, test=0.435) total time=   0.2s\n",
      "[CV 1/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.845, test=0.440) total time=   0.5s\n",
      "[CV 2/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.841, test=0.466) total time=   0.5s\n",
      "[CV 3/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.850, test=0.457) total time=   0.5s\n",
      "[CV 4/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.856, test=0.481) total time=   0.5s\n",
      "[CV 5/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.849, test=0.453) total time=   0.5s\n",
      "[CV 1/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.846, test=0.452) total time=   0.7s\n",
      "[CV 2/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.840, test=0.462) total time=   0.7s\n",
      "[CV 3/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.853, test=0.467) total time=   0.8s\n",
      "[CV 4/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.861, test=0.498) total time=   0.8s\n",
      "[CV 5/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.844, test=0.477) total time=   0.8s\n",
      "Selected Parameters: {'rf__max_depth': None, 'rf__min_samples_leaf': 5, 'rf__min_samples_split': 15, 'rf__n_estimators': 150}\n",
      "Train score: 0.8487829195839697\n",
      "Test score: 0.410142901330034\n",
      "Running for 5 out of a total of 5\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.412) total time=   0.4s\n",
      "[CV 2/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.388) total time=   0.3s\n",
      "[CV 3/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.429) total time=   0.3s\n",
      "[CV 4/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.385) total time=   0.3s\n",
      "[CV 5/5; 1/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 1/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.424) total time=   0.3s\n",
      "[CV 1/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.417) total time=   0.6s\n",
      "[CV 2/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.424) total time=   0.7s\n",
      "[CV 3/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.453) total time=   0.6s\n",
      "[CV 4/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.413) total time=   0.6s\n",
      "[CV 5/5; 2/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 2/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.418) total time=   0.6s\n",
      "[CV 1/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.420) total time=   1.0s\n",
      "[CV 2/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.409) total time=   1.1s\n",
      "[CV 3/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.437) total time=   1.1s\n",
      "[CV 4/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.392) total time=   1.1s\n",
      "[CV 5/5; 3/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 3/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.427) total time=   1.1s\n",
      "[CV 1/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.938, test=0.425) total time=   0.3s\n",
      "[CV 2/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.943, test=0.441) total time=   0.3s\n",
      "[CV 3/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.945, test=0.447) total time=   0.2s\n",
      "[CV 4/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.949, test=0.417) total time=   0.2s\n",
      "[CV 5/5; 4/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 4/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.941, test=0.451) total time=   0.2s\n",
      "[CV 1/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.959, test=0.432) total time=   0.6s\n",
      "[CV 2/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.959, test=0.426) total time=   0.6s\n",
      "[CV 3/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.960, test=0.478) total time=   0.6s\n",
      "[CV 4/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.958, test=0.418) total time=   0.6s\n",
      "[CV 5/5; 5/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 5/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.953, test=0.449) total time=   0.6s\n",
      "[CV 1/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.952, test=0.434) total time=   0.9s\n",
      "[CV 2/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.959, test=0.441) total time=   1.0s\n",
      "[CV 3/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.959, test=0.480) total time=   1.1s\n",
      "[CV 4/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.963, test=0.441) total time=   1.0s\n",
      "[CV 5/5; 6/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 6/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.963, test=0.456) total time=   1.1s\n",
      "[CV 1/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.881, test=0.433) total time=   0.3s\n",
      "[CV 2/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.886, test=0.427) total time=   0.2s\n",
      "[CV 3/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.890, test=0.460) total time=   0.2s\n",
      "[CV 4/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.892, test=0.439) total time=   0.2s\n",
      "[CV 5/5; 7/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 7/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.885, test=0.456) total time=   0.2s\n",
      "[CV 1/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.895, test=0.435) total time=   0.5s\n",
      "[CV 2/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.906, test=0.449) total time=   0.5s\n",
      "[CV 3/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.902, test=0.498) total time=   0.5s\n",
      "[CV 4/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.908, test=0.443) total time=   0.5s\n",
      "[CV 5/5; 8/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 8/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.906, test=0.451) total time=   0.5s\n",
      "[CV 1/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.896, test=0.437) total time=   0.9s\n",
      "[CV 2/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.910, test=0.451) total time=   1.0s\n",
      "[CV 3/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.913, test=0.478) total time=   1.0s\n",
      "[CV 4/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.910, test=0.433) total time=   1.0s\n",
      "[CV 5/5; 9/54] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 9/54] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.911, test=0.442) total time=   1.0s\n",
      "[CV 1/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.949, test=0.436) total time=   0.3s\n",
      "[CV 2/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.957, test=0.425) total time=   0.3s\n",
      "[CV 3/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.957, test=0.455) total time=   0.2s\n",
      "[CV 4/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.957, test=0.435) total time=   0.2s\n",
      "[CV 5/5; 10/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 10/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.949, test=0.425) total time=   0.2s\n",
      "[CV 1/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.958, test=0.437) total time=   0.6s\n",
      "[CV 2/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.969, test=0.425) total time=   0.7s\n",
      "[CV 3/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.961, test=0.461) total time=   0.6s\n",
      "[CV 4/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.965, test=0.421) total time=   0.6s\n",
      "[CV 5/5; 11/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 11/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.965, test=0.446) total time=   0.6s\n",
      "[CV 1/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.961, test=0.430) total time=   0.9s\n",
      "[CV 2/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.964, test=0.435) total time=   1.0s\n",
      "[CV 3/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.967, test=0.484) total time=   1.0s\n",
      "[CV 4/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.966, test=0.439) total time=   1.1s\n",
      "[CV 5/5; 12/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 12/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.966, test=0.432) total time=   1.0s\n",
      "[CV 1/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.903, test=0.418) total time=   0.4s\n",
      "[CV 2/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.906, test=0.449) total time=   0.4s\n",
      "[CV 3/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.914, test=0.461) total time=   0.2s\n",
      "[CV 4/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.914, test=0.449) total time=   0.2s\n",
      "[CV 5/5; 13/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 13/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.916, test=0.442) total time=   0.2s\n",
      "[CV 1/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.925, test=0.454) total time=   0.5s\n",
      "[CV 2/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.926, test=0.423) total time=   0.5s\n",
      "[CV 3/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.929, test=0.461) total time=   0.5s\n",
      "[CV 4/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.926, test=0.446) total time=   0.5s\n",
      "[CV 5/5; 14/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 14/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.924, test=0.439) total time=   0.5s\n",
      "[CV 1/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.920, test=0.444) total time=   0.9s\n",
      "[CV 2/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.925, test=0.433) total time=   1.0s\n",
      "[CV 3/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.934, test=0.473) total time=   1.0s\n",
      "[CV 4/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.937, test=0.441) total time=   1.0s\n",
      "[CV 5/5; 15/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 15/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.924, test=0.451) total time=   0.8s\n",
      "[CV 1/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.856, test=0.452) total time=   0.3s\n",
      "[CV 2/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.855, test=0.447) total time=   0.2s\n",
      "[CV 3/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.863, test=0.445) total time=   0.2s\n",
      "[CV 4/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.872, test=0.461) total time=   0.2s\n",
      "[CV 5/5; 16/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 16/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.861, test=0.461) total time=   0.2s\n",
      "[CV 1/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.862, test=0.434) total time=   0.5s\n",
      "[CV 2/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.872, test=0.435) total time=   0.5s\n",
      "[CV 3/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.871, test=0.453) total time=   0.5s\n",
      "[CV 4/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.874, test=0.442) total time=   0.5s\n",
      "[CV 5/5; 17/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 17/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.870, test=0.444) total time=   0.5s\n",
      "[CV 1/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.868, test=0.442) total time=   0.8s\n",
      "[CV 2/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.883, test=0.462) total time=   0.9s\n",
      "[CV 3/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.877, test=0.465) total time=   1.0s\n",
      "[CV 4/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.887, test=0.449) total time=   1.0s\n",
      "[CV 5/5; 18/54] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 18/54] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.869, test=0.441) total time=   0.9s\n",
      "[CV 1/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.868, test=0.440) total time=   0.3s\n",
      "[CV 2/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.871, test=0.457) total time=   0.2s\n",
      "[CV 3/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.872, test=0.487) total time=   0.2s\n",
      "[CV 4/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.880, test=0.425) total time=   0.2s\n",
      "[CV 5/5; 19/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 19/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.874, test=0.446) total time=   0.2s\n",
      "[CV 1/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.885, test=0.431) total time=   0.5s\n",
      "[CV 2/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.884, test=0.454) total time=   0.5s\n",
      "[CV 3/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.885, test=0.471) total time=   0.5s\n",
      "[CV 4/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.898, test=0.438) total time=   0.5s\n",
      "[CV 5/5; 20/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 20/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.883, test=0.440) total time=   0.5s\n",
      "[CV 1/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.886, test=0.427) total time=   0.8s\n",
      "[CV 2/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.890, test=0.433) total time=   1.0s\n",
      "[CV 3/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.892, test=0.492) total time=   0.8s\n",
      "[CV 4/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.890, test=0.444) total time=   0.9s\n",
      "[CV 5/5; 21/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 21/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.884, test=0.441) total time=   1.0s\n",
      "[CV 1/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.870, test=0.452) total time=   0.2s\n",
      "[CV 2/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.880, test=0.445) total time=   0.2s\n",
      "[CV 3/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.871, test=0.462) total time=   0.2s\n",
      "[CV 4/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.872, test=0.441) total time=   0.2s\n",
      "[CV 5/5; 22/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 22/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.872, test=0.440) total time=   0.2s\n",
      "[CV 1/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.866, test=0.427) total time=   0.5s\n",
      "[CV 2/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.889, test=0.448) total time=   0.5s\n",
      "[CV 3/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.890, test=0.473) total time=   0.5s\n",
      "[CV 4/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.896, test=0.436) total time=   0.6s\n",
      "[CV 5/5; 23/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 23/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.885, test=0.456) total time=   0.7s\n",
      "[CV 1/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.882, test=0.445) total time=   0.8s\n",
      "[CV 2/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.889, test=0.439) total time=   0.9s\n",
      "[CV 3/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.888, test=0.473) total time=   1.0s\n",
      "[CV 4/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.896, test=0.434) total time=   0.9s\n",
      "[CV 5/5; 24/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 24/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.886, test=0.424) total time=   0.8s\n",
      "[CV 1/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.828, test=0.438) total time=   0.2s\n",
      "[CV 2/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.823, test=0.443) total time=   0.2s\n",
      "[CV 3/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.837, test=0.489) total time=   0.2s\n",
      "[CV 4/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.837, test=0.450) total time=   0.2s\n",
      "[CV 5/5; 25/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 25/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.835, test=0.435) total time=   0.2s\n",
      "[CV 1/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.827, test=0.431) total time=   0.5s\n",
      "[CV 2/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.843, test=0.450) total time=   0.6s\n",
      "[CV 3/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.845, test=0.492) total time=   0.5s\n",
      "[CV 4/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.849, test=0.452) total time=   0.5s\n",
      "[CV 5/5; 26/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 26/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.842, test=0.436) total time=   0.5s\n",
      "[CV 1/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.836, test=0.449) total time=   0.8s\n",
      "[CV 2/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.846, test=0.436) total time=   0.8s\n",
      "[CV 3/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.847, test=0.472) total time=   0.8s\n",
      "[CV 4/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.852, test=0.446) total time=   0.8s\n",
      "[CV 5/5; 27/54] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 27/54] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.846, test=0.449) total time=   0.8s\n",
      "[CV 1/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.410) total time=   0.4s\n",
      "[CV 2/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.999, test=0.415) total time=   0.3s\n",
      "[CV 3/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.416) total time=   0.3s\n",
      "[CV 4/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.403) total time=   0.3s\n",
      "[CV 5/5; 28/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 28/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=1.000, test=0.435) total time=   0.3s\n",
      "[CV 1/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.402) total time=   0.6s\n",
      "[CV 2/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.401) total time=   0.6s\n",
      "[CV 3/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.445) total time=   0.6s\n",
      "[CV 4/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.397) total time=   0.6s\n",
      "[CV 5/5; 29/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 29/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=1.000, test=0.429) total time=   0.6s\n",
      "[CV 1/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.414) total time=   1.0s\n",
      "[CV 2/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.411) total time=   1.2s\n",
      "[CV 3/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.451) total time=   1.1s\n",
      "[CV 4/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.370) total time=   1.1s\n",
      "[CV 5/5; 30/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 30/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=1.000, test=0.439) total time=   1.1s\n",
      "[CV 1/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.944, test=0.435) total time=   0.3s\n",
      "[CV 2/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.947, test=0.437) total time=   0.3s\n",
      "[CV 3/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.951, test=0.461) total time=   0.2s\n",
      "[CV 4/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.948, test=0.439) total time=   0.3s\n",
      "[CV 5/5; 31/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 31/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.948, test=0.438) total time=   0.2s\n",
      "[CV 1/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.951, test=0.438) total time=   0.6s\n",
      "[CV 2/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.965, test=0.425) total time=   0.6s\n",
      "[CV 3/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.956, test=0.491) total time=   0.6s\n",
      "[CV 4/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.960, test=0.430) total time=   0.6s\n",
      "[CV 5/5; 32/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 32/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.958, test=0.470) total time=   0.6s\n",
      "[CV 1/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.954, test=0.444) total time=   0.9s\n",
      "[CV 2/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.964, test=0.444) total time=   1.1s\n",
      "[CV 3/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.962, test=0.478) total time=   1.0s\n",
      "[CV 4/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.962, test=0.426) total time=   1.0s\n",
      "[CV 5/5; 33/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 33/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.966, test=0.448) total time=   1.0s\n",
      "[CV 1/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.884, test=0.435) total time=   0.3s\n",
      "[CV 2/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.895, test=0.430) total time=   0.2s\n",
      "[CV 3/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.890, test=0.475) total time=   0.2s\n",
      "[CV 4/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.896, test=0.445) total time=   0.2s\n",
      "[CV 5/5; 34/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 34/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.880, test=0.450) total time=   0.2s\n",
      "[CV 1/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.893, test=0.443) total time=   0.5s\n",
      "[CV 2/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.905, test=0.448) total time=   0.6s\n",
      "[CV 3/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.907, test=0.490) total time=   0.5s\n",
      "[CV 4/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.903, test=0.431) total time=   0.5s\n",
      "[CV 5/5; 35/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 35/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.901, test=0.461) total time=   0.7s\n",
      "[CV 1/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.890, test=0.445) total time=   0.9s\n",
      "[CV 2/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.905, test=0.436) total time=   1.0s\n",
      "[CV 3/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.908, test=0.488) total time=   0.9s\n",
      "[CV 4/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.913, test=0.453) total time=   1.0s\n",
      "[CV 5/5; 36/54] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 36/54] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.905, test=0.443) total time=   1.0s\n",
      "[CV 1/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.947, test=0.435) total time=   0.3s\n",
      "[CV 2/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.962, test=0.442) total time=   0.3s\n",
      "[CV 3/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.959, test=0.469) total time=   0.3s\n",
      "[CV 4/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.963, test=0.411) total time=   0.2s\n",
      "[CV 5/5; 37/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 37/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.953, test=0.433) total time=   0.2s\n",
      "[CV 1/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.960, test=0.436) total time=   0.6s\n",
      "[CV 2/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.966, test=0.445) total time=   0.7s\n",
      "[CV 3/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.966, test=0.471) total time=   0.6s\n",
      "[CV 4/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.958, test=0.423) total time=   0.6s\n",
      "[CV 5/5; 38/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 38/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.963, test=0.471) total time=   0.6s\n",
      "[CV 1/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.966, test=0.428) total time=   1.0s\n",
      "[CV 2/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.969, test=0.444) total time=   1.1s\n",
      "[CV 3/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.968, test=0.466) total time=   1.1s\n",
      "[CV 4/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.970, test=0.437) total time=   1.2s\n",
      "[CV 5/5; 39/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 39/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.968, test=0.421) total time=   1.1s\n",
      "[CV 1/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.900, test=0.451) total time=   0.3s\n",
      "[CV 2/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.914, test=0.429) total time=   0.3s\n",
      "[CV 3/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.912, test=0.455) total time=   0.3s\n",
      "[CV 4/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.923, test=0.440) total time=   0.3s\n",
      "[CV 5/5; 40/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 40/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.910, test=0.458) total time=   0.3s\n",
      "[CV 1/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.921, test=0.440) total time=   0.6s\n",
      "[CV 2/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.925, test=0.442) total time=   0.6s\n",
      "[CV 3/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.922, test=0.467) total time=   0.6s\n",
      "[CV 4/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.932, test=0.437) total time=   0.6s\n",
      "[CV 5/5; 41/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 41/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.919, test=0.457) total time=   0.7s\n",
      "[CV 1/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.921, test=0.439) total time=   1.0s\n",
      "[CV 2/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.927, test=0.439) total time=   1.2s\n",
      "[CV 3/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.933, test=0.474) total time=   1.0s\n",
      "[CV 4/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.931, test=0.421) total time=   0.9s\n",
      "[CV 5/5; 42/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 42/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.930, test=0.455) total time=   1.0s\n",
      "[CV 1/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.854, test=0.451) total time=   0.2s\n",
      "[CV 2/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.863, test=0.456) total time=   0.2s\n",
      "[CV 3/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.861, test=0.464) total time=   0.2s\n",
      "[CV 4/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.860, test=0.442) total time=   0.2s\n",
      "[CV 5/5; 43/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 43/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.857, test=0.439) total time=   0.2s\n",
      "[CV 1/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.859, test=0.440) total time=   0.5s\n",
      "[CV 2/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.868, test=0.450) total time=   0.5s\n",
      "[CV 3/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.871, test=0.470) total time=   0.5s\n",
      "[CV 4/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.883, test=0.424) total time=   0.5s\n",
      "[CV 5/5; 44/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 44/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.865, test=0.454) total time=   0.6s\n",
      "[CV 1/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.865, test=0.442) total time=   0.8s\n",
      "[CV 2/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.875, test=0.439) total time=   1.0s\n",
      "[CV 3/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.880, test=0.439) total time=   1.0s\n",
      "[CV 4/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.885, test=0.443) total time=   0.8s\n",
      "[CV 5/5; 45/54] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 45/54] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.869, test=0.448) total time=   0.9s\n",
      "[CV 1/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 1/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.865, test=0.436) total time=   0.3s\n",
      "[CV 2/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 2/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.881, test=0.457) total time=   0.2s\n",
      "[CV 3/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 3/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.878, test=0.450) total time=   0.2s\n",
      "[CV 4/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 4/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.879, test=0.459) total time=   0.2s\n",
      "[CV 5/5; 46/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50\n",
      "[CV 5/5; 46/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=50;, score=(train=0.867, test=0.455) total time=   0.2s\n",
      "[CV 1/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.882, test=0.432) total time=   0.5s\n",
      "[CV 2/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.887, test=0.446) total time=   0.5s\n",
      "[CV 3/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.878, test=0.481) total time=   0.5s\n",
      "[CV 4/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.884, test=0.432) total time=   0.5s\n",
      "[CV 5/5; 47/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 47/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=0.880, test=0.452) total time=   0.5s\n",
      "[CV 1/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 1/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.887, test=0.427) total time=   0.8s\n",
      "[CV 2/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 2/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.892, test=0.444) total time=   0.9s\n",
      "[CV 3/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 3/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.890, test=0.475) total time=   1.1s\n",
      "[CV 4/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 4/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.901, test=0.441) total time=   1.1s\n",
      "[CV 5/5; 48/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150\n",
      "[CV 5/5; 48/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=150;, score=(train=0.889, test=0.432) total time=   1.0s\n",
      "[CV 1/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 1/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.870, test=0.427) total time=   0.3s\n",
      "[CV 2/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 2/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.872, test=0.425) total time=   0.2s\n",
      "[CV 3/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 3/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.874, test=0.458) total time=   0.2s\n",
      "[CV 4/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 4/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.880, test=0.436) total time=   0.2s\n",
      "[CV 5/5; 49/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50\n",
      "[CV 5/5; 49/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=50;, score=(train=0.857, test=0.454) total time=   0.2s\n",
      "[CV 1/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.893, test=0.438) total time=   0.5s\n",
      "[CV 2/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.891, test=0.448) total time=   0.5s\n",
      "[CV 3/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.883, test=0.468) total time=   0.5s\n",
      "[CV 4/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.892, test=0.438) total time=   0.5s\n",
      "[CV 5/5; 50/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 50/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=0.884, test=0.444) total time=   0.5s\n",
      "[CV 1/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 1/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.882, test=0.455) total time=   0.8s\n",
      "[CV 2/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 2/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.888, test=0.449) total time=   0.8s\n",
      "[CV 3/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 3/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.885, test=0.467) total time=   1.0s\n",
      "[CV 4/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 4/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.887, test=0.428) total time=   0.8s\n",
      "[CV 5/5; 51/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150\n",
      "[CV 5/5; 51/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=150;, score=(train=0.887, test=0.437) total time=   1.0s\n",
      "[CV 1/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 1/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.824, test=0.439) total time=   0.3s\n",
      "[CV 2/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 2/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.830, test=0.436) total time=   0.2s\n",
      "[CV 3/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 3/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.833, test=0.460) total time=   0.2s\n",
      "[CV 4/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 4/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.841, test=0.431) total time=   0.2s\n",
      "[CV 5/5; 52/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50\n",
      "[CV 5/5; 52/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=50;, score=(train=0.825, test=0.450) total time=   0.2s\n",
      "[CV 1/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 1/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.837, test=0.436) total time=   0.5s\n",
      "[CV 2/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 2/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.845, test=0.451) total time=   0.5s\n",
      "[CV 3/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 3/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.846, test=0.445) total time=   0.5s\n",
      "[CV 4/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 4/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.847, test=0.454) total time=   0.5s\n",
      "[CV 5/5; 53/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100\n",
      "[CV 5/5; 53/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=100;, score=(train=0.841, test=0.450) total time=   0.5s\n",
      "[CV 1/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 1/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.838, test=0.452) total time=   0.9s\n",
      "[CV 2/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 2/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.846, test=0.447) total time=   0.9s\n",
      "[CV 3/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 3/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.859, test=0.485) total time=   0.8s\n",
      "[CV 4/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 4/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.859, test=0.439) total time=   0.8s\n",
      "[CV 5/5; 54/54] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150\n",
      "[CV 5/5; 54/54] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=15, rf__n_estimators=150;, score=(train=0.840, test=0.442) total time=   0.9s\n",
      "Selected Parameters: {'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 15, 'rf__n_estimators': 100}\n",
      "Train score: 0.89584748978712\n",
      "Test score: 0.3487091925338938\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#Saving the results\r\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_multi.p\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "pickle.dump(selected_params_rf_multi, open(path, \"wb\"))\r\n",
    "\r\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_rf_multi.csv\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "df_predicted_rf_multi.to_csv(path)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:4: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_multi.p'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtaining the optimal features and hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of selected features:\r\n",
    "\r\n",
    "Selected features:\r\n",
    "\r\n",
    "Selected hyperparameters:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "# Setting class value\r\n",
    "# Set final boundary slightly over 1 so 1's are included as well\r\n",
    "df_multi = df[df['perc_loss'].notnull()]\r\n",
    "classes = {0: [0, 0.3], 1: [0.3, 0.8], 2: [0.8, 1.1]}\r\n",
    "df_multi[\"class_value_multi\"] = df_multi[\"perc_loss\"].apply(\r\n",
    "    lambda x: determine_class(x, classes=classes)\r\n",
    ")\r\n",
    "\r\n",
    "# Setting for feature seleciton on full data set\r\n",
    "X = df_multi[features]\r\n",
    "y = df_multi[\"class_value_multi\"]\r\n",
    "\r\n",
    "# Setting train and test set for obtaining performance estimate\r\n",
    "df_train_list, df_test_list = splitting_train_test(df_multi)\r\n",
    "\r\n",
    "# Setting the XGBoost search grid\r\n",
    "xgb_search_space = [\r\n",
    "    {\r\n",
    "        \"estimator__learning_rate\": [0.1, 0.5, 1],\r\n",
    "        \"estimator__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"estimator__max_depth\": [6, 8],\r\n",
    "        \"estimator__reg_lambda\": [0.001, 0.1, 1],\r\n",
    "        \"estimator__n_estimators\": [100, 200],\r\n",
    "        \"estimator__colsample_bytree\": [0.5, 0.7],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "selected_features_xgb_multi, selected_params_xgb_multi_full = xgb_multi_features(\r\n",
    "    X=X,\r\n",
    "    y=y,\r\n",
    "    features=features,\r\n",
    "    num_class=len(classes),\r\n",
    "    search_space=xgb_search_space,\r\n",
    "    objective=\"multi:softmax\",\r\n",
    "    cv_splits=5,\r\n",
    "    min_features_to_select=1,\r\n",
    "    GS_score=\"f1_macro\",\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=50,\r\n",
    "    verbose=10,\r\n",
    ")\r\n",
    "\r\n",
    "print(\r\n",
    "    f\"Number of features selected in RF multiclass: {len(selected_features_xgb_multi)}\"\r\n",
    ")\r\n",
    "print(f\"Selected features RF multiclass: {selected_features_xgb_multi}\")\r\n",
    "print(f\"Selected Parameters in RF multiclass: {selected_params_xgb_multi_full}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5; 1/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[21:58:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 1/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.360, test=0.336) total time= 3.6min\n",
      "[CV 2/5; 1/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:02:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 1/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.375, test=0.315) total time= 3.6min\n",
      "[CV 3/5; 1/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:05:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 1/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.390, test=0.358) total time= 3.6min\n",
      "[CV 4/5; 1/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:09:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 1/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.380, test=0.317) total time= 3.5min\n",
      "[CV 5/5; 1/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:12:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 1/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=0.1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.373, test=0.320) total time= 3.6min\n",
      "[CV 1/5; 2/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[22:16:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 2/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.455) total time= 2.6min\n",
      "[CV 2/5; 2/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[22:19:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 2/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.443) total time= 2.4min\n",
      "[CV 3/5; 2/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[22:21:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 2/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.437) total time= 2.8min\n",
      "[CV 4/5; 2/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[22:24:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 2/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=0.999, test=0.391) total time= 2.8min\n",
      "[CV 5/5; 2/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1\n",
      "[22:27:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 2/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.1, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=1;, score=(train=1.000, test=0.457) total time= 2.8min\n",
      "[CV 1/5; 3/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:29:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 3/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.462, test=0.305) total time= 3.1min\n",
      "[CV 2/5; 3/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:32:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 3/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.612, test=0.389) total time= 3.0min\n",
      "[CV 3/5; 3/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:35:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 3/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.481, test=0.349) total time= 3.1min\n",
      "[CV 4/5; 3/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:38:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 3/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.609, test=0.349) total time= 3.0min\n",
      "[CV 5/5; 3/50] START estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:42:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:43:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 3/50] END estimator__colsample_bytree=0.5, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.604, test=0.336) total time= 3.1min\n",
      "[CV 1/5; 4/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[22:45:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 4/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.471) total time= 1.6min\n",
      "[CV 2/5; 4/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[22:46:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 4/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.423) total time= 1.8min\n",
      "[CV 3/5; 4/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[22:48:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 4/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.415) total time= 1.6min\n",
      "[CV 4/5; 4/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[22:50:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 4/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.435) total time= 1.6min\n",
      "[CV 5/5; 4/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001\n",
      "[22:51:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 4/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=1, estimator__max_depth=8, estimator__n_estimators=100, estimator__reg_lambda=0.001;, score=(train=1.000, test=0.424) total time= 1.5min\n",
      "[CV 1/5; 5/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:53:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 5/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.908, test=0.458) total time= 3.0min\n",
      "[CV 2/5; 5/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:56:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 5/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.914, test=0.402) total time= 3.0min\n",
      "[CV 3/5; 5/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[22:59:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:01:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 5/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.961, test=0.399) total time= 2.9min\n",
      "[CV 4/5; 5/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[23:02:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 5/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.902, test=0.411) total time= 2.9min\n",
      "[CV 5/5; 5/50] START estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[23:05:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 5/50] END estimator__colsample_bytree=0.5, estimator__gamma=0.1, estimator__learning_rate=0.1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.970, test=0.432) total time= 2.8min\n",
      "[CV 1/5; 6/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[23:07:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 6/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.936, test=0.463) total time= 1.4min\n",
      "[CV 2/5; 6/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[23:09:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 6/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.445, test=0.268) total time= 1.4min\n",
      "[CV 3/5; 6/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[23:10:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:11:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 6/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.953, test=0.420) total time= 1.4min\n",
      "[CV 4/5; 6/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[23:12:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 6/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.449, test=0.321) total time= 1.5min\n",
      "[CV 5/5; 6/50] START estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1\n",
      "[23:13:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:14:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 6/50] END estimator__colsample_bytree=0.7, estimator__gamma=0.5, estimator__learning_rate=0.5, estimator__max_depth=6, estimator__n_estimators=100, estimator__reg_lambda=1;, score=(train=0.462, test=0.343) total time= 1.5min\n",
      "[CV 1/5; 7/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[23:15:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 7/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.410, test=0.306) total time= 2.4min\n",
      "[CV 2/5; 7/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[23:17:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:17:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:18:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:19:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 7/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.582, test=0.351) total time= 2.4min\n",
      "[CV 3/5; 7/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[23:20:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:20:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 7/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.436, test=0.350) total time= 2.5min\n",
      "[CV 4/5; 7/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[23:22:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:22:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:23:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:24:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 7/50] END estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1;, score=(train=0.518, test=0.370) total time= 2.6min\n",
      "[CV 5/5; 7/50] START estimator__colsample_bytree=0.7, estimator__gamma=2, estimator__learning_rate=1, estimator__max_depth=6, estimator__n_estimators=200, estimator__reg_lambda=0.1\n",
      "[23:25:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:25:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtaining model performance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the selected features for XGB\r\n",
    "selected_features_xgb_multi = [\r\n",
    "    \"rice_area\",\r\n",
    "    \"mean_slope\",\r\n",
    "    \"mean_elevation_m\",\r\n",
    "    \"ruggedness_stdev\",\r\n",
    "    \"mean_ruggedness\",\r\n",
    "    \"slope_stdev\",\r\n",
    "    \"area_km2\",\r\n",
    "    \"poverty_perc\",\r\n",
    "    \"with_coast\",\r\n",
    "    \"coast_length\",\r\n",
    "    \"perimeter\",\r\n",
    "    \"glat\",\r\n",
    "    \"glon\",\r\n",
    "    \"coast_peri_ratio\",\r\n",
    "    \"rainfall_sum\",\r\n",
    "    \"rainfall_max\",\r\n",
    "    \"dis_track_min\",\r\n",
    "    \"vmax_sust\",\r\n",
    "]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the XGBoost search grid\r\n",
    "xgb_search_space = [\r\n",
    "    {\r\n",
    "        \"xgb__learning_rate\": [0.1, 0.5, 1],\r\n",
    "        \"xgb__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"xgb__max_depth\": [6, 8],\r\n",
    "        \"xgb__reg_lambda\": [0.001, 0.1, 1],\r\n",
    "        \"xgb__n_estimators\": [100, 200],\r\n",
    "        \"xgb__colsample_bytree\": [0.5, 0.7],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "df_predicted_xgb_multi, selected_params_xgb_multi = xgb_multi_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    num_class=len(classes),\r\n",
    "    features=selected_features_xgb_multi,\r\n",
    "    search_space=xgb_search_space,\r\n",
    "    stratK=True,\r\n",
    "    cv_splits=5,\r\n",
    "    objective=\"multi:softmax\",\r\n",
    "    GS_score=\"f1_macro\",\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=50,\r\n",
    "    verbose=10,\r\n",
    ")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Saving the results\r\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_xgb_multi.p\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "pickle.dump(selected_params_xgb_multi, open(path, \"wb\"))\r\n",
    "\r\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_xgb_multi.csv\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "df_predicted_xgb_multi.to_csv(path)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmark"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "# Random unweighted predictions\r\n",
    "df_predicted_random_multi = pd.DataFrame(columns=[\"year\", \"actual\", \"predicted\"])\r\n",
    "\r\n",
    "for i in range(len(df_train_list)):\r\n",
    "\r\n",
    "    train = df_train_list[i]\r\n",
    "    test = df_test_list[i]\r\n",
    "\r\n",
    "    y_train = train[\"class_value_multi\"]\r\n",
    "    y_test = test[\"class_value_multi\"]\r\n",
    "\r\n",
    "    y_pred_test = unweighted_random(y_train, y_test)\r\n",
    "    df_predicted_temp = pd.DataFrame(\r\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_pred_test}\r\n",
    "    )\r\n",
    "\r\n",
    "    df_predicted_random_multi = pd.concat(\r\n",
    "        [df_predicted_random_multi, df_predicted_temp]\r\n",
    "    )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "# Random Weighted Predictions\r\n",
    "df_predicted_random_weighted_multi = pd.DataFrame(\r\n",
    "    columns=[\"year\", \"actual\", \"predicted\"]\r\n",
    ")\r\n",
    "for i in range(len(df_train_list)):\r\n",
    "\r\n",
    "    train = df_train_list[i]\r\n",
    "    test = df_test_list[i]\r\n",
    "\r\n",
    "    y_train = train[\"class_value_multi\"]\r\n",
    "    y_test = test[\"class_value_multi\"]\r\n",
    "\r\n",
    "    y_pred_test = weighted_random(y_train, y_test)\r\n",
    "    df_predicted_temp = pd.DataFrame(\r\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_pred_test}\r\n",
    "    )\r\n",
    "\r\n",
    "    df_predicted_random_weighted_multi = pd.concat(\r\n",
    "        [df_predicted_random_weighted_multi, df_predicted_temp]\r\n",
    "    )\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "models = {\r\n",
    "    \"Random Forest\": df_predicted_rf_multi,\r\n",
    "    # \"XGBoost\": df_predicted_xgb_multi,\r\n",
    "    \"Random\": df_predicted_random_multi,\r\n",
    "    \"Weighted Random\": df_predicted_random_weighted_multi,\r\n",
    "}\r\n",
    "\r\n",
    "f1 = []\r\n",
    "precision = []\r\n",
    "recall = []\r\n",
    "\r\n",
    "# add 'list' if error\r\n",
    "for df_temp in models.values():\r\n",
    "    f1.append(f1_score(df_temp[\"actual\"], df_temp[\"predicted\"], average=\"macro\"))\r\n",
    "    precision.append(precision_score(df_temp[\"actual\"], df_temp[\"predicted\"], average=\"macro\"))\r\n",
    "    recall.append(recall_score(df_temp[\"actual\"], df_temp[\"predicted\"], average=\"macro\"))\r\n",
    "\r\n",
    "df_results_multi = pd.DataFrame(\r\n",
    "    {\"Models\": list(models.keys()), \"F1 score\": f1, \"Recall\": recall, \"Precision\": precision}\r\n",
    ")\r\n",
    "\r\n",
    "display(df_results_multi)\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.409386</td>\n",
       "      <td>0.410419</td>\n",
       "      <td>0.409806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>0.298415</td>\n",
       "      <td>0.330347</td>\n",
       "      <td>0.329676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weighted Random</td>\n",
       "      <td>0.335421</td>\n",
       "      <td>0.340306</td>\n",
       "      <td>0.339631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Models  F1 score    Recall  Precision\n",
       "0    Random Forest  0.409386  0.410419   0.409806\n",
       "1           Random  0.298415  0.330347   0.329676\n",
       "2  Weighted Random  0.335421  0.340306   0.339631"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the optimal model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "### Training the optimal model\r\n",
    "rf = RandomForestClassifier(\r\n",
    "    class_weight=\"balanced\",\r\n",
    "    n_estimators=50,\r\n",
    "    max_depth=None,\r\n",
    "    min_samples_leaf=3,\r\n",
    "    min_samples_split=15,\r\n",
    ")\r\n",
    "\r\n",
    "selected_features_rf_multi = [\r\n",
    "    \"mean_slope\",\r\n",
    "    \"mean_elevation_m\",\r\n",
    "    \"ruggedness_stdev\",\r\n",
    "    \"mean_ruggedness\",\r\n",
    "    \"slope_stdev\",\r\n",
    "    \"area_km2\",\r\n",
    "    \"poverty_perc\",\r\n",
    "    \"perimeter\",\r\n",
    "    \"glat\",\r\n",
    "    \"glon\",\r\n",
    "    \"rainfall_max_6h\",\r\n",
    "    \"rainfall_max_24h\",\r\n",
    "    \"dis_track_min\",\r\n",
    "    \"vmax\",\r\n",
    "]\r\n",
    "\r\n",
    "rf_fitted = rf.fit(X[selected_features_rf_multi], y)\r\n",
    "\r\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_multi_rf.sav\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "pickle.dump(rf_fitted, open(path, \"wb\"))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:31: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_multi_rf.sav'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression\r\n",
    "\r\n",
    "This sections contains the Regression models that are trained and tested to obtain the optimal model, hyperparameter settings and features. First the model is trained on the full dataset to obtain the optimal features followed by a model that obtains the performance estimate using Nested Cross Validation.\r\n",
    "\r\n",
    "\r\n",
    "- Performance metrics\r\n",
    "- Nested Cross Validation\r\n",
    "- Benchmark Models\r\n",
    "- Main finding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Full dataset for feature selection\r\n",
    "df_regr = df[df['perc_loss'].notnull()]\r\n",
    "\r\n",
    "X = df_regr[features]\r\n",
    "y = df_regr[\"perc_loss\"]\r\n",
    "\r\n",
    "# Setting the train and the test sets for obtaining performance estimate\r\n",
    "df_train_list, df_test_list = splitting_train_test(df_regr)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the optimal model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of selected features RF Regression: 12\r\n",
    "\r\n",
    "Selected features RF Regression:\r\n",
    "- mean_slope\r\n",
    "- mean_elevation_m\r\n",
    "- ruggedness_stdev\r\n",
    "- mean_ruggedness\r\n",
    "- area_km2\r\n",
    "- coast_length\r\n",
    "- poverty_perc\r\n",
    "- perimeter\r\n",
    "- glat\r\n",
    "- glon\r\n",
    "- coast_peri_ratio\r\n",
    "- rainfall_max_6h\r\n",
    "- rainfall_max_24h\r\n",
    "- dis_track_min\r\n",
    "- vmax\r\n",
    "\r\n",
    "\r\n",
    "Selected Parameters RF Regression: \r\n",
    "- max_depth = 20\r\n",
    "- min_samples_leaf = 1\r\n",
    "- min_samples_split = 8\r\n",
    "- n_estimators = 100\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#%% Setting input varialbes\r\n",
    "rf_search_space = [\r\n",
    "    {\r\n",
    "        \"estimator__n_estimators\": [100, 250],\r\n",
    "        \"estimator__max_depth\": [20, None],\r\n",
    "        \"estimator__min_samples_split\": [2, 8, 10],\r\n",
    "        \"estimator__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "(\r\n",
    "    selected_features_rf_regr,\r\n",
    "    selected_params_rf_regr_full,\r\n",
    ") = rf_regression_features(\r\n",
    "    X=X,\r\n",
    "    y=y,\r\n",
    "    features=features,\r\n",
    "    search_space=rf_search_space,\r\n",
    "    min_features_to_select=1,\r\n",
    "    cv_splits=5,\r\n",
    "    GS_score=\"neg_root_mean_squared_error\",\r\n",
    "    GS_randomized=False,\r\n",
    "    GS_n_iter=10,\r\n",
    "    verbose=10,\r\n",
    ")\r\n",
    "\r\n",
    "print(\r\n",
    "    f\"Number of selected features RF Regression {len(selected_features_rf_regr)}\"\r\n",
    ")\r\n",
    "print(f\"Selected features RF Regression: {selected_features_rf_regr}\")\r\n",
    "print(f\"Selected Parameters RF Regression: {selected_params_rf_regr_full}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 1/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.123, test=-0.324) total time= 1.9min\n",
      "[CV 2/5; 1/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 1/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.121, test=-0.307) total time= 2.2min\n",
      "[CV 3/5; 1/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 1/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.123, test=-0.315) total time= 1.9min\n",
      "[CV 4/5; 1/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 1/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.122, test=-0.321) total time= 2.0min\n",
      "[CV 5/5; 1/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 1/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.121, test=-0.328) total time= 2.1min\n",
      "[CV 1/5; 2/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 2/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.122, test=-0.321) total time= 4.5min\n",
      "[CV 2/5; 2/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 2/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.121, test=-0.314) total time= 5.2min\n",
      "[CV 3/5; 2/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 2/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.121, test=-0.314) total time= 4.5min\n",
      "[CV 4/5; 2/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 2/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.120, test=-0.321) total time= 5.1min\n",
      "[CV 5/5; 2/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 2/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.120, test=-0.326) total time= 5.3min\n",
      "[CV 1/5; 3/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 3/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.166, test=-0.319) total time= 1.8min\n",
      "[CV 2/5; 3/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 3/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.167, test=-0.308) total time= 1.9min\n",
      "[CV 3/5; 3/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 3/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.172, test=-0.308) total time= 2.0min\n",
      "[CV 4/5; 3/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 3/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.165, test=-0.319) total time= 1.8min\n",
      "[CV 5/5; 3/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 3/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.166, test=-0.322) total time= 2.0min\n",
      "[CV 1/5; 4/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 4/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.163, test=-0.319) total time= 4.3min\n",
      "[CV 2/5; 4/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 4/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.168, test=-0.309) total time= 4.9min\n",
      "[CV 3/5; 4/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 4/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.170, test=-0.306) total time= 4.9min\n",
      "[CV 4/5; 4/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 4/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.163, test=-0.321) total time= 5.1min\n",
      "[CV 5/5; 4/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 4/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.162, test=-0.325) total time= 4.6min\n",
      "[CV 1/5; 5/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 5/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.177, test=-0.318) total time= 1.7min\n",
      "[CV 2/5; 5/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 5/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.182, test=-0.308) total time= 1.9min\n",
      "[CV 3/5; 5/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 5/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.177, test=-0.313) total time= 1.7min\n",
      "[CV 4/5; 5/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 5/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.178, test=-0.320) total time= 1.8min\n",
      "[CV 5/5; 5/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 5/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.174, test=-0.326) total time= 1.6min\n",
      "[CV 1/5; 6/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 6/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.176, test=-0.318) total time= 4.3min\n",
      "[CV 2/5; 6/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 6/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.180, test=-0.311) total time= 4.7min\n",
      "[CV 3/5; 6/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 6/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.183, test=-0.308) total time= 4.8min\n",
      "[CV 4/5; 6/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 6/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.176, test=-0.321) total time= 4.4min\n",
      "[CV 5/5; 6/36] START estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 6/36] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.176, test=-0.325) total time= 4.6min\n",
      "[CV 1/5; 7/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 7/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.170, test=-0.320) total time= 1.7min\n",
      "[CV 2/5; 7/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 7/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.171, test=-0.314) total time= 1.7min\n",
      "[CV 3/5; 7/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 7/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.172, test=-0.312) total time= 1.6min\n",
      "[CV 4/5; 7/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 7/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.170, test=-0.320) total time= 1.7min\n",
      "[CV 5/5; 7/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 7/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.169, test=-0.327) total time= 1.6min\n",
      "[CV 1/5; 8/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 8/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.170, test=-0.317) total time= 4.3min\n",
      "[CV 2/5; 8/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 8/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.171, test=-0.313) total time= 4.2min\n",
      "[CV 3/5; 8/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 8/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.170, test=-0.312) total time= 3.8min\n",
      "[CV 4/5; 8/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 8/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.169, test=-0.319) total time= 4.2min\n",
      "[CV 5/5; 8/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 8/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.168, test=-0.326) total time= 3.9min\n",
      "[CV 1/5; 9/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 9/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.182, test=-0.318) total time= 1.6min\n",
      "[CV 2/5; 9/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 9/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.182, test=-0.314) total time= 1.6min\n",
      "[CV 3/5; 9/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 9/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.184, test=-0.311) total time= 1.6min\n",
      "[CV 4/5; 9/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 9/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.182, test=-0.321) total time= 1.6min\n",
      "[CV 5/5; 9/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 9/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.178, test=-0.325) total time= 1.6min\n",
      "[CV 1/5; 10/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 10/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.181, test=-0.317) total time= 4.0min\n",
      "[CV 2/5; 10/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 10/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.184, test=-0.309) total time= 4.4min\n",
      "[CV 3/5; 10/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 10/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.183, test=-0.311) total time= 4.3min\n",
      "[CV 4/5; 10/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 10/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.182, test=-0.317) total time= 4.3min\n",
      "[CV 5/5; 10/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 10/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.180, test=-0.327) total time= 4.1min\n",
      "[CV 1/5; 11/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 11/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.194, test=-0.318) total time= 1.6min\n",
      "[CV 2/5; 11/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 11/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.194, test=-0.311) total time= 1.7min\n",
      "[CV 3/5; 11/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 11/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.193, test=-0.312) total time= 1.6min\n",
      "[CV 4/5; 11/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 11/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.193, test=-0.319) total time= 1.7min\n",
      "[CV 5/5; 11/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 11/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.189, test=-0.326) total time= 1.6min\n",
      "[CV 1/5; 12/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 12/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.192, test=-0.318) total time= 4.0min\n",
      "[CV 2/5; 12/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 12/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.195, test=-0.309) total time= 4.3min\n",
      "[CV 3/5; 12/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 12/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.194, test=-0.310) total time= 4.2min\n",
      "[CV 4/5; 12/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 12/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.192, test=-0.319) total time= 4.1min\n",
      "[CV 5/5; 12/36] START estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 12/36] END estimator__max_depth=20, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.192, test=-0.325) total time= 4.3min\n",
      "[CV 1/5; 13/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 13/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.206, test=-0.317) total time= 1.6min\n",
      "[CV 2/5; 13/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 13/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.206, test=-0.312) total time= 1.4min\n",
      "[CV 3/5; 13/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 13/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.209, test=-0.311) total time= 1.6min\n",
      "[CV 4/5; 13/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 13/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.206, test=-0.319) total time= 1.6min\n",
      "[CV 5/5; 13/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 13/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.206, test=-0.327) total time= 1.6min\n",
      "[CV 1/5; 14/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 14/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.205, test=-0.316) total time= 3.8min\n",
      "[CV 2/5; 14/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 14/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.207, test=-0.309) total time= 3.9min\n",
      "[CV 3/5; 14/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 14/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.205, test=-0.310) total time= 3.8min\n",
      "[CV 4/5; 14/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 14/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.211, test=-0.317) total time= 4.1min\n",
      "[CV 5/5; 14/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 14/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.203, test=-0.325) total time= 3.9min\n",
      "[CV 1/5; 15/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 15/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.207, test=-0.317) total time= 1.6min\n",
      "[CV 2/5; 15/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 15/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.206, test=-0.311) total time= 1.4min\n",
      "[CV 3/5; 15/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 15/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.205, test=-0.312) total time= 1.4min\n",
      "[CV 4/5; 15/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 15/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.208, test=-0.318) total time= 1.6min\n",
      "[CV 5/5; 15/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 15/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.205, test=-0.326) total time= 1.6min\n",
      "[CV 1/5; 16/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 16/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.204, test=-0.317) total time= 3.8min\n",
      "[CV 2/5; 16/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 16/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.206, test=-0.310) total time= 3.8min\n",
      "[CV 3/5; 16/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 16/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.206, test=-0.310) total time= 3.9min\n",
      "[CV 4/5; 16/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 16/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.203, test=-0.320) total time= 3.6min\n",
      "[CV 5/5; 16/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 16/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.202, test=-0.325) total time= 3.8min\n",
      "[CV 1/5; 17/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 17/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.205, test=-0.317) total time= 1.5min\n",
      "[CV 2/5; 17/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 17/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.209, test=-0.309) total time= 1.6min\n",
      "[CV 3/5; 17/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 17/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.207, test=-0.312) total time= 1.4min\n",
      "[CV 4/5; 17/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 17/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.209, test=-0.316) total time= 1.6min\n",
      "[CV 5/5; 17/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 17/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.203, test=-0.326) total time= 1.5min\n",
      "[CV 1/5; 18/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 18/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.204, test=-0.317) total time= 3.6min\n",
      "[CV 2/5; 18/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 18/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.205, test=-0.311) total time= 3.5min\n",
      "[CV 3/5; 18/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 18/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.205, test=-0.312) total time= 4.9min\n",
      "[CV 4/5; 18/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 18/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.204, test=-0.319) total time= 6.9min\n",
      "[CV 5/5; 18/36] START estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 18/36] END estimator__max_depth=20, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.202, test=-0.325) total time= 8.8min\n",
      "[CV 1/5; 19/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 19/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.120, test=-0.320) total time= 5.3min\n",
      "[CV 2/5; 19/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 19/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.118, test=-0.313) total time= 2.6min\n",
      "[CV 3/5; 19/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 19/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.121, test=-0.315) total time= 1.7min\n",
      "[CV 4/5; 19/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 19/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.120, test=-0.322) total time= 1.6min\n",
      "[CV 5/5; 19/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 19/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.118, test=-0.328) total time= 1.9min\n",
      "[CV 1/5; 20/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 20/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.118, test=-0.322) total time= 4.6min\n",
      "[CV 2/5; 20/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 20/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.116, test=-0.311) total time= 5.5min\n",
      "[CV 3/5; 20/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 20/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.117, test=-0.309) total time= 5.2min\n",
      "[CV 4/5; 20/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 20/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.119, test=-0.318) total time= 9.9min\n",
      "[CV 5/5; 20/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 20/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.118, test=-0.329) total time= 5.2min\n",
      "[CV 1/5; 21/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 21/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.164, test=-0.318) total time= 1.7min\n",
      "[CV 2/5; 21/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 21/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.165, test=-0.313) total time= 1.8min\n",
      "[CV 3/5; 21/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 21/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.164, test=-0.314) total time= 1.7min\n",
      "[CV 4/5; 21/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 21/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.163, test=-0.321) total time= 2.1min\n",
      "[CV 5/5; 21/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 21/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.162, test=-0.327) total time= 2.6min\n",
      "[CV 1/5; 22/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 22/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.163, test=-0.318) total time= 6.4min\n",
      "[CV 2/5; 22/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 22/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.166, test=-0.309) total time= 6.9min\n",
      "[CV 3/5; 22/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 22/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.169, test=-0.306) total time= 7.4min\n",
      "[CV 4/5; 22/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 22/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.162, test=-0.322) total time= 6.0min\n",
      "[CV 5/5; 22/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 22/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.161, test=-0.326) total time= 7.2min\n",
      "[CV 1/5; 23/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 23/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.176, test=-0.321) total time= 1.9min\n",
      "[CV 2/5; 23/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 23/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.176, test=-0.313) total time= 1.7min\n",
      "[CV 3/5; 23/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 23/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.177, test=-0.313) total time= 1.9min\n",
      "[CV 4/5; 23/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 23/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.175, test=-0.322) total time= 1.7min\n",
      "[CV 5/5; 23/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 23/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.174, test=-0.326) total time= 1.9min\n",
      "[CV 1/5; 24/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 24/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.174, test=-0.320) total time= 4.0min\n",
      "[CV 2/5; 24/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 24/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.180, test=-0.308) total time= 5.1min\n",
      "[CV 3/5; 24/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 24/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.176, test=-0.314) total time= 4.8min\n",
      "[CV 4/5; 24/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 24/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.176, test=-0.320) total time= 4.6min\n",
      "[CV 5/5; 24/36] START estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 24/36] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.175, test=-0.325) total time= 4.8min\n",
      "[CV 1/5; 25/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 25/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.171, test=-0.318) total time= 1.8min\n",
      "[CV 2/5; 25/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 25/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.170, test=-0.314) total time= 1.8min\n",
      "[CV 3/5; 25/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 25/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.172, test=-0.313) total time= 1.9min\n",
      "[CV 4/5; 25/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 25/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.172, test=-0.320) total time= 2.0min\n",
      "[CV 5/5; 25/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 25/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.169, test=-0.329) total time= 1.8min\n",
      "[CV 1/5; 26/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 26/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.169, test=-0.319) total time= 4.5min\n",
      "[CV 2/5; 26/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 26/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.171, test=-0.310) total time= 4.2min\n",
      "[CV 3/5; 26/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 26/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.179, test=-0.304) total time= 5.2min\n",
      "[CV 4/5; 26/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 26/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.169, test=-0.319) total time= 5.0min\n",
      "[CV 5/5; 26/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 26/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.167, test=-0.327) total time= 4.8min\n",
      "[CV 1/5; 27/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 27/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.182, test=-0.317) total time= 1.9min\n",
      "[CV 2/5; 27/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 27/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.182, test=-0.313) total time= 1.6min\n",
      "[CV 3/5; 27/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 27/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.182, test=-0.312) total time= 1.9min\n",
      "[CV 4/5; 27/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 27/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.183, test=-0.319) total time= 2.4min\n",
      "[CV 5/5; 27/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 27/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.180, test=-0.326) total time= 2.0min\n",
      "[CV 1/5; 28/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 28/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.180, test=-0.318) total time= 5.1min\n",
      "[CV 2/5; 28/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 28/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.182, test=-0.311) total time= 4.6min\n",
      "[CV 3/5; 28/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 28/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.182, test=-0.312) total time= 4.8min\n",
      "[CV 4/5; 28/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 28/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.180, test=-0.320) total time= 4.4min\n",
      "[CV 5/5; 28/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 28/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.181, test=-0.325) total time= 5.2min\n",
      "[CV 1/5; 29/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 29/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.193, test=-0.318) total time= 1.9min\n",
      "[CV 2/5; 29/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 29/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.195, test=-0.311) total time= 2.0min\n",
      "[CV 3/5; 29/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 29/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.201, test=-0.306) total time= 1.8min\n",
      "[CV 4/5; 29/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 29/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.193, test=-0.319) total time= 1.7min\n",
      "[CV 5/5; 29/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 29/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.190, test=-0.327) total time= 1.6min\n",
      "[CV 1/5; 30/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 30/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.191, test=-0.317) total time= 3.9min\n",
      "[CV 2/5; 30/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 30/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.192, test=-0.310) total time= 4.3min\n",
      "[CV 3/5; 30/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 30/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.191, test=-0.312) total time= 3.8min\n",
      "[CV 4/5; 30/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 30/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.191, test=-0.319) total time= 4.0min\n",
      "[CV 5/5; 30/36] START estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 30/36] END estimator__max_depth=None, estimator__min_samples_leaf=3, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.191, test=-0.326) total time= 4.1min\n",
      "[CV 1/5; 31/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 1/5; 31/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.205, test=-0.318) total time= 1.5min\n",
      "[CV 2/5; 31/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 2/5; 31/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.206, test=-0.312) total time= 1.5min\n",
      "[CV 3/5; 31/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 3/5; 31/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.215, test=-0.307) total time= 1.6min\n",
      "[CV 4/5; 31/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 4/5; 31/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.205, test=-0.319) total time= 1.6min\n",
      "[CV 5/5; 31/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100\n",
      "[CV 5/5; 31/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=100;, score=(train=-0.205, test=-0.326) total time= 1.6min\n",
      "[CV 1/5; 32/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 1/5; 32/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.204, test=-0.316) total time= 3.6min\n",
      "[CV 2/5; 32/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 2/5; 32/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.211, test=-0.305) total time= 4.1min\n",
      "[CV 3/5; 32/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 3/5; 32/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.204, test=-0.312) total time= 4.1min\n",
      "[CV 4/5; 32/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 4/5; 32/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.209, test=-0.318) total time= 5.1min\n",
      "[CV 5/5; 32/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250\n",
      "[CV 5/5; 32/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=2, estimator__n_estimators=250;, score=(train=-0.203, test=-0.325) total time= 4.8min\n",
      "[CV 1/5; 33/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 1/5; 33/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.204, test=-0.317) total time= 1.9min\n",
      "[CV 2/5; 33/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 2/5; 33/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.206, test=-0.311) total time= 1.9min\n",
      "[CV 3/5; 33/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 3/5; 33/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.207, test=-0.311) total time= 1.9min\n",
      "[CV 4/5; 33/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 4/5; 33/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.213, test=-0.315) total time= 2.0min\n",
      "[CV 5/5; 33/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100\n",
      "[CV 5/5; 33/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=100;, score=(train=-0.203, test=-0.327) total time= 1.7min\n",
      "[CV 1/5; 34/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 1/5; 34/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.205, test=-0.317) total time= 4.9min\n",
      "[CV 2/5; 34/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 2/5; 34/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.208, test=-0.310) total time= 5.2min\n",
      "[CV 3/5; 34/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 3/5; 34/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.204, test=-0.312) total time= 4.7min\n",
      "[CV 4/5; 34/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 4/5; 34/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.209, test=-0.316) total time= 5.0min\n",
      "[CV 5/5; 34/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250\n",
      "[CV 5/5; 34/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=8, estimator__n_estimators=250;, score=(train=-0.202, test=-0.324) total time= 4.2min\n",
      "[CV 1/5; 35/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 1/5; 35/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.207, test=-0.316) total time= 2.0min\n",
      "[CV 2/5; 35/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 2/5; 35/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.213, test=-0.307) total time= 2.1min\n",
      "[CV 3/5; 35/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 3/5; 35/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.207, test=-0.309) total time= 2.0min\n",
      "[CV 4/5; 35/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 4/5; 35/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.205, test=-0.319) total time= 1.9min\n",
      "[CV 5/5; 35/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100\n",
      "[CV 5/5; 35/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=100;, score=(train=-0.203, test=-0.325) total time= 1.8min\n",
      "[CV 1/5; 36/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 1/5; 36/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.205, test=-0.315) total time= 4.8min\n",
      "[CV 2/5; 36/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 2/5; 36/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.206, test=-0.310) total time= 5.0min\n",
      "[CV 3/5; 36/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 3/5; 36/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.205, test=-0.312) total time= 4.0min\n",
      "[CV 4/5; 36/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 4/5; 36/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.207, test=-0.318) total time= 3.9min\n",
      "[CV 5/5; 36/36] START estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250\n",
      "[CV 5/5; 36/36] END estimator__max_depth=None, estimator__min_samples_leaf=5, estimator__min_samples_split=10, estimator__n_estimators=250;, score=(train=-0.204, test=-0.326) total time= 4.1min\n",
      "Number of selected features RF Regression 15\n",
      "Selected features RF Regression: ['mean_slope', 'mean_elevation_m', 'ruggedness_stdev', 'mean_ruggedness', 'area_km2', 'poverty_perc', 'coast_length', 'perimeter', 'glat', 'glon', 'coast_peri_ratio', 'rainfall_max_6h', 'rainfall_max_24h', 'dis_track_min', 'vmax']\n",
      "Selected Parameters RF Regression: {'estimator__max_depth': 20, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 8, 'estimator__n_estimators': 100}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtaining the performance estimate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Based on output previous cell\r\n",
    "selected_features_rf_regr = [\r\n",
    "    \"rice_area\",\r\n",
    "    \"mean_slope\",\r\n",
    "    \"mean_elevation_m\",\r\n",
    "    \"ruggedness_stdev\",\r\n",
    "    \"mean_ruggedness\",\r\n",
    "    \"slope_stdev\",\r\n",
    "    \"area_km2\",\r\n",
    "    \"poverty_perc\",\r\n",
    "    \"with_coast\",\r\n",
    "    \"coast_length\",\r\n",
    "    \"perimeter\",\r\n",
    "    \"glat\",\r\n",
    "    \"glon\",\r\n",
    "    \"coast_peri_ratio\",\r\n",
    "    \"rainfall_sum\",\r\n",
    "    \"rainfall_max\",\r\n",
    "    \"dis_track_min\",\r\n",
    "    \"vmax_sust\",\r\n",
    "]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "#%% Setting input varialbes\r\n",
    "rf_search_space = [\r\n",
    "    {\r\n",
    "        \"rf__n_estimators\": [100, 250],\r\n",
    "        \"rf__max_depth\": [20, None],\r\n",
    "        \"rf__min_samples_split\": [2, 8, 10],\r\n",
    "        \"rf__min_samples_leaf\": [1, 3, 5],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "df_predicted_rf_regr, selected_params_rf_regr = rf_regression_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    features=selected_features_rf_regr,\r\n",
    "    search_space=rf_search_space,\r\n",
    "    cv_splits=5,\r\n",
    "    GS_score=\"neg_root_mean_squared_error\",\r\n",
    "    GS_randomized=False,\r\n",
    "    GS_n_iter=10,\r\n",
    "    verbose=10,\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running for 1 out of a total of 5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.127, test=-0.333) total time=   2.1s\n",
      "[CV 2/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.126, test=-0.326) total time=   2.1s\n",
      "[CV 3/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.124, test=-0.342) total time=   2.2s\n",
      "[CV 4/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.124, test=-0.324) total time=   1.8s\n",
      "[CV 5/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.126, test=-0.334) total time=   1.6s\n",
      "[CV 1/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.124, test=-0.328) total time=   4.1s\n",
      "[CV 2/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.123, test=-0.328) total time=   3.7s\n",
      "[CV 3/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.122, test=-0.343) total time=   3.7s\n",
      "[CV 4/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.123, test=-0.325) total time=   3.4s\n",
      "[CV 5/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.333) total time=   3.6s\n",
      "[CV 1/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.168, test=-0.327) total time=   1.1s\n",
      "[CV 2/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.168, test=-0.326) total time=   1.1s\n",
      "[CV 3/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.169, test=-0.343) total time=   1.1s\n",
      "[CV 4/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.326) total time=   1.3s\n",
      "[CV 5/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.171, test=-0.334) total time=   1.4s\n",
      "[CV 1/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.168, test=-0.329) total time=   3.6s\n",
      "[CV 2/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.327) total time=   2.9s\n",
      "[CV 3/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.166, test=-0.342) total time=   3.4s\n",
      "[CV 4/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.169, test=-0.323) total time=   2.9s\n",
      "[CV 5/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.169, test=-0.330) total time=   3.7s\n",
      "[CV 1/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.182, test=-0.329) total time=   1.2s\n",
      "[CV 2/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.181, test=-0.329) total time=   1.4s\n",
      "[CV 3/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.180, test=-0.342) total time=   1.0s\n",
      "[CV 4/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.325) total time=   1.2s\n",
      "[CV 5/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.185, test=-0.331) total time=   1.1s\n",
      "[CV 1/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.329) total time=   3.2s\n",
      "[CV 2/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.180, test=-0.327) total time=   2.9s\n",
      "[CV 3/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.180, test=-0.341) total time=   3.1s\n",
      "[CV 4/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.324) total time=   2.7s\n",
      "[CV 5/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.182, test=-0.329) total time=   3.4s\n",
      "[CV 1/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.324) total time=   1.2s\n",
      "[CV 2/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.176, test=-0.327) total time=   1.3s\n",
      "[CV 3/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.173, test=-0.336) total time=   1.1s\n",
      "[CV 4/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.176, test=-0.323) total time=   1.1s\n",
      "[CV 5/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.177, test=-0.332) total time=   1.3s\n",
      "[CV 1/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.326) total time=   3.4s\n",
      "[CV 2/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.328) total time=   2.8s\n",
      "[CV 3/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.172, test=-0.341) total time=   2.9s\n",
      "[CV 4/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.175, test=-0.323) total time=   3.7s\n",
      "[CV 5/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.176, test=-0.330) total time=   3.3s\n",
      "[CV 1/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.187, test=-0.329) total time=   1.3s\n",
      "[CV 2/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.186, test=-0.329) total time=   1.1s\n",
      "[CV 3/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.185, test=-0.341) total time=   1.4s\n",
      "[CV 4/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.186, test=-0.323) total time=   1.1s\n",
      "[CV 5/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.188, test=-0.330) total time=   1.2s\n",
      "[CV 1/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.187, test=-0.326) total time=   3.7s\n",
      "[CV 2/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.326) total time=   3.0s\n",
      "[CV 3/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.339) total time=   2.7s\n",
      "[CV 4/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.186, test=-0.326) total time=   3.4s\n",
      "[CV 5/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.187, test=-0.329) total time=   6.2s\n",
      "[CV 1/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.200, test=-0.329) total time=   2.6s\n",
      "[CV 2/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.197, test=-0.323) total time=   1.8s\n",
      "[CV 3/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.197, test=-0.338) total time=   1.2s\n",
      "[CV 4/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.199, test=-0.326) total time=   1.3s\n",
      "[CV 5/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.199, test=-0.328) total time=   1.4s\n",
      "[CV 1/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.197, test=-0.325) total time=   3.3s\n",
      "[CV 2/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.195, test=-0.325) total time=   2.6s\n",
      "[CV 3/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.195, test=-0.339) total time=   3.1s\n",
      "[CV 4/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.197, test=-0.324) total time=   2.8s\n",
      "[CV 5/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.198, test=-0.328) total time=   2.9s\n",
      "[CV 1/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.212, test=-0.328) total time=   1.0s\n",
      "[CV 2/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.211, test=-0.327) total time=   0.9s\n",
      "[CV 3/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.210, test=-0.338) total time=   0.9s\n",
      "[CV 4/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.213, test=-0.325) total time=   0.9s\n",
      "[CV 5/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.213, test=-0.329) total time=   1.0s\n",
      "[CV 1/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.211, test=-0.326) total time=   3.3s\n",
      "[CV 2/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.210, test=-0.326) total time=   3.9s\n",
      "[CV 3/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.209, test=-0.339) total time=   2.5s\n",
      "[CV 4/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.211, test=-0.324) total time=   3.0s\n",
      "[CV 5/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.212, test=-0.330) total time=   3.0s\n",
      "[CV 1/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.211, test=-0.329) total time=   1.3s\n",
      "[CV 2/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.210, test=-0.325) total time=   1.1s\n",
      "[CV 3/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.210, test=-0.334) total time=   1.0s\n",
      "[CV 4/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.210, test=-0.325) total time=   1.0s\n",
      "[CV 5/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.213, test=-0.330) total time=   1.0s\n",
      "[CV 1/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.211, test=-0.326) total time=   2.8s\n",
      "[CV 2/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.210, test=-0.326) total time=   2.9s\n",
      "[CV 3/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.209, test=-0.340) total time=   2.8s\n",
      "[CV 4/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.211, test=-0.323) total time=   2.6s\n",
      "[CV 5/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.212, test=-0.327) total time=   2.9s\n",
      "[CV 1/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.212, test=-0.327) total time=   1.0s\n",
      "[CV 2/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.210, test=-0.325) total time=   1.0s\n",
      "[CV 3/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.209, test=-0.340) total time=   0.9s\n",
      "[CV 4/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.213, test=-0.325) total time=   1.0s\n",
      "[CV 5/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.212, test=-0.328) total time=   1.0s\n",
      "[CV 1/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.211, test=-0.327) total time=   2.8s\n",
      "[CV 2/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.209, test=-0.324) total time=   3.1s\n",
      "[CV 3/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.209, test=-0.337) total time=   2.9s\n",
      "[CV 4/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.210, test=-0.323) total time=   3.6s\n",
      "[CV 5/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.213, test=-0.328) total time=   2.5s\n",
      "[CV 1/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.124, test=-0.329) total time=   1.5s\n",
      "[CV 2/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.126, test=-0.328) total time=   1.3s\n",
      "[CV 3/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.122, test=-0.343) total time=   1.2s\n",
      "[CV 4/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.123, test=-0.324) total time=   1.4s\n",
      "[CV 5/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.125, test=-0.334) total time=   1.2s\n",
      "[CV 1/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.123, test=-0.330) total time=   3.6s\n",
      "[CV 2/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.124, test=-0.326) total time=   3.8s\n",
      "[CV 3/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.122, test=-0.344) total time=   3.3s\n",
      "[CV 4/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.124, test=-0.325) total time=   3.3s\n",
      "[CV 5/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.124, test=-0.333) total time=   3.3s\n",
      "[CV 1/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.329) total time=   1.2s\n",
      "[CV 2/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.167, test=-0.329) total time=   1.0s\n",
      "[CV 3/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.168, test=-0.342) total time=   1.1s\n",
      "[CV 4/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.169, test=-0.323) total time=   1.2s\n",
      "[CV 5/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.334) total time=   1.1s\n",
      "[CV 1/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.328) total time=   3.0s\n",
      "[CV 2/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.328) total time=   2.8s\n",
      "[CV 3/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.340) total time=   2.8s\n",
      "[CV 4/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.322) total time=   3.0s\n",
      "[CV 5/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.169, test=-0.330) total time=   3.0s\n",
      "[CV 1/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.329) total time=   1.0s\n",
      "[CV 2/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.327) total time=   1.0s\n",
      "[CV 3/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.181, test=-0.343) total time=   1.0s\n",
      "[CV 4/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.182, test=-0.327) total time=   1.0s\n",
      "[CV 5/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.332) total time=   1.0s\n",
      "[CV 1/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.328) total time=   2.8s\n",
      "[CV 2/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.326) total time=   2.9s\n",
      "[CV 3/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.180, test=-0.341) total time=   2.9s\n",
      "[CV 4/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.182, test=-0.324) total time=   2.7s\n",
      "[CV 5/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.182, test=-0.330) total time=   3.0s\n",
      "[CV 1/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.174, test=-0.329) total time=   1.0s\n",
      "[CV 2/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.174, test=-0.327) total time=   1.2s\n",
      "[CV 3/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.342) total time=   1.2s\n",
      "[CV 4/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.176, test=-0.326) total time=   1.1s\n",
      "[CV 5/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.177, test=-0.331) total time=   1.0s\n",
      "[CV 1/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.175, test=-0.326) total time=   2.8s\n",
      "[CV 2/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.325) total time=   2.7s\n",
      "[CV 3/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.173, test=-0.340) total time=   2.9s\n",
      "[CV 4/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.323) total time=   2.7s\n",
      "[CV 5/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.175, test=-0.328) total time=   2.9s\n",
      "[CV 1/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.188, test=-0.326) total time=   1.0s\n",
      "[CV 2/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.186, test=-0.326) total time=   1.1s\n",
      "[CV 3/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.187, test=-0.338) total time=   1.0s\n",
      "[CV 4/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.188, test=-0.324) total time=   1.0s\n",
      "[CV 5/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.189, test=-0.330) total time=   1.0s\n",
      "[CV 1/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.186, test=-0.325) total time=   2.7s\n",
      "[CV 2/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.186, test=-0.324) total time=   2.5s\n",
      "[CV 3/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.184, test=-0.339) total time=   2.7s\n",
      "[CV 4/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.187, test=-0.324) total time=   3.0s\n",
      "[CV 5/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.187, test=-0.327) total time=   2.8s\n",
      "[CV 1/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.197, test=-0.324) total time=   1.0s\n",
      "[CV 2/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.197, test=-0.329) total time=   0.9s\n",
      "[CV 3/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.197, test=-0.338) total time=   0.9s\n",
      "[CV 4/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.198, test=-0.323) total time=   0.9s\n",
      "[CV 5/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.199, test=-0.331) total time=   1.0s\n",
      "[CV 1/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.197, test=-0.328) total time=   2.6s\n",
      "[CV 2/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.197, test=-0.326) total time=   2.7s\n",
      "[CV 3/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.196, test=-0.338) total time=   3.9s\n",
      "[CV 4/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.197, test=-0.324) total time=   2.8s\n",
      "[CV 5/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.199, test=-0.326) total time=   3.0s\n",
      "[CV 1/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.211, test=-0.326) total time=   1.3s\n",
      "[CV 2/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.212, test=-0.324) total time=   0.9s\n",
      "[CV 3/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.210, test=-0.340) total time=   1.0s\n",
      "[CV 4/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.211, test=-0.322) total time=   1.1s\n",
      "[CV 5/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.214, test=-0.329) total time=   0.9s\n",
      "[CV 1/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.211, test=-0.327) total time=   2.6s\n",
      "[CV 2/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.210, test=-0.327) total time=   2.8s\n",
      "[CV 3/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.210, test=-0.339) total time=   2.6s\n",
      "[CV 4/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.211, test=-0.325) total time=   2.5s\n",
      "[CV 5/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.213, test=-0.327) total time=   2.4s\n",
      "[CV 1/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.212, test=-0.324) total time=   1.0s\n",
      "[CV 2/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.211, test=-0.326) total time=   1.0s\n",
      "[CV 3/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.209, test=-0.340) total time=   1.3s\n",
      "[CV 4/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.213, test=-0.325) total time=   1.5s\n",
      "[CV 5/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.214, test=-0.328) total time=   1.2s\n",
      "[CV 1/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.211, test=-0.327) total time=   4.0s\n",
      "[CV 2/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.210, test=-0.326) total time=   2.6s\n",
      "[CV 3/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.210, test=-0.338) total time=   2.6s\n",
      "[CV 4/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.211, test=-0.325) total time=   2.9s\n",
      "[CV 5/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.212, test=-0.326) total time=   2.8s\n",
      "[CV 1/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.212, test=-0.325) total time=   1.0s\n",
      "[CV 2/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.210, test=-0.328) total time=   0.9s\n",
      "[CV 3/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.209, test=-0.337) total time=   0.9s\n",
      "[CV 4/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.211, test=-0.325) total time=   0.9s\n",
      "[CV 5/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.212, test=-0.326) total time=   0.9s\n",
      "[CV 1/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.211, test=-0.324) total time=   2.6s\n",
      "[CV 2/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.210, test=-0.325) total time=   2.5s\n",
      "[CV 3/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.209, test=-0.339) total time=   2.8s\n",
      "[CV 4/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.211, test=-0.324) total time=   2.6s\n",
      "[CV 5/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.212, test=-0.330) total time=   2.5s\n",
      "Selected Parameters {'rf__max_depth': 20, 'rf__min_samples_leaf': 5, 'rf__min_samples_split': 10, 'rf__n_estimators': 250}\n",
      "Train score: 0.17167425228825647\n",
      "Test score: 0.27640752025694054\n",
      "Running for 2 out of a total of 5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.124, test=-0.335) total time=   1.9s\n",
      "[CV 2/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.124, test=-0.344) total time=   1.8s\n",
      "[CV 3/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.126, test=-0.324) total time=   1.9s\n",
      "[CV 4/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.126, test=-0.339) total time=   1.9s\n",
      "[CV 5/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.123, test=-0.329) total time=   1.7s\n",
      "[CV 1/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.123, test=-0.334) total time=   5.4s\n",
      "[CV 2/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.122, test=-0.340) total time=   5.8s\n",
      "[CV 3/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.124, test=-0.321) total time=   4.9s\n",
      "[CV 4/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.124, test=-0.339) total time=   5.2s\n",
      "[CV 5/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.123, test=-0.327) total time=   4.7s\n",
      "[CV 1/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.336) total time=   1.7s\n",
      "[CV 2/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.165, test=-0.343) total time=   1.5s\n",
      "[CV 3/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.169, test=-0.322) total time=   1.8s\n",
      "[CV 4/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.168, test=-0.340) total time=   1.8s\n",
      "[CV 5/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.168, test=-0.324) total time=   1.9s\n",
      "[CV 1/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.334) total time=   4.5s\n",
      "[CV 2/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.163, test=-0.338) total time=   4.4s\n",
      "[CV 3/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.168, test=-0.322) total time=   4.9s\n",
      "[CV 4/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.166, test=-0.338) total time=   4.3s\n",
      "[CV 5/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.325) total time=   4.2s\n",
      "[CV 1/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.180, test=-0.335) total time=   1.5s\n",
      "[CV 2/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.179, test=-0.340) total time=   1.7s\n",
      "[CV 3/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.323) total time=   2.0s\n",
      "[CV 4/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.180, test=-0.337) total time=   1.6s\n",
      "[CV 5/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.180, test=-0.324) total time=   1.8s\n",
      "[CV 1/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.180, test=-0.330) total time=   5.2s\n",
      "[CV 2/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.177, test=-0.337) total time=   4.6s\n",
      "[CV 3/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.322) total time=   4.2s\n",
      "[CV 4/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.337) total time=   4.1s\n",
      "[CV 5/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.180, test=-0.326) total time=   4.1s\n",
      "[CV 1/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.333) total time=   1.5s\n",
      "[CV 2/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.171, test=-0.342) total time=   1.7s\n",
      "[CV 3/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.176, test=-0.321) total time=   1.7s\n",
      "[CV 4/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.340) total time=   1.4s\n",
      "[CV 5/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.325) total time=   1.8s\n",
      "[CV 1/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.173, test=-0.331) total time=   3.9s\n",
      "[CV 2/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.171, test=-0.339) total time=   4.0s\n",
      "[CV 3/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.176, test=-0.322) total time=   3.9s\n",
      "[CV 4/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.173, test=-0.338) total time=   3.7s\n",
      "[CV 5/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.173, test=-0.325) total time=   4.0s\n",
      "[CV 1/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.187, test=-0.332) total time=   1.4s\n",
      "[CV 2/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.183, test=-0.339) total time=   1.6s\n",
      "[CV 3/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.187, test=-0.323) total time=   1.5s\n",
      "[CV 4/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.186, test=-0.341) total time=   1.7s\n",
      "[CV 5/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.186, test=-0.325) total time=   1.4s\n",
      "[CV 1/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.330) total time=   3.9s\n",
      "[CV 2/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.182, test=-0.338) total time=   4.4s\n",
      "[CV 3/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.186, test=-0.320) total time=   4.5s\n",
      "[CV 4/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.335) total time=   4.2s\n",
      "[CV 5/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.324) total time=   5.7s\n",
      "[CV 1/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.197, test=-0.332) total time=   1.4s\n",
      "[CV 2/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.193, test=-0.337) total time=   1.5s\n",
      "[CV 3/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.197, test=-0.323) total time=   1.7s\n",
      "[CV 4/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.196, test=-0.340) total time=   1.4s\n",
      "[CV 5/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.196, test=-0.324) total time=   1.4s\n",
      "[CV 1/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.196, test=-0.332) total time=   3.4s\n",
      "[CV 2/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.192, test=-0.338) total time=   3.2s\n",
      "[CV 3/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.197, test=-0.321) total time=   3.8s\n",
      "[CV 4/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.195, test=-0.336) total time=   3.7s\n",
      "[CV 5/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.197, test=-0.325) total time=   3.8s\n",
      "[CV 1/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.210, test=-0.332) total time=   1.4s\n",
      "[CV 2/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.206, test=-0.339) total time=   1.6s\n",
      "[CV 3/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.211, test=-0.320) total time=   1.3s\n",
      "[CV 4/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.210, test=-0.339) total time=   1.6s\n",
      "[CV 5/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.211, test=-0.325) total time=   1.3s\n",
      "[CV 1/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.209, test=-0.331) total time=   3.9s\n",
      "[CV 2/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.206, test=-0.337) total time=   3.5s\n",
      "[CV 3/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.210, test=-0.321) total time=   3.6s\n",
      "[CV 4/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.209, test=-0.336) total time=   3.8s\n",
      "[CV 5/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.209, test=-0.324) total time=   3.5s\n",
      "[CV 1/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.211, test=-0.333) total time=   1.3s\n",
      "[CV 2/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.208, test=-0.339) total time=   1.5s\n",
      "[CV 3/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.210, test=-0.319) total time=   1.5s\n",
      "[CV 4/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.209, test=-0.335) total time=   1.4s\n",
      "[CV 5/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.210, test=-0.323) total time=   1.4s\n",
      "[CV 1/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.210, test=-0.332) total time=   3.7s\n",
      "[CV 2/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.206, test=-0.338) total time=   3.5s\n",
      "[CV 3/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.211, test=-0.322) total time=   4.0s\n",
      "[CV 4/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.209, test=-0.336) total time=   4.0s\n",
      "[CV 5/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.210, test=-0.324) total time=   3.5s\n",
      "[CV 1/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.210, test=-0.334) total time=   1.4s\n",
      "[CV 2/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.206, test=-0.340) total time=   1.4s\n",
      "[CV 3/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.211, test=-0.321) total time=   1.6s\n",
      "[CV 4/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.211, test=-0.338) total time=   1.3s\n",
      "[CV 5/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.210, test=-0.324) total time=   1.5s\n",
      "[CV 1/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.209, test=-0.332) total time=   3.6s\n",
      "[CV 2/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.207, test=-0.337) total time=   3.5s\n",
      "[CV 3/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.211, test=-0.320) total time=   3.4s\n",
      "[CV 4/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.209, test=-0.336) total time=   3.5s\n",
      "[CV 5/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.210, test=-0.324) total time=   3.4s\n",
      "[CV 1/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.124, test=-0.331) total time=   2.0s\n",
      "[CV 2/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.123, test=-0.342) total time=   2.0s\n",
      "[CV 3/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.124, test=-0.325) total time=   1.8s\n",
      "[CV 4/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.124, test=-0.339) total time=   2.0s\n",
      "[CV 5/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.123, test=-0.325) total time=   1.9s\n",
      "[CV 1/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.122, test=-0.333) total time=   4.9s\n",
      "[CV 2/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.120, test=-0.339) total time=   4.8s\n",
      "[CV 3/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.123, test=-0.322) total time=   4.6s\n",
      "[CV 4/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.123, test=-0.340) total time=   4.7s\n",
      "[CV 5/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.122, test=-0.327) total time=   4.7s\n",
      "[CV 1/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.168, test=-0.335) total time=   1.7s\n",
      "[CV 2/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.163, test=-0.341) total time=   1.8s\n",
      "[CV 3/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.169, test=-0.324) total time=   1.7s\n",
      "[CV 4/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.167, test=-0.340) total time=   1.8s\n",
      "[CV 5/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.167, test=-0.328) total time=   1.6s\n",
      "[CV 1/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.333) total time=   4.6s\n",
      "[CV 2/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.164, test=-0.338) total time=   4.1s\n",
      "[CV 3/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.168, test=-0.321) total time=   4.2s\n",
      "[CV 4/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.338) total time=   4.2s\n",
      "[CV 5/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.326) total time=   4.1s\n",
      "[CV 1/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.181, test=-0.332) total time=   1.5s\n",
      "[CV 2/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.177, test=-0.339) total time=   1.8s\n",
      "[CV 3/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.182, test=-0.322) total time=   1.5s\n",
      "[CV 4/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.181, test=-0.339) total time=   1.6s\n",
      "[CV 5/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.181, test=-0.329) total time=   1.6s\n",
      "[CV 1/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.180, test=-0.332) total time=   4.1s\n",
      "[CV 2/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.176, test=-0.338) total time=   4.1s\n",
      "[CV 3/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.319) total time=   4.0s\n",
      "[CV 4/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.179, test=-0.337) total time=   4.3s\n",
      "[CV 5/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.180, test=-0.325) total time=   4.4s\n",
      "[CV 1/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.332) total time=   1.5s\n",
      "[CV 2/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.171, test=-0.341) total time=   1.8s\n",
      "[CV 3/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.322) total time=   1.4s\n",
      "[CV 4/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.337) total time=   1.8s\n",
      "[CV 5/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.174, test=-0.323) total time=   1.7s\n",
      "[CV 1/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.173, test=-0.332) total time=   4.0s\n",
      "[CV 2/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.170, test=-0.339) total time=   4.0s\n",
      "[CV 3/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.320) total time=   3.8s\n",
      "[CV 4/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.337) total time=   4.0s\n",
      "[CV 5/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.173, test=-0.324) total time=   3.9s\n",
      "[CV 1/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.185, test=-0.333) total time=   1.4s\n",
      "[CV 2/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.183, test=-0.339) total time=   1.6s\n",
      "[CV 3/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.186, test=-0.323) total time=   1.6s\n",
      "[CV 4/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.186, test=-0.338) total time=   1.4s\n",
      "[CV 5/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.186, test=-0.324) total time=   1.7s\n",
      "[CV 1/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.331) total time=   3.7s\n",
      "[CV 2/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.181, test=-0.337) total time=   3.8s\n",
      "[CV 3/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.186, test=-0.321) total time=   3.8s\n",
      "[CV 4/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.338) total time=   3.9s\n",
      "[CV 5/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.324) total time=   3.8s\n",
      "[CV 1/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.197, test=-0.330) total time=   1.4s\n",
      "[CV 2/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.192, test=-0.339) total time=   1.7s\n",
      "[CV 3/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.197, test=-0.320) total time=   1.4s\n",
      "[CV 4/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.196, test=-0.334) total time=   1.6s\n",
      "[CV 5/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.197, test=-0.324) total time=   1.5s\n",
      "[CV 1/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.196, test=-0.333) total time=   3.8s\n",
      "[CV 2/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.193, test=-0.339) total time=   3.8s\n",
      "[CV 3/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.197, test=-0.321) total time=   4.4s\n",
      "[CV 4/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.196, test=-0.338) total time=   4.3s\n",
      "[CV 5/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.196, test=-0.325) total time=   3.5s\n",
      "[CV 1/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.210, test=-0.332) total time=   1.2s\n",
      "[CV 2/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.207, test=-0.338) total time=   1.4s\n",
      "[CV 3/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.210, test=-0.321) total time=   1.7s\n",
      "[CV 4/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.210, test=-0.337) total time=   1.5s\n",
      "[CV 5/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.210, test=-0.322) total time=   1.9s\n",
      "[CV 1/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.209, test=-0.329) total time=   3.6s\n",
      "[CV 2/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.206, test=-0.337) total time=   3.4s\n",
      "[CV 3/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.210, test=-0.321) total time=   3.3s\n",
      "[CV 4/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.209, test=-0.336) total time=   3.4s\n",
      "[CV 5/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.210, test=-0.324) total time=   3.2s\n",
      "[CV 1/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.210, test=-0.331) total time=   1.2s\n",
      "[CV 2/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.206, test=-0.339) total time=   1.2s\n",
      "[CV 3/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.211, test=-0.322) total time=   1.2s\n",
      "[CV 4/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.209, test=-0.337) total time=   1.3s\n",
      "[CV 5/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.212, test=-0.323) total time=   1.2s\n",
      "[CV 1/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.209, test=-0.334) total time=   3.1s\n",
      "[CV 2/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.206, test=-0.338) total time=   3.4s\n",
      "[CV 3/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.210, test=-0.320) total time=   3.2s\n",
      "[CV 4/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.209, test=-0.336) total time=   3.1s\n",
      "[CV 5/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.210, test=-0.325) total time=   3.2s\n",
      "[CV 1/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.210, test=-0.332) total time=   1.3s\n",
      "[CV 2/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.206, test=-0.339) total time=   1.2s\n",
      "[CV 3/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.212, test=-0.323) total time=   1.2s\n",
      "[CV 4/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.210, test=-0.338) total time=   1.2s\n",
      "[CV 5/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.211, test=-0.325) total time=   1.2s\n",
      "[CV 1/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.210, test=-0.332) total time=   3.2s\n",
      "[CV 2/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.206, test=-0.338) total time=   3.4s\n",
      "[CV 3/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.210, test=-0.322) total time=   3.1s\n",
      "[CV 4/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.209, test=-0.337) total time=   3.3s\n",
      "[CV 5/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.210, test=-0.324) total time=   3.0s\n",
      "Selected Parameters {'rf__max_depth': 20, 'rf__min_samples_leaf': 3, 'rf__min_samples_split': 8, 'rf__n_estimators': 250}\n",
      "Train score: 0.15051757939626526\n",
      "Test score: 0.3495335003505825\n",
      "Running for 3 out of a total of 5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.128, test=-0.334) total time=   1.8s\n",
      "[CV 2/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.128, test=-0.339) total time=   2.0s\n",
      "[CV 3/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.127, test=-0.341) total time=   1.8s\n",
      "[CV 4/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.127, test=-0.332) total time=   1.9s\n",
      "[CV 5/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.128, test=-0.349) total time=   1.9s\n",
      "[CV 1/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.126, test=-0.333) total time=   4.7s\n",
      "[CV 2/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.126, test=-0.337) total time=   4.6s\n",
      "[CV 3/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.338) total time=   4.4s\n",
      "[CV 4/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.126, test=-0.331) total time=   4.6s\n",
      "[CV 5/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.350) total time=   4.6s\n",
      "[CV 1/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.332) total time=   1.5s\n",
      "[CV 2/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.172, test=-0.333) total time=   1.6s\n",
      "[CV 3/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.171, test=-0.339) total time=   1.7s\n",
      "[CV 4/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.171, test=-0.330) total time=   1.6s\n",
      "[CV 5/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.351) total time=   1.5s\n",
      "[CV 1/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.169, test=-0.334) total time=   4.2s\n",
      "[CV 2/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.170, test=-0.336) total time=   4.1s\n",
      "[CV 3/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.170, test=-0.338) total time=   4.0s\n",
      "[CV 4/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.170, test=-0.329) total time=   4.0s\n",
      "[CV 5/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.168, test=-0.349) total time=   4.1s\n",
      "[CV 1/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.333) total time=   1.7s\n",
      "[CV 2/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.184, test=-0.336) total time=   1.5s\n",
      "[CV 3/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.184, test=-0.339) total time=   1.6s\n",
      "[CV 4/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.184, test=-0.331) total time=   1.6s\n",
      "[CV 5/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.350) total time=   1.5s\n",
      "[CV 1/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.184, test=-0.332) total time=   4.1s\n",
      "[CV 2/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.183, test=-0.335) total time=   4.0s\n",
      "[CV 3/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.183, test=-0.337) total time=   4.0s\n",
      "[CV 4/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.184, test=-0.328) total time=   3.9s\n",
      "[CV 5/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.182, test=-0.348) total time=   4.1s\n",
      "[CV 1/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.178, test=-0.331) total time=   1.6s\n",
      "[CV 2/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.178, test=-0.336) total time=   1.7s\n",
      "[CV 3/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.177, test=-0.339) total time=   1.5s\n",
      "[CV 4/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.178, test=-0.331) total time=   1.4s\n",
      "[CV 5/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.176, test=-0.349) total time=   1.6s\n",
      "[CV 1/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.177, test=-0.332) total time=   3.8s\n",
      "[CV 2/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.177, test=-0.335) total time=   3.8s\n",
      "[CV 3/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.177, test=-0.337) total time=   3.8s\n",
      "[CV 4/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.177, test=-0.329) total time=   3.8s\n",
      "[CV 5/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.175, test=-0.348) total time=   3.9s\n",
      "[CV 1/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.190, test=-0.334) total time=   1.4s\n",
      "[CV 2/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.189, test=-0.332) total time=   1.7s\n",
      "[CV 3/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.189, test=-0.336) total time=   1.5s\n",
      "[CV 4/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.189, test=-0.329) total time=   1.4s\n",
      "[CV 5/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.189, test=-0.347) total time=   1.4s\n",
      "[CV 1/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.189, test=-0.331) total time=   3.9s\n",
      "[CV 2/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.189, test=-0.333) total time=   3.7s\n",
      "[CV 3/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.188, test=-0.337) total time=   4.1s\n",
      "[CV 4/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.189, test=-0.328) total time=   3.7s\n",
      "[CV 5/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.187, test=-0.350) total time=   3.8s\n",
      "[CV 1/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.202, test=-0.331) total time=   1.4s\n",
      "[CV 2/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.200, test=-0.335) total time=   1.3s\n",
      "[CV 3/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.200, test=-0.339) total time=   1.7s\n",
      "[CV 4/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.201, test=-0.328) total time=   1.7s\n",
      "[CV 5/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.199, test=-0.348) total time=   1.5s\n",
      "[CV 1/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.200, test=-0.330) total time=   3.9s\n",
      "[CV 2/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.200, test=-0.334) total time=   3.8s\n",
      "[CV 3/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.199, test=-0.336) total time=   3.6s\n",
      "[CV 4/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.199, test=-0.328) total time=   3.7s\n",
      "[CV 5/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.198, test=-0.347) total time=   3.8s\n",
      "[CV 1/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.215, test=-0.332) total time=   1.4s\n",
      "[CV 2/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.214, test=-0.333) total time=   1.3s\n",
      "[CV 3/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.213, test=-0.338) total time=   1.3s\n",
      "[CV 4/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.215, test=-0.329) total time=   1.4s\n",
      "[CV 5/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.212, test=-0.347) total time=   1.3s\n",
      "[CV 1/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.214, test=-0.330) total time=   3.7s\n",
      "[CV 2/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.214, test=-0.333) total time=   3.5s\n",
      "[CV 3/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.212, test=-0.336) total time=   3.4s\n",
      "[CV 4/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.213, test=-0.327) total time=   3.5s\n",
      "[CV 5/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.212, test=-0.348) total time=   3.5s\n",
      "[CV 1/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.215, test=-0.331) total time=   1.3s\n",
      "[CV 2/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.214, test=-0.334) total time=   1.4s\n",
      "[CV 3/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.213, test=-0.336) total time=   1.3s\n",
      "[CV 4/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.215, test=-0.328) total time=   1.4s\n",
      "[CV 5/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.213, test=-0.349) total time=   1.3s\n",
      "[CV 1/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.213, test=-0.330) total time=   3.7s\n",
      "[CV 2/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.213, test=-0.334) total time=   3.4s\n",
      "[CV 3/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.213, test=-0.337) total time=   3.6s\n",
      "[CV 4/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.214, test=-0.326) total time=   3.4s\n",
      "[CV 5/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.212, test=-0.348) total time=   3.4s\n",
      "[CV 1/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.214, test=-0.329) total time=   1.4s\n",
      "[CV 2/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.214, test=-0.335) total time=   1.3s\n",
      "[CV 3/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.213, test=-0.336) total time=   1.4s\n",
      "[CV 4/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.214, test=-0.328) total time=   1.3s\n",
      "[CV 5/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.212, test=-0.350) total time=   1.5s\n",
      "[CV 1/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.214, test=-0.330) total time=   3.5s\n",
      "[CV 2/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.213, test=-0.332) total time=   3.5s\n",
      "[CV 3/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.212, test=-0.338) total time=   3.4s\n",
      "[CV 4/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.214, test=-0.327) total time=   3.4s\n",
      "[CV 5/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.212, test=-0.347) total time=   3.5s\n",
      "[CV 1/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.126, test=-0.335) total time=   1.7s\n",
      "[CV 2/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.127, test=-0.338) total time=   1.9s\n",
      "[CV 3/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.127, test=-0.341) total time=   1.8s\n",
      "[CV 4/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.127, test=-0.329) total time=   1.9s\n",
      "[CV 5/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.125, test=-0.351) total time=   1.9s\n",
      "[CV 1/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.333) total time=   4.6s\n",
      "[CV 2/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.337) total time=   4.5s\n",
      "[CV 3/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.339) total time=   4.6s\n",
      "[CV 4/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.333) total time=   4.5s\n",
      "[CV 5/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.350) total time=   4.7s\n",
      "[CV 1/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.171, test=-0.329) total time=   1.6s\n",
      "[CV 2/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.335) total time=   1.5s\n",
      "[CV 3/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.336) total time=   1.6s\n",
      "[CV 4/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.331) total time=   1.6s\n",
      "[CV 5/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.168, test=-0.347) total time=   1.6s\n",
      "[CV 1/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.170, test=-0.334) total time=   4.2s\n",
      "[CV 2/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.170, test=-0.334) total time=   4.1s\n",
      "[CV 3/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.169, test=-0.339) total time=   4.1s\n",
      "[CV 4/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.169, test=-0.328) total time=   4.0s\n",
      "[CV 5/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.168, test=-0.347) total time=   4.1s\n",
      "[CV 1/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.333) total time=   1.5s\n",
      "[CV 2/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.184, test=-0.335) total time=   1.5s\n",
      "[CV 3/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.340) total time=   1.6s\n",
      "[CV 4/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.184, test=-0.328) total time=   1.6s\n",
      "[CV 5/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.351) total time=   1.6s\n",
      "[CV 1/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.183, test=-0.333) total time=   4.1s\n",
      "[CV 2/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.183, test=-0.335) total time=   3.9s\n",
      "[CV 3/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.183, test=-0.338) total time=   3.8s\n",
      "[CV 4/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.183, test=-0.328) total time=   3.9s\n",
      "[CV 5/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.348) total time=   4.0s\n",
      "[CV 1/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.178, test=-0.333) total time=   1.5s\n",
      "[CV 2/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.178, test=-0.336) total time=   1.5s\n",
      "[CV 3/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.176, test=-0.337) total time=   1.5s\n",
      "[CV 4/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.177, test=-0.332) total time=   1.5s\n",
      "[CV 5/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.176, test=-0.348) total time=   1.4s\n",
      "[CV 1/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.177, test=-0.331) total time=   3.9s\n",
      "[CV 2/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.177, test=-0.333) total time=   3.8s\n",
      "[CV 3/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.176, test=-0.336) total time=   3.6s\n",
      "[CV 4/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.177, test=-0.329) total time=   3.9s\n",
      "[CV 5/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.176, test=-0.348) total time=   3.9s\n",
      "[CV 1/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.189, test=-0.331) total time=   1.5s\n",
      "[CV 2/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.190, test=-0.335) total time=   1.5s\n",
      "[CV 3/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.188, test=-0.338) total time=   1.4s\n",
      "[CV 4/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.189, test=-0.330) total time=   1.6s\n",
      "[CV 5/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.187, test=-0.348) total time=   1.4s\n",
      "[CV 1/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.189, test=-0.331) total time=   3.9s\n",
      "[CV 2/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.188, test=-0.334) total time=   3.7s\n",
      "[CV 3/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.188, test=-0.337) total time=   3.7s\n",
      "[CV 4/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.189, test=-0.328) total time=   3.7s\n",
      "[CV 5/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.187, test=-0.348) total time=   3.7s\n",
      "[CV 1/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.200, test=-0.332) total time=   1.5s\n",
      "[CV 2/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.201, test=-0.333) total time=   1.4s\n",
      "[CV 3/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.200, test=-0.338) total time=   1.3s\n",
      "[CV 4/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.201, test=-0.328) total time=   1.3s\n",
      "[CV 5/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.198, test=-0.350) total time=   1.5s\n",
      "[CV 1/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.200, test=-0.331) total time=   3.9s\n",
      "[CV 2/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.200, test=-0.334) total time=   3.7s\n",
      "[CV 3/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.199, test=-0.338) total time=   3.6s\n",
      "[CV 4/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.200, test=-0.328) total time=   3.7s\n",
      "[CV 5/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.198, test=-0.348) total time=   3.6s\n",
      "[CV 1/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.214, test=-0.331) total time=   1.4s\n",
      "[CV 2/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.214, test=-0.332) total time=   1.4s\n",
      "[CV 3/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.214, test=-0.337) total time=   1.3s\n",
      "[CV 4/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.215, test=-0.330) total time=   1.4s\n",
      "[CV 5/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.212, test=-0.347) total time=   1.3s\n",
      "[CV 1/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.214, test=-0.332) total time=   3.7s\n",
      "[CV 2/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.213, test=-0.332) total time=   3.4s\n",
      "[CV 3/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.213, test=-0.335) total time=   3.4s\n",
      "[CV 4/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.213, test=-0.328) total time=   3.4s\n",
      "[CV 5/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.212, test=-0.349) total time=   3.5s\n",
      "[CV 1/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.215, test=-0.331) total time=   1.3s\n",
      "[CV 2/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.214, test=-0.332) total time=   1.4s\n",
      "[CV 3/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.214, test=-0.336) total time=   1.3s\n",
      "[CV 4/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.215, test=-0.329) total time=   1.4s\n",
      "[CV 5/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.213, test=-0.349) total time=   1.3s\n",
      "[CV 1/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.214, test=-0.332) total time=   3.5s\n",
      "[CV 2/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.214, test=-0.333) total time=   3.4s\n",
      "[CV 3/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.213, test=-0.336) total time=   3.3s\n",
      "[CV 4/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.213, test=-0.328) total time=   3.5s\n",
      "[CV 5/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.211, test=-0.348) total time=   3.5s\n",
      "[CV 1/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.214, test=-0.331) total time=   1.3s\n",
      "[CV 2/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.215, test=-0.332) total time=   1.3s\n",
      "[CV 3/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.214, test=-0.336) total time=   1.3s\n",
      "[CV 4/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.214, test=-0.327) total time=   1.4s\n",
      "[CV 5/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.212, test=-0.348) total time=   1.3s\n",
      "[CV 1/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.214, test=-0.331) total time=   3.6s\n",
      "[CV 2/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.213, test=-0.333) total time=   3.4s\n",
      "[CV 3/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.213, test=-0.336) total time=   3.4s\n",
      "[CV 4/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.213, test=-0.327) total time=   3.3s\n",
      "[CV 5/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.212, test=-0.347) total time=   3.6s\n",
      "Selected Parameters {'rf__max_depth': 20, 'rf__min_samples_leaf': 5, 'rf__min_samples_split': 2, 'rf__n_estimators': 250}\n",
      "Train score: 0.17557781360295227\n",
      "Test score: 0.26817530288431185\n",
      "Running for 4 out of a total of 5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.126, test=-0.338) total time=   2.6s\n",
      "[CV 2/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.126, test=-0.327) total time=   2.7s\n",
      "[CV 3/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.126, test=-0.339) total time=   2.7s\n",
      "[CV 4/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.128, test=-0.329) total time=   2.8s\n",
      "[CV 5/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.128, test=-0.329) total time=   2.6s\n",
      "[CV 1/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.338) total time=   6.7s\n",
      "[CV 2/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.329) total time=   6.5s\n",
      "[CV 3/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.340) total time=   6.6s\n",
      "[CV 4/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.126, test=-0.327) total time=   6.5s\n",
      "[CV 5/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.126, test=-0.331) total time=   6.6s\n",
      "[CV 1/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.169, test=-0.334) total time=   2.3s\n",
      "[CV 2/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.328) total time=   2.5s\n",
      "[CV 3/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.169, test=-0.340) total time=   2.5s\n",
      "[CV 4/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.171, test=-0.328) total time=   2.6s\n",
      "[CV 5/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.329) total time=   2.7s\n",
      "[CV 1/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.168, test=-0.335) total time=   6.5s\n",
      "[CV 2/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.169, test=-0.324) total time=   6.3s\n",
      "[CV 3/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.168, test=-0.337) total time=   5.8s\n",
      "[CV 4/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.169, test=-0.328) total time=   5.8s\n",
      "[CV 5/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.169, test=-0.329) total time=   5.6s\n",
      "[CV 1/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.182, test=-0.336) total time=   2.3s\n",
      "[CV 2/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.181, test=-0.325) total time=   2.4s\n",
      "[CV 3/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.338) total time=   2.3s\n",
      "[CV 4/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.182, test=-0.329) total time=   2.4s\n",
      "[CV 5/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.182, test=-0.330) total time=   2.2s\n",
      "[CV 1/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.335) total time=   6.0s\n",
      "[CV 2/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.182, test=-0.323) total time=   5.6s\n",
      "[CV 3/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.337) total time=   5.7s\n",
      "[CV 4/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.182, test=-0.326) total time=   5.6s\n",
      "[CV 5/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.328) total time=   5.7s\n",
      "[CV 1/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.335) total time=   2.1s\n",
      "[CV 2/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.176, test=-0.327) total time=   2.3s\n",
      "[CV 3/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.334) total time=   2.1s\n",
      "[CV 4/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.177, test=-0.329) total time=   2.2s\n",
      "[CV 5/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.176, test=-0.326) total time=   2.2s\n",
      "[CV 1/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.336) total time=   5.6s\n",
      "[CV 2/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.176, test=-0.325) total time=   5.4s\n",
      "[CV 3/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.335) total time=   5.5s\n",
      "[CV 4/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.176, test=-0.327) total time=   5.5s\n",
      "[CV 5/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.176, test=-0.327) total time=   5.5s\n",
      "[CV 1/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.187, test=-0.337) total time=   2.1s\n",
      "[CV 2/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.187, test=-0.325) total time=   2.3s\n",
      "[CV 3/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.188, test=-0.337) total time=   2.1s\n",
      "[CV 4/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.188, test=-0.325) total time=   2.3s\n",
      "[CV 5/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.189, test=-0.330) total time=   2.1s\n",
      "[CV 1/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.186, test=-0.335) total time=   5.4s\n",
      "[CV 2/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.188, test=-0.324) total time=   5.3s\n",
      "[CV 3/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.186, test=-0.335) total time=   5.3s\n",
      "[CV 4/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.188, test=-0.328) total time=   5.4s\n",
      "[CV 5/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.187, test=-0.328) total time=   5.5s\n",
      "[CV 1/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.196, test=-0.336) total time=   2.0s\n",
      "[CV 2/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.199, test=-0.325) total time=   2.3s\n",
      "[CV 3/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.198, test=-0.336) total time=   2.3s\n",
      "[CV 4/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.200, test=-0.327) total time=   2.4s\n",
      "[CV 5/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.199, test=-0.329) total time=   2.4s\n",
      "[CV 1/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.196, test=-0.335) total time=   5.6s\n",
      "[CV 2/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.198, test=-0.324) total time=   5.1s\n",
      "[CV 3/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.198, test=-0.334) total time=   5.4s\n",
      "[CV 4/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.199, test=-0.327) total time=   5.2s\n",
      "[CV 5/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.198, test=-0.326) total time=   5.3s\n",
      "[CV 1/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.211, test=-0.336) total time=   1.9s\n",
      "[CV 2/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.212, test=-0.326) total time=   2.0s\n",
      "[CV 3/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.211, test=-0.334) total time=   2.1s\n",
      "[CV 4/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.212, test=-0.327) total time=   2.0s\n",
      "[CV 5/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.212, test=-0.328) total time=   2.0s\n",
      "[CV 1/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.210, test=-0.335) total time=   5.1s\n",
      "[CV 2/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.212, test=-0.325) total time=   5.0s\n",
      "[CV 3/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.212, test=-0.334) total time=   4.9s\n",
      "[CV 4/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.211, test=-0.326) total time=   5.1s\n",
      "[CV 5/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.212, test=-0.326) total time=   5.1s\n",
      "[CV 1/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.210, test=-0.335) total time=   2.0s\n",
      "[CV 2/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.213, test=-0.324) total time=   2.2s\n",
      "[CV 3/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.212, test=-0.335) total time=   2.0s\n",
      "[CV 4/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.214, test=-0.325) total time=   2.0s\n",
      "[CV 5/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.213, test=-0.327) total time=   2.1s\n",
      "[CV 1/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.210, test=-0.335) total time=   5.1s\n",
      "[CV 2/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.212, test=-0.323) total time=   4.9s\n",
      "[CV 3/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.211, test=-0.334) total time=   5.1s\n",
      "[CV 4/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.212, test=-0.326) total time=   5.0s\n",
      "[CV 5/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.212, test=-0.327) total time=   5.0s\n",
      "[CV 1/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.211, test=-0.335) total time=   1.9s\n",
      "[CV 2/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.212, test=-0.324) total time=   2.0s\n",
      "[CV 3/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.211, test=-0.336) total time=   2.0s\n",
      "[CV 4/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.214, test=-0.326) total time=   2.0s\n",
      "[CV 5/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.212, test=-0.329) total time=   2.0s\n",
      "[CV 1/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.210, test=-0.335) total time=   5.0s\n",
      "[CV 2/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.211, test=-0.324) total time=   5.2s\n",
      "[CV 3/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.211, test=-0.334) total time=   5.2s\n",
      "[CV 4/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.212, test=-0.326) total time=   4.9s\n",
      "[CV 5/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.212, test=-0.326) total time=   4.8s\n",
      "[CV 1/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.124, test=-0.338) total time=   2.7s\n",
      "[CV 2/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.125, test=-0.327) total time=   2.7s\n",
      "[CV 3/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.124, test=-0.338) total time=   2.7s\n",
      "[CV 4/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.125, test=-0.328) total time=   2.6s\n",
      "[CV 5/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.125, test=-0.329) total time=   2.8s\n",
      "[CV 1/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.122, test=-0.336) total time=   6.7s\n",
      "[CV 2/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.124, test=-0.326) total time=   6.7s\n",
      "[CV 3/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.123, test=-0.339) total time=   6.7s\n",
      "[CV 4/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.329) total time=   6.6s\n",
      "[CV 5/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.123, test=-0.330) total time=   6.6s\n",
      "[CV 1/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.168, test=-0.337) total time=   2.4s\n",
      "[CV 2/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.169, test=-0.327) total time=   2.4s\n",
      "[CV 3/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.168, test=-0.338) total time=   2.3s\n",
      "[CV 4/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.171, test=-0.330) total time=   2.5s\n",
      "[CV 5/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.329) total time=   2.3s\n",
      "[CV 1/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.336) total time=   5.9s\n",
      "[CV 2/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.325) total time=   5.8s\n",
      "[CV 3/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.168, test=-0.337) total time=   5.9s\n",
      "[CV 4/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.169, test=-0.328) total time=   5.8s\n",
      "[CV 5/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.168, test=-0.328) total time=   5.8s\n",
      "[CV 1/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.181, test=-0.335) total time=   2.2s\n",
      "[CV 2/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.328) total time=   2.4s\n",
      "[CV 3/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.181, test=-0.337) total time=   2.3s\n",
      "[CV 4/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.330) total time=   2.2s\n",
      "[CV 5/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.182, test=-0.329) total time=   2.3s\n",
      "[CV 1/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.180, test=-0.334) total time=   5.9s\n",
      "[CV 2/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.325) total time=   5.8s\n",
      "[CV 3/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.180, test=-0.338) total time=   5.7s\n",
      "[CV 4/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.182, test=-0.326) total time=   5.6s\n",
      "[CV 5/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.329) total time=   5.8s\n",
      "[CV 1/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.335) total time=   2.1s\n",
      "[CV 2/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.177, test=-0.329) total time=   2.3s\n",
      "[CV 3/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.335) total time=   2.1s\n",
      "[CV 4/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.177, test=-0.328) total time=   2.4s\n",
      "[CV 5/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.176, test=-0.327) total time=   2.0s\n",
      "[CV 1/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.335) total time=   5.7s\n",
      "[CV 2/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.175, test=-0.324) total time=   5.3s\n",
      "[CV 3/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.175, test=-0.337) total time=   5.8s\n",
      "[CV 4/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.176, test=-0.327) total time=   5.5s\n",
      "[CV 5/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.175, test=-0.327) total time=   5.9s\n",
      "[CV 1/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.186, test=-0.337) total time=   2.0s\n",
      "[CV 2/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.188, test=-0.323) total time=   1.7s\n",
      "[CV 3/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.188, test=-0.335) total time=   1.8s\n",
      "[CV 4/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.190, test=-0.328) total time=   1.7s\n",
      "[CV 5/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.188, test=-0.330) total time=   1.7s\n",
      "[CV 1/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.336) total time=   4.5s\n",
      "[CV 2/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.187, test=-0.324) total time=   4.3s\n",
      "[CV 3/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.186, test=-0.335) total time=   4.3s\n",
      "[CV 4/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.188, test=-0.326) total time=   4.3s\n",
      "[CV 5/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.187, test=-0.327) total time=   4.2s\n",
      "[CV 1/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.198, test=-0.336) total time=   1.7s\n",
      "[CV 2/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.199, test=-0.326) total time=   1.6s\n",
      "[CV 3/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.198, test=-0.336) total time=   1.7s\n",
      "[CV 4/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.200, test=-0.327) total time=   1.7s\n",
      "[CV 5/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.199, test=-0.327) total time=   1.7s\n",
      "[CV 1/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.196, test=-0.335) total time=   4.4s\n",
      "[CV 2/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.198, test=-0.325) total time=   4.2s\n",
      "[CV 3/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.197, test=-0.335) total time=   4.3s\n",
      "[CV 4/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.199, test=-0.328) total time=   4.2s\n",
      "[CV 5/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.197, test=-0.326) total time=   4.3s\n",
      "[CV 1/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.211, test=-0.335) total time=   1.5s\n",
      "[CV 2/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.212, test=-0.323) total time=   1.6s\n",
      "[CV 3/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.211, test=-0.336) total time=   1.5s\n",
      "[CV 4/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.212, test=-0.327) total time=   1.6s\n",
      "[CV 5/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.212, test=-0.325) total time=   1.6s\n",
      "[CV 1/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.210, test=-0.334) total time=   4.0s\n",
      "[CV 2/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.212, test=-0.325) total time=   4.0s\n",
      "[CV 3/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.211, test=-0.334) total time=   4.0s\n",
      "[CV 4/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.212, test=-0.326) total time=   4.2s\n",
      "[CV 5/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.212, test=-0.326) total time=   4.0s\n",
      "[CV 1/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.210, test=-0.337) total time=   1.6s\n",
      "[CV 2/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.213, test=-0.325) total time=   1.6s\n",
      "[CV 3/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.211, test=-0.336) total time=   1.6s\n",
      "[CV 4/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.213, test=-0.327) total time=   1.6s\n",
      "[CV 5/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.212, test=-0.326) total time=   1.6s\n",
      "[CV 1/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.210, test=-0.335) total time=   4.1s\n",
      "[CV 2/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.212, test=-0.323) total time=   3.8s\n",
      "[CV 3/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.211, test=-0.335) total time=   4.2s\n",
      "[CV 4/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.212, test=-0.326) total time=   4.1s\n",
      "[CV 5/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.212, test=-0.327) total time=   4.0s\n",
      "[CV 1/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.211, test=-0.336) total time=   1.6s\n",
      "[CV 2/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.213, test=-0.325) total time=   1.6s\n",
      "[CV 3/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.212, test=-0.333) total time=   1.6s\n",
      "[CV 4/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.211, test=-0.326) total time=   1.6s\n",
      "[CV 5/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.212, test=-0.325) total time=   1.6s\n",
      "[CV 1/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.210, test=-0.334) total time=   4.0s\n",
      "[CV 2/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.212, test=-0.325) total time=   4.1s\n",
      "[CV 3/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.210, test=-0.334) total time=   4.1s\n",
      "[CV 4/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.212, test=-0.326) total time=   4.0s\n",
      "[CV 5/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.212, test=-0.326) total time=   4.1s\n",
      "Selected Parameters {'rf__max_depth': 20, 'rf__min_samples_leaf': 5, 'rf__min_samples_split': 8, 'rf__n_estimators': 250}\n",
      "Train score: 0.17365177627866843\n",
      "Test score: 0.3115204576798002\n",
      "Running for 5 out of a total of 5\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.127, test=-0.346) total time=   2.2s\n",
      "[CV 2/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.127, test=-0.325) total time=   2.4s\n",
      "[CV 3/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.126, test=-0.340) total time=   2.4s\n",
      "[CV 4/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.128, test=-0.326) total time=   2.3s\n",
      "[CV 5/5; 1/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 1/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.129, test=-0.326) total time=   2.5s\n",
      "[CV 1/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.124, test=-0.348) total time=   5.8s\n",
      "[CV 2/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.126, test=-0.330) total time=   5.8s\n",
      "[CV 3/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.124, test=-0.343) total time=   5.7s\n",
      "[CV 4/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.127, test=-0.327) total time=   5.8s\n",
      "[CV 5/5; 2/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 2/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.128, test=-0.324) total time=   5.8s\n",
      "[CV 1/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.168, test=-0.346) total time=   2.0s\n",
      "[CV 2/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.327) total time=   2.2s\n",
      "[CV 3/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.343) total time=   1.9s\n",
      "[CV 4/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.171, test=-0.326) total time=   2.1s\n",
      "[CV 5/5; 3/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 3/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.172, test=-0.322) total time=   2.1s\n",
      "[CV 1/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.168, test=-0.345) total time=   5.3s\n",
      "[CV 2/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.169, test=-0.327) total time=   5.2s\n",
      "[CV 3/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.168, test=-0.340) total time=   5.1s\n",
      "[CV 4/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.170, test=-0.326) total time=   5.2s\n",
      "[CV 5/5; 4/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 4/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.171, test=-0.322) total time=   5.2s\n",
      "[CV 1/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.182, test=-0.344) total time=   2.1s\n",
      "[CV 2/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.183, test=-0.326) total time=   2.1s\n",
      "[CV 3/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.181, test=-0.342) total time=   2.1s\n",
      "[CV 4/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.184, test=-0.325) total time=   1.9s\n",
      "[CV 5/5; 5/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 5/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.185, test=-0.325) total time=   2.2s\n",
      "[CV 1/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.345) total time=   5.1s\n",
      "[CV 2/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.182, test=-0.327) total time=   5.0s\n",
      "[CV 3/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.179, test=-0.340) total time=   5.2s\n",
      "[CV 4/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.184, test=-0.326) total time=   5.1s\n",
      "[CV 5/5; 6/36] START rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 6/36] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.185, test=-0.323) total time=   5.1s\n",
      "[CV 1/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.175, test=-0.344) total time=   2.0s\n",
      "[CV 2/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.178, test=-0.326) total time=   1.9s\n",
      "[CV 3/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.173, test=-0.341) total time=   2.1s\n",
      "[CV 4/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.179, test=-0.325) total time=   2.0s\n",
      "[CV 5/5; 7/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 7/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.178, test=-0.321) total time=   2.1s\n",
      "[CV 1/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.343) total time=   5.0s\n",
      "[CV 2/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.176, test=-0.325) total time=   4.9s\n",
      "[CV 3/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.342) total time=   4.8s\n",
      "[CV 4/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.177, test=-0.324) total time=   4.8s\n",
      "[CV 5/5; 8/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 8/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.178, test=-0.323) total time=   5.0s\n",
      "[CV 1/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.187, test=-0.344) total time=   1.9s\n",
      "[CV 2/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.188, test=-0.325) total time=   1.9s\n",
      "[CV 3/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.187, test=-0.341) total time=   2.0s\n",
      "[CV 4/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.190, test=-0.325) total time=   1.8s\n",
      "[CV 5/5; 9/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 9/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.190, test=-0.324) total time=   1.8s\n",
      "[CV 1/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.342) total time=   4.8s\n",
      "[CV 2/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.187, test=-0.326) total time=   4.7s\n",
      "[CV 3/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.186, test=-0.339) total time=   4.7s\n",
      "[CV 4/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.189, test=-0.325) total time=   4.8s\n",
      "[CV 5/5; 10/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 10/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.189, test=-0.322) total time=   4.8s\n",
      "[CV 1/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.198, test=-0.342) total time=   1.9s\n",
      "[CV 2/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.199, test=-0.327) total time=   1.8s\n",
      "[CV 3/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.196, test=-0.341) total time=   1.9s\n",
      "[CV 4/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.201, test=-0.324) total time=   1.8s\n",
      "[CV 5/5; 11/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 11/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.202, test=-0.321) total time=   1.9s\n",
      "[CV 1/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.196, test=-0.343) total time=   4.9s\n",
      "[CV 2/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.198, test=-0.326) total time=   4.6s\n",
      "[CV 3/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.196, test=-0.341) total time=   4.7s\n",
      "[CV 4/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.200, test=-0.324) total time=   4.7s\n",
      "[CV 5/5; 12/36] START rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 12/36] END rf__max_depth=20, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.200, test=-0.320) total time=   4.8s\n",
      "[CV 1/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.211, test=-0.343) total time=   1.7s\n",
      "[CV 2/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.212, test=-0.326) total time=   1.8s\n",
      "[CV 3/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.210, test=-0.341) total time=   1.8s\n",
      "[CV 4/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.214, test=-0.324) total time=   1.8s\n",
      "[CV 5/5; 13/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 13/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.214, test=-0.322) total time=   1.8s\n",
      "[CV 1/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.210, test=-0.342) total time=   4.6s\n",
      "[CV 2/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.211, test=-0.326) total time=   4.4s\n",
      "[CV 3/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.209, test=-0.341) total time=   4.4s\n",
      "[CV 4/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.213, test=-0.323) total time=   4.3s\n",
      "[CV 5/5; 14/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 14/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.214, test=-0.322) total time=   5.0s\n",
      "[CV 1/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.210, test=-0.343) total time=   2.1s\n",
      "[CV 2/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.212, test=-0.326) total time=   1.7s\n",
      "[CV 3/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.210, test=-0.341) total time=   1.8s\n",
      "[CV 4/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.214, test=-0.324) total time=   1.8s\n",
      "[CV 5/5; 15/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 15/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.214, test=-0.322) total time=   1.8s\n",
      "[CV 1/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.210, test=-0.341) total time=   4.5s\n",
      "[CV 2/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.211, test=-0.324) total time=   4.4s\n",
      "[CV 3/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.209, test=-0.340) total time=   4.4s\n",
      "[CV 4/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.213, test=-0.322) total time=   4.4s\n",
      "[CV 5/5; 16/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 16/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.213, test=-0.322) total time=   4.5s\n",
      "[CV 1/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.211, test=-0.343) total time=   1.8s\n",
      "[CV 2/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.213, test=-0.324) total time=   1.9s\n",
      "[CV 3/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.210, test=-0.340) total time=   2.0s\n",
      "[CV 4/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.214, test=-0.324) total time=   1.7s\n",
      "[CV 5/5; 17/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 17/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.214, test=-0.322) total time=   1.8s\n",
      "[CV 1/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.210, test=-0.342) total time=   4.5s\n",
      "[CV 2/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.211, test=-0.325) total time=   4.4s\n",
      "[CV 3/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.209, test=-0.340) total time=   4.2s\n",
      "[CV 4/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.213, test=-0.322) total time=   4.5s\n",
      "[CV 5/5; 18/36] START rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 18/36] END rf__max_depth=20, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.214, test=-0.321) total time=   4.5s\n",
      "[CV 1/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.123, test=-0.348) total time=   2.5s\n",
      "[CV 2/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.124, test=-0.326) total time=   2.3s\n",
      "[CV 3/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.123, test=-0.342) total time=   2.4s\n",
      "[CV 4/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.127, test=-0.327) total time=   2.3s\n",
      "[CV 5/5; 19/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 19/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.127, test=-0.325) total time=   2.4s\n",
      "[CV 1/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.122, test=-0.348) total time=   5.9s\n",
      "[CV 2/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.123, test=-0.328) total time=   5.9s\n",
      "[CV 3/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.122, test=-0.343) total time=   5.8s\n",
      "[CV 4/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.125, test=-0.325) total time=   5.8s\n",
      "[CV 5/5; 20/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 20/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.124, test=-0.326) total time=   5.9s\n",
      "[CV 1/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.166, test=-0.345) total time=   2.0s\n",
      "[CV 2/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.168, test=-0.327) total time=   2.1s\n",
      "[CV 3/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.167, test=-0.341) total time=   2.2s\n",
      "[CV 4/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.170, test=-0.327) total time=   2.1s\n",
      "[CV 5/5; 21/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 21/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.172, test=-0.324) total time=   2.0s\n",
      "[CV 1/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.346) total time=   5.5s\n",
      "[CV 2/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.325) total time=   5.2s\n",
      "[CV 3/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.167, test=-0.340) total time=   5.0s\n",
      "[CV 4/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.170, test=-0.326) total time=   5.3s\n",
      "[CV 5/5; 22/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 22/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.170, test=-0.323) total time=   5.2s\n",
      "[CV 1/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.181, test=-0.345) total time=   1.9s\n",
      "[CV 2/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.182, test=-0.327) total time=   2.1s\n",
      "[CV 3/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.180, test=-0.337) total time=   2.0s\n",
      "[CV 4/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.184, test=-0.327) total time=   2.1s\n",
      "[CV 5/5; 23/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 23/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.184, test=-0.322) total time=   1.9s\n",
      "[CV 1/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.179, test=-0.345) total time=   5.3s\n",
      "[CV 2/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.181, test=-0.327) total time=   5.1s\n",
      "[CV 3/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.180, test=-0.342) total time=   5.6s\n",
      "[CV 4/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.183, test=-0.325) total time=   5.0s\n",
      "[CV 5/5; 24/36] START rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 24/36] END rf__max_depth=None, rf__min_samples_leaf=1, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.183, test=-0.322) total time=   5.8s\n",
      "[CV 1/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.174, test=-0.344) total time=   2.5s\n",
      "[CV 2/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.176, test=-0.328) total time=   2.5s\n",
      "[CV 3/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.173, test=-0.341) total time=   2.3s\n",
      "[CV 4/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.177, test=-0.325) total time=   2.4s\n",
      "[CV 5/5; 25/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 25/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.178, test=-0.325) total time=   2.6s\n",
      "[CV 1/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.174, test=-0.344) total time=   6.1s\n",
      "[CV 2/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.175, test=-0.326) total time=   6.1s\n",
      "[CV 3/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.173, test=-0.339) total time=   6.0s\n",
      "[CV 4/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.177, test=-0.323) total time=   5.9s\n",
      "[CV 5/5; 26/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 26/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.177, test=-0.323) total time=   6.1s\n",
      "[CV 1/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.186, test=-0.342) total time=   2.4s\n",
      "[CV 2/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.188, test=-0.327) total time=   2.4s\n",
      "[CV 3/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.186, test=-0.342) total time=   2.4s\n",
      "[CV 4/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.190, test=-0.323) total time=   2.3s\n",
      "[CV 5/5; 27/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 27/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.190, test=-0.322) total time=   2.5s\n",
      "[CV 1/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.344) total time=   6.0s\n",
      "[CV 2/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.187, test=-0.327) total time=   6.0s\n",
      "[CV 3/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.185, test=-0.342) total time=   5.9s\n",
      "[CV 4/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.188, test=-0.322) total time=   5.9s\n",
      "[CV 5/5; 28/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 28/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.189, test=-0.320) total time=   6.0s\n",
      "[CV 1/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.195, test=-0.343) total time=   2.4s\n",
      "[CV 2/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.199, test=-0.327) total time=   2.2s\n",
      "[CV 3/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.197, test=-0.341) total time=   2.4s\n",
      "[CV 4/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.200, test=-0.325) total time=   2.3s\n",
      "[CV 5/5; 29/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 29/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.200, test=-0.321) total time=   2.5s\n",
      "[CV 1/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.196, test=-0.343) total time=   6.1s\n",
      "[CV 2/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.198, test=-0.325) total time=   5.8s\n",
      "[CV 3/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.196, test=-0.339) total time=   5.8s\n",
      "[CV 4/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.199, test=-0.323) total time=   5.8s\n",
      "[CV 5/5; 30/36] START rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 30/36] END rf__max_depth=None, rf__min_samples_leaf=3, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.200, test=-0.321) total time=   5.9s\n",
      "[CV 1/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 1/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.210, test=-0.342) total time=   2.3s\n",
      "[CV 2/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 2/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.213, test=-0.325) total time=   2.1s\n",
      "[CV 3/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 3/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.209, test=-0.339) total time=   2.3s\n",
      "[CV 4/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 4/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.214, test=-0.323) total time=   2.3s\n",
      "[CV 5/5; 31/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100\n",
      "[CV 5/5; 31/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=100;, score=(train=-0.214, test=-0.323) total time=   2.2s\n",
      "[CV 1/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 1/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.210, test=-0.343) total time=   5.7s\n",
      "[CV 2/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 2/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.211, test=-0.325) total time=   5.4s\n",
      "[CV 3/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 3/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.209, test=-0.340) total time=   5.5s\n",
      "[CV 4/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 4/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.213, test=-0.322) total time=   5.5s\n",
      "[CV 5/5; 32/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250\n",
      "[CV 5/5; 32/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=2, rf__n_estimators=250;, score=(train=-0.213, test=-0.322) total time=   5.6s\n",
      "[CV 1/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 1/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.211, test=-0.343) total time=   2.2s\n",
      "[CV 2/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 2/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.212, test=-0.327) total time=   2.4s\n",
      "[CV 3/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 3/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.210, test=-0.338) total time=   2.2s\n",
      "[CV 4/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 4/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.214, test=-0.323) total time=   2.2s\n",
      "[CV 5/5; 33/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100\n",
      "[CV 5/5; 33/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=100;, score=(train=-0.214, test=-0.320) total time=   2.2s\n",
      "[CV 1/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 1/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.210, test=-0.341) total time=   5.3s\n",
      "[CV 2/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 2/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.211, test=-0.325) total time=   4.6s\n",
      "[CV 3/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 3/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.209, test=-0.340) total time=   4.6s\n",
      "[CV 4/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 4/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.213, test=-0.322) total time=   4.7s\n",
      "[CV 5/5; 34/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250\n",
      "[CV 5/5; 34/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=8, rf__n_estimators=250;, score=(train=-0.213, test=-0.321) total time=   4.9s\n",
      "[CV 1/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 1/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.211, test=-0.343) total time=   2.3s\n",
      "[CV 2/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 2/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.211, test=-0.326) total time=   2.1s\n",
      "[CV 3/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 3/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.210, test=-0.340) total time=   2.4s\n",
      "[CV 4/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 4/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.213, test=-0.324) total time=   2.2s\n",
      "[CV 5/5; 35/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100\n",
      "[CV 5/5; 35/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=100;, score=(train=-0.213, test=-0.319) total time=   2.2s\n",
      "[CV 1/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 1/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.210, test=-0.341) total time=   5.6s\n",
      "[CV 2/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 2/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.211, test=-0.325) total time=   5.5s\n",
      "[CV 3/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 3/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.209, test=-0.341) total time=   5.5s\n",
      "[CV 4/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 4/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.213, test=-0.323) total time=   5.5s\n",
      "[CV 5/5; 36/36] START rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250\n",
      "[CV 5/5; 36/36] END rf__max_depth=None, rf__min_samples_leaf=5, rf__min_samples_split=10, rf__n_estimators=250;, score=(train=-0.213, test=-0.321) total time=   5.6s\n",
      "Selected Parameters {'rf__max_depth': None, 'rf__min_samples_leaf': 5, 'rf__min_samples_split': 8, 'rf__n_estimators': 250}\n",
      "Train score: 0.17339977625474173\n",
      "Test score: 0.256825729192288\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_regr.p\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "pickle.dump(selected_params_rf_regr, open(path, \"wb\"))\r\n",
    "\r\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_rf_regr.csv\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "df_predicted_rf_regr.to_csv(path)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:3: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_regr.p'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtaining the optimal model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "xgb_search_space = [\r\n",
    "    {\r\n",
    "        \"estimator__learning_rate\": [0.1, 0.5, 1],\r\n",
    "        \"estimator__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"estimator__max_depth\": [6, 8],\r\n",
    "        \"estimator__reg_lambda\": [0.001, 0.1, 1],\r\n",
    "        \"estimator__n_estimators\": [100, 200],\r\n",
    "        \"estimator__colsample_bytree\": [0.5, 0.7],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "selected_features_xgb_regr, selected_params_xgb_regr_full = xgb_regression_features(\r\n",
    "    X=X,\r\n",
    "    y=y,\r\n",
    "    features=features,\r\n",
    "    search_space=xgb_search_space,\r\n",
    "    min_features_to_select=1,\r\n",
    "    cv_splits=5,\r\n",
    "    GS_score=\"neg_root_mean_squared_error\",\r\n",
    "    objective='\"reg:squarederror\"',\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=50,\r\n",
    "    verbose=10,\r\n",
    ")\r\n",
    "\r\n",
    "\r\n",
    "print(f\"Number of selected features XGBoost Regression {len(selected_features_xgb_regr)}\")\r\n",
    "print(f\"Selected features XGBoost Regression: {selected_features_xgb_regr}\")\r\n",
    "print(f\"Selected Parameters XGBoost Regression: {selected_params_xgb_regr_full}\")\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtaining the performance estimate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the selected features for XGB\r\n",
    "selected_features_xgb_regr = [\r\n",
    "    'rice_area', \r\n",
    "    'mean_slope', \r\n",
    "    'mean_elevation_m', \r\n",
    "    'ruggedness_stdev', \r\n",
    "    'mean_ruggedness', \r\n",
    "    'slope_stdev', \r\n",
    "    'area_km2', \r\n",
    "    'poverty_perc', \r\n",
    "    'with_coast', \r\n",
    "    'coast_length', \r\n",
    "    'perimeter', \r\n",
    "    'glat', \r\n",
    "    'glon', \r\n",
    "    'coast_peri_ratio', \r\n",
    "    'rainfall_sum', \r\n",
    "    'rainfall_max', \r\n",
    "    'dis_track_min', \r\n",
    "    'vmax_sust'\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "xgb_search_space = [\r\n",
    "    {\r\n",
    "        \"xgb__learning_rate\": [0.1, 0.5, 1],\r\n",
    "        \"xgb__gamma\": [0.1, 0.5, 2],\r\n",
    "        \"xgb__max_depth\": [6, 8],\r\n",
    "        \"xgb__reg_lambda\": [0.001, 0.1, 1],\r\n",
    "        \"xgb__n_estimators\": [100, 200],\r\n",
    "        \"xgb__colsample_bytree\": [0.5, 0.7],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "df_predicted_xgb_regr, selected_params_xgb_regr = xgb_regression_performance(\r\n",
    "    df_train_list=df_train_list,\r\n",
    "    df_test_list=df_test_list,\r\n",
    "    features=selected_features_xgb_regr,\r\n",
    "    search_space=xgb_search_space,\r\n",
    "    cv_splits=5,\r\n",
    "    objective=\"reg:squarederror\",\r\n",
    "    GS_score=\"neg_root_mean_squared_error\",\r\n",
    "    GS_randomized=True,\r\n",
    "    GS_n_iter=50,\r\n",
    "    verbose=10,\r\n",
    ")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_xgb_regr.p\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "pickle.dump(selected_params_xgb_regr, open(path, \"wb\"))\r\n",
    "\r\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_xgb_regr.csv\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "df_predicted_xgb_regr.to_csv(path)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmark"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# Predict the average\r\n",
    "df_predicted_mean = pd.DataFrame(columns=[\"year\", \"actual\", \"predicted\"])\r\n",
    "\r\n",
    "for i in range(len(df_train_list)):\r\n",
    "\r\n",
    "    train = df_train_list[i]\r\n",
    "    test = df_test_list[i]\r\n",
    "\r\n",
    "    y_train = train[\"perc_loss\"]\r\n",
    "    y_test = test[\"perc_loss\"]\r\n",
    "\r\n",
    "    y_test_pred = [np.mean(y_train)] * len(y_test)\r\n",
    "\r\n",
    "    df_predicted_temp = pd.DataFrame(\r\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_test_pred}\r\n",
    "    )\r\n",
    "\r\n",
    "    df_predicted_mean = pd.concat([df_predicted_mean, df_predicted_temp])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "# Simle Linear Regression with Wind Speed\r\n",
    "input_variable = \"vmax\"\r\n",
    "df_predicted_lr = pd.DataFrame(columns=[\"year\", \"actual\", \"predicted\"])\r\n",
    "\r\n",
    "for i in range(len(df_train_list)):\r\n",
    "\r\n",
    "    train = df_train_list[i]\r\n",
    "    test = df_test_list[i]\r\n",
    "\r\n",
    "    x_train = train[input_variable].values.reshape(-1, 1)\r\n",
    "    y_train = train[\"perc_loss\"].values.reshape(-1, 1)\r\n",
    "\r\n",
    "    x_test = test[input_variable].values.reshape(-1, 1)\r\n",
    "    y_test = test[\"perc_loss\"]\r\n",
    "\r\n",
    "    model = LinearRegression()\r\n",
    "    lr_fitted = model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    y_pred_train = lr_fitted.predict(x_train)\r\n",
    "    y_pred_test = lr_fitted.predict(x_test)\r\n",
    "    y_pred_test = y_pred_test.tolist()\r\n",
    "    y_pred_test = [val for sublist in y_pred_test for val in sublist]\r\n",
    "\r\n",
    "    df_predicted_temp = pd.DataFrame(\r\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_pred_test}\r\n",
    "    )\r\n",
    "\r\n",
    "    df_predicted_lr = pd.concat([df_predicted_lr, df_predicted_temp])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "models = {\r\n",
    "    \"Random Forest\": df_predicted_rf_regr,\r\n",
    "    # \"XGBoost\": df_predicted_xgb_regr,\r\n",
    "    \"Average\": df_predicted_mean,\r\n",
    "    \"Simple Linear Regression\": df_predicted_lr,\r\n",
    "}\r\n",
    "\r\n",
    "mae = []\r\n",
    "rmse = []\r\n",
    "\r\n",
    "# add 'list' if error\r\n",
    "for df_temp in models.values():\r\n",
    "    mae.append(mean_absolute_error(df_temp[\"actual\"], df_temp[\"predicted\"]))\r\n",
    "    rmse.append(mean_squared_error(df_temp[\"actual\"], df_temp[\"predicted\"], squared=False))\r\n",
    "\r\n",
    "df_results_regr = pd.DataFrame({\"Models\": list(models.keys()), \"MAE\": mae, \"RMSE\": rmse})\r\n",
    "\r\n",
    "display(df_results_regr)\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.281097</td>\n",
       "      <td>0.334649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Average</td>\n",
       "      <td>0.318810</td>\n",
       "      <td>0.354945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>0.292208</td>\n",
       "      <td>0.333280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Models       MAE      RMSE\n",
       "0             Random Forest  0.281097  0.334649\n",
       "1                   Average  0.318810  0.354945\n",
       "2  Simple Linear Regression  0.292208  0.333280"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the optimal model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "rf = RandomForestRegressor(\r\n",
    "    max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=100,\r\n",
    ")\r\n",
    "\r\n",
    "selected_features_rf_regr = [\r\n",
    "    \"mean_slope\",\r\n",
    "    \"mean_elevation_m\",\r\n",
    "    \"ruggedness_stdev\",\r\n",
    "    \"mean_ruggedness\",\r\n",
    "    \"area_km2\",\r\n",
    "    \"poverty_perc\",\r\n",
    "    \"coast_length\",\r\n",
    "    \"perimeter\",\r\n",
    "    \"glat\",\r\n",
    "    \"glon\",\r\n",
    "    \"coast_peri_ratio\",\r\n",
    "    \"rainfall_max_6h\",\r\n",
    "    \"rainfall_max_24h\",\r\n",
    "    \"dis_track_min\",\r\n",
    "    \"vmax\",\r\n",
    "]\r\n",
    "\r\n",
    "rf_fitted = rf.fit(X[selected_features_rf_regr], y)\r\n",
    "\r\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_regr_rf.sav\"\r\n",
    "path = os.path.join(cdir, file_name)\r\n",
    "pickle.dump(rf_fitted, open(path, \"wb\"))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:27: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_regr_rf.sav'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('Rice_Field_Damage_Philippines': conda)"
  },
  "interpreter": {
   "hash": "b367308e6f055391f859b515bbb645f6640c7b29224a7a1d3f6b55de7d9ef17f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}